0.00 16.14 SPEAKER_06  Are you going to be done chewing your little caramel?
16.96 17.92 SPEAKER_06  You can just do the intro.
18.52 21.68 SPEAKER_08  Just like dripping with like loathing.
21.68 30.38 SPEAKER_06  I hate eating on the mic and Milo, dear listener, we're going to be releasing all of this as chosen to eat a little caramel right now.
31.32 34.52 SPEAKER_06  And he's chewing right up by the fucking microphone.
35.02 36.22 SPEAKER_08  Unrepentant, ladies and gentlemen.
36.24 36.88 SPEAKER_05  I hate him.
37.84 39.10 SPEAKER_05  But folks, does he repent?
39.18 39.68 SPEAKER_05  He doesn't.
39.76 41.12 SPEAKER_05  He doesn't repent at all.
42.08 44.70 SPEAKER_05  People say, why do you chew the turtle on the mic?
44.72 47.40 SPEAKER_08  Trumpet canossa with the Holy Roman Emperor.
47.66 47.96 SPEAKER_06  That's right.
48.20 48.90 SPEAKER_06  Hi, everybody.
49.52 50.72 SPEAKER_06  It is TF.
50.96 51.44 SPEAKER_06  It is Monday.
51.56 52.42 SPEAKER_06  It's your bonus episode.
53.18 53.62 SPEAKER_06  Bonus.
54.74 55.76 SPEAKER_06  It's the bonus.
55.76 57.98 SPEAKER_06  You managed to finish chewing your little turtle.
58.02 58.34 SPEAKER_05  That's right.
58.42 59.44 SPEAKER_05  I finished chewing it.
59.50 61.26 SPEAKER_05  Sleepy Joe, he'd still be chewing away.
61.38 62.50 SPEAKER_05  He's not got his own teeth.
63.34 63.88 SPEAKER_05  He'd be there.
63.98 65.32 SPEAKER_05  He'd be getting Kamala to help him.
65.50 67.00 SPEAKER_05  He'd be saying, please help me chew.
67.40 68.58 SPEAKER_05  I can't chew anymore.
68.68 69.12 SPEAKER_05  No, no.
69.86 70.94 SPEAKER_06  That's what he would be saying.
71.02 71.72 SPEAKER_03  He would be saying that.
71.74 72.88 SPEAKER_05  You want to see him chew one, folks?
72.98 73.28 SPEAKER_05  Yeah.
76.48 82.42 SPEAKER_03  You know, actually, on that subject, Annabelle and I went to her five-year-old nephew's birthday party at the weekend.
82.42 83.00 SPEAKER_03  Was it a good party?
83.00 84.46 SPEAKER_03  Uh, no.
84.64 91.48 SPEAKER_03  However, they had, like, entertainment, which I've never seen at a children's party before outside of, like, a TV series.
91.58 93.90 SPEAKER_03  I feel like we always just went to soft play or some shit.
93.94 99.76 SPEAKER_03  But they had, like, a guy who came to a village hall to entertain the children for, like, two hours, which is my nightmare job.
100.54 103.04 SPEAKER_03  But what I realized- Yeah, you want to be entertaining drunk adults.
103.28 103.66 SPEAKER_03  Yeah.
103.84 104.72 SPEAKER_03  For 45 minutes.
104.72 105.24 SPEAKER_03  Exactly.
105.46 109.90 SPEAKER_03  What I realized is that this is exactly what a Trump rally is like.
110.28 113.20 SPEAKER_03  Because he would just be going, like, who likes farts?
113.30 114.34 SPEAKER_03  And they'd be like, yeah!
115.14 116.64 SPEAKER_03  And you're like, shall I do a fart?
116.78 117.14 SPEAKER_03  Yeah!
117.84 118.04 SPEAKER_03  Yeah.
118.04 121.46 SPEAKER_03  Like, the audience dynamic was exactly the same.
123.04 128.58 SPEAKER_08  You've circled back to this idea that Trump is a clown, not from, like, instinctual liberalism, but from having seen an actual clown.
128.58 129.76 SPEAKER_03  He's literally a clown.
129.90 130.82 SPEAKER_03  He's like Golier.
130.82 131.22 SPEAKER_03  Yeah.
131.22 131.54 SPEAKER_03  Yeah.
131.64 134.06 SPEAKER_06  He understands the absurdity of all politics.
134.26 135.82 SPEAKER_06  And that's awesome, basically.
135.98 136.18 SPEAKER_06  Yeah.
136.20 136.80 SPEAKER_06  That's what we're saying.
137.32 137.60 SPEAKER_06  All right.
137.66 138.40 SPEAKER_06  So, hi, everybody.
138.60 139.28 SPEAKER_06  It's TF.
139.40 139.74 SPEAKER_06  It's Bonus.
139.82 140.54 SPEAKER_06  You heard a little bit.
140.62 141.40 SPEAKER_06  Behind the curtain.
142.06 153.14 SPEAKER_06  In the second half of this episode, we're going to be talking to returning guest Dan McQuillan, who's the author of Resisting AI, Anti-Fascist Approach to Artificial Intelligence, and the Professor- Professor?
153.96 154.42 SPEAKER_06  I'm patient.
154.56 155.24 SPEAKER_06  Excuse me.
155.68 155.82 SPEAKER_03  Yeah.
156.20 157.28 SPEAKER_03  The Professor.
157.50 159.04 SPEAKER_03  Someone very interested in the Q branch.
159.04 168.42 SPEAKER_06  The professor, or lecturer, excuse me, in creative and social computing at Goldsmith, all about sort of his view on the sort of replacement of the public sector with AI.
169.10 169.30 SPEAKER_06  Yeah.
169.40 173.14 SPEAKER_06  I have no idea how that segment's going to go, because we definitely have a good look.
173.14 173.16 SPEAKER_06  Yeah.
173.16 175.28 SPEAKER_06  I'm really looking forward to doing that segment in the future.
175.38 178.88 SPEAKER_06  I was just going to say, we have actually done it already, and it's a pretty good conversation.
179.06 180.34 SPEAKER_06  So, do look forward to that.
180.40 182.96 SPEAKER_06  However, we have a few items.
182.96 193.14 SPEAKER_06  We have some news, but before that, I have, for the second time ever, and probably the last, I have some listener input, where someone has responded to one of the shows.
193.22 201.26 SPEAKER_06  I'm not going to say how, because I don't want to give you all ideas, in a way that makes me want to report to you what they said, because it was just a very, very interesting thing.
201.26 202.90 SPEAKER_06  And I thought it was worth listening.
203.08 225.62 SPEAKER_06  So, thank you to the listener who brought this to my attention, which is that when we talked about AI and gaming, when we talked about the SAG-AFTRA contract, what we didn't, we talked about everything except the actual economics of how that would work for the companies, because AI models, right, when you run them, they cost a little bit of money every single time.
226.24 226.34 SPEAKER_08  What?
226.88 227.16 SPEAKER_08  So.
227.70 228.42 SPEAKER_08  No, no, you're right.
228.42 235.64 SPEAKER_08  We completely fucking forgot to talk about that, because we bought into the hype of AI, where they're just like, we're not going to mention this, you know, it's going to be
235.64 256.42 SPEAKER_06  frictionless. So, if you're going to have, as Replica Studios sort of seems to be pushing, the idea of infinitely scalable NPCs that have AI brains, basically, that you can just say whatever you want to, I don't know how that doesn't cost, like, I don't know, a dollar for every time you talk to the shopkeeper in Baldur's Gate.
257.10 258.26 SPEAKER_08  Don't worry about it.
258.26 271.68 SPEAKER_08  I mean, video games getting more expensive is like one of those kind of like bullshit consumer complaints, but they do, and this is going to make them more so, despite AI making it easier to produce like a shitload more and worse content.
271.76 274.18 SPEAKER_08  Video games are going to get worse and more expensive.
274.68 278.30 SPEAKER_08  But also, all of that computing is going to have to happen somewhere, as you say.
278.30 285.26 SPEAKER_08  And I think the trend for that already, this priming for this, has been that you just won't own anything.
285.40 290.44 SPEAKER_08  You'll have games as like a live service, and ideally, you won't even have the hardware.
290.58 301.12 SPEAKER_08  You'll just do the sort of Google Stadia thing, where like, it is running on Google's computers and it's a little walled garden, completely unmodifiable and unaccessible to you, and you just stream it.
301.12 303.10 SPEAKER_08  And play it that way.
303.22 305.20 SPEAKER_08  And then once you're done, it just goes back into the void.
305.20 323.42 SPEAKER_06  What I think would be cool is if we distributed gaming like smart meters, like sort of smart metered energy, where it's like you log on, and if a lot of other people are using the data center at the same time, it's expensive to talk to the shopkeeper and get your procedurally generated AI dialogue.
323.86 328.08 SPEAKER_06  But if you're playing not at peak hours, it's actually cheaper to talk to the shopkeeper.
328.52 331.58 SPEAKER_06  And so then you just get a bill after you're finished playing your game.
331.60 333.40 SPEAKER_06  I can't afford to talk to the shopkeeper.
333.56 334.74 SPEAKER_04  It's 6.30 p.m.
335.20 337.02 SPEAKER_04  It's fucking pandemonium in there.
337.06 338.44 SPEAKER_03  No, I'll come back at 4 a.m.
338.80 340.84 SPEAKER_03  Have a right old natter with a geezer.
341.74 356.34 SPEAKER_06  And so that means that in exchange for the NPCs having a rich full life, mediated through a large language model, unless that large language model is going to be just run on your home computer and also be very...
356.34 357.00 SPEAKER_06  Oh, it won't be.
357.12 357.28 SPEAKER_06  Yeah.
357.34 357.72 SPEAKER_06  No, no, no.
357.78 375.10 SPEAKER_08  It absolutely won't be, because the thing is, right, like if that cost has to get passed onto you, then publishers particularly want to do that in a way that like they do it and then you pay more to them for it because they can overcharge you more rather than you pay for the cost of the utility or whatever.
375.48 377.52 SPEAKER_08  It's the same thing as like dedicated servers, right?
377.52 384.56 SPEAKER_08  Where can you sort of like host the infrastructure that allows you to play a multiplayer game on your own server?
385.04 389.08 SPEAKER_08  Often this is a tremendously vexed question because what publishers and developers want is to say no.
389.18 391.02 SPEAKER_08  To be like, no, you have to go through us.
391.36 396.64 SPEAKER_08  And yes, this is very expensive for us to maintain these servers, but and that's why we will charge you more to do it.
396.64 405.72 SPEAKER_06  So what's going to happen is you're going to set up, you're going to get Pope in your computer, you're going to play Crusader Kings 3, and it's going to be like, thank you for playing Crusader Kings 3.
405.88 407.90 SPEAKER_06  Your session ended up costing you $14.
408.62 408.84 SPEAKER_08  Yeah.
408.96 412.58 SPEAKER_08  And the thing is, you won't own Crusader Kings 3.
412.70 415.28 SPEAKER_08  You won't be able to play Crusader Kings 3 if your internet is down.
415.66 419.00 SPEAKER_08  And you won't be able to do anything unconventional with it.
419.02 429.92 SPEAKER_08  You won't be able to install the mod that makes all of the medieval kings and queens into My Little Ponies because that's just running on some Google thing somewhere and what you're getting is a stream of it that you're manipulating.
429.92 434.72 SPEAKER_03  It'll become cheaper and more effective to simply go on a crusade where you can do whatever you want.
435.34 437.18 SPEAKER_03  You can just reclaim the holy land.
437.58 437.78 SPEAKER_08  Yeah.
437.84 439.14 SPEAKER_08  We've accidentally killed video games.
439.20 441.14 SPEAKER_08  It's now cheaper and easier to do the thing.
441.56 449.36 SPEAKER_08  I am going to, instead of buying the next Call of Duty, I'm going to join the SAS because it's easier for me to do one trillion pushups.
449.36 458.84 SPEAKER_06  So, I just want to, once again, thank the listener who brought that to our attention because that is actually the most interesting part of that whole deal.
459.26 459.62 SPEAKER_06  All right.
459.70 464.00 SPEAKER_06  On to a couple pieces of news before we go and talk with Dan.
464.46 467.44 SPEAKER_06  First is a little bit of UK news.
467.92 469.24 SPEAKER_06  I don't want to alarm any of you.
469.30 469.96 SPEAKER_06  That plays again.
469.98 470.86 SPEAKER_06  I don't want to alarm any of you.
470.86 479.12 SPEAKER_06  Remember that 28 billion pounds that was going to be spent in the first term of a, um, of a Starmer parliament?
479.12 484.40 SPEAKER_06  And then they said they would spend it at some point towards the second half of a Starmer parliament.
484.40 486.48 SPEAKER_08  Riley, I want to be a hundred percent honest with you.
486.60 487.06 SPEAKER_08  Uh, no.
487.28 487.52 SPEAKER_06  Well.
487.94 488.64 SPEAKER_08  The Stormlement.
489.08 492.80 SPEAKER_06  They were, this is the, uh, green prosperity plan.
493.00 494.06 SPEAKER_06  This was our answer.
494.22 494.84 SPEAKER_06  The Storm chamber.
494.86 496.90 SPEAKER_06  This was our answer to the Inflation Reduction Act.
496.90 500.14 SPEAKER_06  It has been, uh, chipped away at, reduced in its promise.
500.22 513.44 SPEAKER_06  It was going to be the thing that basically, like, fixes the, uh, British infrastructure and public sector much in the same way that the Inflation Reduction Act fixed not by improving but by patching a rotten system, the US state.
513.52 516.00 SPEAKER_03  Would you say that it's undergone a Storm reduction process?
516.36 517.22 SPEAKER_03  Thank you, Milo.
518.34 518.82 SPEAKER_08  Yeah.
518.92 525.30 SPEAKER_08  So, have they sacrificed this one on the altar of fiscal, uh, sort of, uh, sternness again?
525.30 528.08 SPEAKER_06  Labor insiders have claimed to the Sun newspaper.
528.98 530.22 SPEAKER_06  Yeah, very buttery staircase.
530.22 531.58 SPEAKER_03  Imagine being one of those guys.
531.70 532.38 SPEAKER_06  Okay, yeah.
532.56 541.28 SPEAKER_06  Um, that the mission to ramp up clean energy production with a massive borrowing hike had become, quote, an albatross around our neck and we're going to dump the figure all together.
542.28 542.64 SPEAKER_08  Oh, no.
542.70 546.30 SPEAKER_08  Yeah, because that poem is about the guy dumping the albatross off his neck.
546.30 546.48 SPEAKER_08  Yeah.
546.60 547.80 SPEAKER_08  Making everything fine again.
547.80 548.20 SPEAKER_03  That's right.
548.30 549.64 SPEAKER_03  Or so much for the Storm offensive.
549.94 550.14 SPEAKER_03  Right.
550.26 550.52 SPEAKER_03  Okay.
550.52 561.42 SPEAKER_08  So, it's like the fucking, not to do a Twitter review, but the Paul Mason tweet where he said the canaries in the coal mine are singing to indicate that things were bad.
561.74 561.90 SPEAKER_08  Yeah.
562.30 562.52 SPEAKER_03  Yeah.
562.94 565.10 SPEAKER_03  They're, uh, they're singing the Sog of Silence.
565.18 565.48 SPEAKER_03  Yeah, yeah.
565.50 567.24 SPEAKER_03  They're singing stuff from The Greatest Showman.
567.28 568.34 SPEAKER_03  It's really fucking annoying.
568.64 569.68 SPEAKER_03  Everyone out of the mine.
570.26 571.08 SPEAKER_03  There's no gas.
571.08 574.56 SPEAKER_08  My, my, my mind canary is doing John Cage's 433.
574.56 574.88 SPEAKER_08  Yeah.
574.98 578.72 SPEAKER_06  Uh, so, this is, this is the, um, the claim, essentially.
578.86 585.42 SPEAKER_06  They're saying, all right, that thing where we were finally going to invest in the public sector, the bit that business wanted, right?
585.50 591.48 SPEAKER_06  There's some now, like, even capital is saying to labor, you are being annoyingly tight.
592.08 592.26 SPEAKER_06  Yeah.
592.66 594.32 SPEAKER_06  Get a fucking round in Starmer.
594.48 596.22 SPEAKER_03  They are clamoring.
597.22 599.52 SPEAKER_03  Uh, Starmer comes back with halves for everyone.
599.52 602.12 SPEAKER_06  Uh, it's like, well, we're all driving.
602.32 603.58 SPEAKER_06  I mean, come on, be reasonable.
604.16 621.76 SPEAKER_06  And, and meanwhile, right, there's a new study has been released from the London School of Economics saying that, um, an uplift in public investment of approximately 26 billion pounds a year after more than a decade of underinvestment is the only thing that would give the UK a chance of staying in, let alone ahead of the global innovation, efficiency, and productivity game.
621.76 624.24 SPEAKER_06  And while high taxes do constrain private activities.
624.36 629.36 SPEAKER_06  So again, this is like the most neoliberal study says the evidence.
629.52 637.24 SPEAKER_06  In the UK, the far bigger constraint is deficient infrastructure and underinvestment in human, intangible, and natural capital.
637.38 638.34 SPEAKER_08  My God, he admitted it.
638.34 649.30 SPEAKER_08  Even the guys in, like, top hats and, like, gold pocket watch chains are saying none of the public services work, which makes it impossible to run a business here, however exploitatively you let us do it.
649.30 653.08 SPEAKER_02  Can I just say, I reject entirely the idea that I did not get around it.
653.28 654.48 SPEAKER_02  I did get around it.
654.48 663.04 SPEAKER_02  I simply refused to buy cocktails, which were not previously discussed, and suggested substituting a much more reasonably priced slimline gin and tonic.
663.54 674.82 SPEAKER_02  I had only had a Guinness, and I think that a cocktail is simply out of proportion with the number of drinks that I had drunk, and I was not going to buy cocktails from others when I was not drinking anything at that price point.
677.30 680.06 SPEAKER_06  I'm sure you can imagine it's very annoying to go to the pub with me.
680.82 681.22 SPEAKER_06  Oh, yeah.
682.82 687.16 SPEAKER_03  I've bought the economy a Diet Coke, and it will be glad in it.
688.46 689.36 SPEAKER_03  And that's essentially it.
689.36 692.34 SPEAKER_06  And, you know, a Robinson's fruit shoot for the potholes.
692.62 692.82 SPEAKER_06  Yeah.
693.08 699.58 SPEAKER_06  We can be pretty sure that that source is probably the certain owner of a buttery staircase.
700.04 700.44 SPEAKER_06  Yes.
701.54 707.38 SPEAKER_06  And because that is, like, the, that is his, that is the Peter Mandelson way.
707.98 713.32 SPEAKER_05  Well, I ordered an espresso martini, and I did not receive one.
714.58 717.00 SPEAKER_05  Let's just say I've got out the lower pack.
717.00 731.16 SPEAKER_06  You know, and it's, and so we already are in a place where nothing works, growth is non-existent, and most of the economy has been driven by just a huge ratcheting up of consumer debt through, like, mortgages and credit cards, rather than, say, stuff.
731.58 732.94 SPEAKER_06  Oceans and our battlefields.
733.00 739.02 SPEAKER_06  And the, and the response from Labour is to continue dithering about this figure.
739.14 742.16 SPEAKER_06  Now, they've insisted they're not dropping it, right?
742.16 753.18 SPEAKER_06  But I, I have some, I've always had some skepticism, and it seems ever closer to being, it's already been compromised several times, and it seems ever closer.
753.46 758.62 SPEAKER_08  The sort of, the Blair tendrils are curling properly around Starman, which is alarming.
758.90 759.16 SPEAKER_03  However.
759.36 763.06 SPEAKER_03  The Blair tendrils feels like one of those indie bands from the landfill area.
763.06 779.80 SPEAKER_06  Now, at the same time, right, I think it's important, and again, this is not really being sort of discussed much at all, at the same time as this sort of, all of the funding for the sort of green transition in general is being sort of hummed and hawed over by the people who are supposed to give it, Tata Steel...
779.80 781.90 SPEAKER_06  Yeah, doesn't want to fund even one transition.
782.28 790.96 SPEAKER_06  At the same time, the last steel plant, the last major steel plant in the UK, has closed even after the government has offered them 500 million.
790.96 792.62 SPEAKER_06  Talk about Tata Steel.
794.04 805.46 SPEAKER_08  Well, yeah, because they kept, the successive governments kept trying to bribe the steel industry to keep, you know, plants open in the UK, and it always kicked the can down the road a little bit further.
805.68 809.98 SPEAKER_08  And now we've finally run out, and now it's just like, oh, this is something we can't do in this country anymore.
810.12 819.58 SPEAKER_06  Well, you remember, one of the last times that the steel industry tried to be reinvigorated in the UK, Lex Greensill was at the centre of it.
819.58 820.74 SPEAKER_06  Great, cool.
820.84 830.56 SPEAKER_08  I mean, the thing is, right, like, not to be sort of like, I love blast furnaces so much, but one of the things that you are going to need to do a green transition is steel.
831.10 842.86 SPEAKER_08  And one of the things about making steel here is that it provides a lot of jobs, and it allows you to make it in a way that's maybe slightly more environmentally responsible if you're making it in question mark.
842.86 856.26 SPEAKER_08  So, yeah, no, that's just gone now because nobody bothered to care about it because it was unfashionable, and you were supposed to go and start recording podcasts or doing, like, web development.
856.44 866.02 SPEAKER_03  So I actually don't fully understand it because I heard a news report about this, but it's that they're replacing the blast furnace with an electric one, which will require a lot less staff to operate, correct?
866.02 871.70 SPEAKER_03  But are they actually reducing the amount of steel they make, or are they just reducing the amount of staff that they have?
872.08 881.16 SPEAKER_06  So the issue, right, is that, um, is number one, huge numbers of jobs are being lost, and number two, while we still can make steel, we won't be able to make new steel.
881.30 884.38 SPEAKER_06  So electric blast furnaces, you can't make steel out of ore.
884.80 886.38 SPEAKER_06  You can only recycle steel.
886.50 886.82 SPEAKER_03  Yeah, essentially.
886.96 887.82 SPEAKER_06  Ah, right, right, right, I see.
887.82 899.76 SPEAKER_06  And much of the argument here, right, and again, this is arguments that the unions put forward, is that the blast furnaces are actually economical to run when energy prices aren't artificially high.
900.22 900.98 SPEAKER_06  Right, okay, yeah.
901.34 928.58 SPEAKER_06  And so, but what is essentially happening is that government and Tata Steel are sort of allowing a huge amount of investment to collapse again, right, and again, successive governments allowed for this, allowing a huge amount of investment to collapse again based on a pretty flimsy argument, and that is, again, going to devastate, further devastate the economy of Wales, and massively reduce the amount of steel that we're able to produce, and eliminate our capacity to produce primary steel at all.
928.88 935.46 SPEAKER_08  And just, not to keep hammering on this, but, like, this was a nationalised industry, like, from the 60s until, like, the late 80s.
935.52 937.90 SPEAKER_08  Like, it wasn't even something that Thatcher came for first.
938.28 954.74 SPEAKER_08  British steel was, like, a nationalised monopoly, and now it's just sort of, like, what we've decided to do is break it up, sell it off, paid the companies running it a succession of large bribes to keep doing it, and now it's unprofitable for them to keep doing that in a way that it implies people.
954.74 955.88 SPEAKER_06  I'd love to privatise a business.
955.88 956.84 SPEAKER_06  It is still profitable.
957.38 958.36 SPEAKER_06  It is profitable.
958.54 960.30 SPEAKER_06  It is profitable for them to do it.
960.50 970.86 SPEAKER_06  It's just not profitable for them to do it when all of the energy they are buying is from another privatised cartel that has managed to, like, reap super profits from a global disruption.
971.16 972.96 SPEAKER_06  It is still profitable to do it.
972.96 974.08 SPEAKER_06  This is great.
974.48 976.14 SPEAKER_06  Anyway, if you're...
976.14 978.44 SPEAKER_08  All of our middlemen are now interfering with each other.
978.66 980.28 SPEAKER_06  Yes, that's exactly what it is.
980.60 981.04 SPEAKER_06  There are...
981.04 994.52 SPEAKER_06  The actual production of steel and electricity, two of the most important things in running a national economy, are in the hands of so many middlemen that the middlemen are the ones who are now being screwed over by one another.
995.02 995.32 SPEAKER_08  Yeah.
995.66 998.18 SPEAKER_08  You have sort of, like, central unplanners.
998.42 1001.50 SPEAKER_08  It's, like, frustrating different sectors of the economy.
1001.50 1002.74 SPEAKER_03  This is the problem with Britain.
1002.86 1004.36 SPEAKER_03  There's no tops or bottoms anymore.
1004.48 1005.36 SPEAKER_03  It's all just middles.
1005.66 1005.88 None  Wow.
1007.28 1012.38 SPEAKER_03  Anyway, if you're interested in what happened to British steel, there's a documentary you can watch about it called The Full Monty.
1013.38 1024.50 SPEAKER_06  So, you know, this comes back to, again, like, this comes back to not just the consequences for the larger plan, which, again, means, like, yeah, we can make...
1024.50 1029.78 SPEAKER_06  There will be steel that will be made in some of the country, but no more primary steel at all.
1030.08 1030.32 SPEAKER_06  None.
1030.70 1030.96 SPEAKER_06  Zero.
1031.44 1031.70 SPEAKER_06  Right?
1031.78 1036.44 SPEAKER_06  That means a huge reliance on, like, elsewhere, essentially, and shipping that here.
1037.08 1037.20 SPEAKER_06  Right?
1037.54 1037.74 SPEAKER_06  Mm-hmm.
1037.78 1038.08 SPEAKER_06  Yeah.
1038.08 1044.46 SPEAKER_06  But also, again, like, you can't overlook as well the massive devastation to that that happens when industry towns lose their industry.
1044.62 1049.48 SPEAKER_06  We know that those people don't up sticks, become programmers, and move to somewhere where there's programming.
1049.64 1050.78 SPEAKER_06  You can't be a programmer anymore.
1050.78 1052.36 SPEAKER_06  Well, it's taken by AI.
1053.58 1053.98 SPEAKER_08  Yeah.
1054.22 1066.24 SPEAKER_08  Yeah, I mean, this is something that I have a feeling we'll say in about 10 minutes' time, but, like, you could restructure those economies if you spent any money or time to do it, but we won't.
1066.34 1073.58 SPEAKER_08  We will just sort of sit there, and then when the sort of people of Portovo vote in a way that we don't like, which, by the way, they never have.
1073.58 1077.48 SPEAKER_08  Like, Portovo has voted Labour since, like, 1922.
1078.10 1078.70 SPEAKER_08  Every election.
1078.70 1079.30 SPEAKER_06  A day one heads.
1079.30 1080.30 SPEAKER_08  Yeah, people...
1080.30 1088.60 SPEAKER_08  Yeah, and yet people on the right of the Labour Party are still like, well, shouldn't, you know, shouldn't have voted Brexit, shouldn't have voted Tory, you know, no sympathy.
1088.86 1095.68 SPEAKER_08  And so, yeah, we're just going to continue to shame anyone who has been immiserated as a result of this kind of, like, incoherence.
1095.70 1098.56 SPEAKER_02  To the people of Portovo, I say we will not leave you behind.
1098.84 1100.94 SPEAKER_02  Why don't you get into Twitch streaming?
1101.50 1104.18 SPEAKER_08  Or selling bath water.
1104.42 1105.64 SPEAKER_08  There are many things.
1105.64 1111.00 SPEAKER_08  Yeah, if you've been working a blast furnace all your working life, just become an e-girl.
1111.18 1111.76 SPEAKER_08  You know, easy.
1111.90 1112.40 SPEAKER_08  Easily done.
1112.78 1115.38 SPEAKER_06  Before we go into our second half, I have another piece of news I want to talk about.
1116.22 1118.56 SPEAKER_06  I'm going back to Neom.
1119.26 1119.96 SPEAKER_03  Oh, hell yeah.
1119.96 1122.14 SPEAKER_06  Because they are...
1122.14 1126.30 SPEAKER_06  Look, they were a little bit back when they invented, like, the food town, right?
1126.38 1129.12 SPEAKER_06  We're going to reinvent dinner, right?
1129.30 1129.86 SPEAKER_06  In Neom.
1130.20 1136.20 SPEAKER_06  And I was like, okay, you're no longer just all about different shapes of luxury hotel, but I'm skeptical.
1136.20 1137.30 SPEAKER_06  Would you describe them as Sobak?
1137.92 1139.50 SPEAKER_06  I would describe them as Sobak.
1139.58 1140.34 SPEAKER_06  Yes, thank you, Milo.
1141.20 1145.32 SPEAKER_06  Because Neom hasn't unveiled their 10th and final region.
1146.38 1148.16 SPEAKER_08  I will put a marker down now.
1148.22 1149.74 SPEAKER_08  This will not be their final region.
1149.88 1151.76 SPEAKER_08  They will announce another round of bullshit.
1151.76 1153.30 SPEAKER_08  They will go back for more Neom.
1153.30 1155.20 SPEAKER_03  Neom has DLC, you know?
1155.38 1158.64 SPEAKER_03  Like, the map is a certain size when you first log on, but then...
1158.64 1159.24 SPEAKER_03  Aquellum.
1159.24 1162.50 SPEAKER_03  That's an investment fund
1162.50 1163.98 SPEAKER_08  based in the city, sorry.
1164.30 1168.18 SPEAKER_06  Will be centered... Or it's, like, really fancy clothes.
1168.58 1169.28 SPEAKER_06  You're just thinking...
1169.28 1170.78 SPEAKER_06  You're thinking you're Aquascooter, maybe?
1170.92 1171.40 SPEAKER_06  But let me tell you.
1171.40 1172.26 SPEAKER_06  Yeah, I am thinking of Aquascooter.
1172.26 1173.22 SPEAKER_06  Let me tell you about Aquellum.
1174.16 1179.68 SPEAKER_06  It is a reverse skyscraper inside a mountain and will be centered around an underwater open square.
1180.28 1180.62 SPEAKER_08  Cool.
1181.68 1183.38 SPEAKER_08  We're going full Bond villain.
1183.84 1184.88 SPEAKER_08  You know, we're finally...
1184.88 1186.92 SPEAKER_08  We're building the lair inside the volcano.
1187.18 1188.84 SPEAKER_08  It's got the little monorail around the outside.
1188.84 1189.24 SPEAKER_06  It does.
1189.24 1190.62 SPEAKER_06  It does have the monorail.
1190.94 1193.08 SPEAKER_06  They have a multi-directional lift.
1193.58 1194.42 SPEAKER_06  Well, how do they need
1194.42 1195.70 SPEAKER_03  British steel to build that?
1197.58 1201.08 SPEAKER_08  Yeah. It's got the guy who says everything twice into the tannoy.
1201.42 1206.58 SPEAKER_08  I mean, so they're building this like, below ground level?
1206.58 1207.16 SPEAKER_08  Well, like, no.
1207.26 1208.40 SPEAKER_08  Into the mountain itself.
1208.58 1209.58 SPEAKER_08  Like, fucking...
1209.58 1211.02 SPEAKER_08  This is the prepper district
1211.02 1215.86 SPEAKER_06  of Neon. Well, they're building it into the mountain, but the mountain is also coastal.
1216.82 1217.08 SPEAKER_06  Okay.
1217.54 1217.94 SPEAKER_06  I...
1217.94 1219.46 SPEAKER_06  So it's a coastal mountain.
1219.50 1221.98 SPEAKER_06  Are they building the mountain or does the mountain already exist?
1221.98 1222.86 SPEAKER_06  No, the mountain exists.
1222.96 1223.98 SPEAKER_06  It's in the Gulf of Acaba.
1224.62 1225.04 SPEAKER_06  And the way...
1225.04 1230.62 SPEAKER_06  So, listeners, I'd like you to imagine, please, a bay inlet beside a mountain.
1231.28 1235.26 SPEAKER_06  In that bay, there is a sort of hole in the water.
1235.40 1235.78 SPEAKER_06  This is the
1235.78 1238.14 SPEAKER_03  trash future guided meditation. And it's surrounding...
1238.14 1238.88 SPEAKER_06  Breathe in and out.
1239.14 1240.50 SPEAKER_06  Surrounding the hole in the water.
1240.60 1245.44 SPEAKER_06  So it's like walls built and like a structure like walls built, a structure sort of underwater with an open top.
1246.46 1258.78 SPEAKER_06  There are super yachts moored and then you go into this open underwater town square and you go into a cave underwater where you take a boat into the skyscraper.
1258.90 1260.20 SPEAKER_06  It's only accessible by boat.
1260.20 1260.90 SPEAKER_03  Wait, wait, wait.
1261.02 1266.90 SPEAKER_03  So it's an underwater town square but which has an open top because the walls go to like just above the surface.
1266.98 1267.68 SPEAKER_03  That's the idea.
1268.10 1271.30 SPEAKER_03  And if weather happens, just don't worry about it?
1271.38 1271.56 SPEAKER_03  Yep.
1271.92 1272.70 SPEAKER_08  In Saudi Arabia?
1272.90 1273.16 SPEAKER_03  No.
1273.52 1273.86 SPEAKER_03  No.
1274.06 1276.18 SPEAKER_03  What if there were a wave or something?
1276.38 1278.28 SPEAKER_03  Like we're not gonna address this.
1278.36 1279.26 SPEAKER_03  Well, it won't be a wave.
1279.80 1280.00 SPEAKER_08  Yeah.
1280.24 1281.06 SPEAKER_03  Probably won't be a wave.
1282.10 1282.88 SPEAKER_03  Mexicans aren't allowed.
1282.88 1283.88 SPEAKER_08  I just...
1283.88 1285.32 SPEAKER_08  I feel like they've...
1285.32 1291.12 SPEAKER_08  Each of these little districts is designed to set up a 1970s disaster movie.
1291.84 1295.32 SPEAKER_08  And so here they've just done a kind of like Towering Inferno.
1295.56 1296.72 SPEAKER_08  Towering Inferno 2.
1297.38 1298.94 SPEAKER_06  Abyssal Flood, basically.
1299.24 1299.28 SPEAKER_03  Yeah, yeah, yeah.
1299.28 1304.40 SPEAKER_03  To be fair, Towering Inferno would be pretty easy to put out if it happened in the Neom underwater town square.
1304.52 1305.66 SPEAKER_03  That'd be a pretty obvious solution.
1305.90 1312.74 SPEAKER_06  It's a bit of an old lady who swallowed a fly thing because yeah, our Inferno problem has solved but our flood problem is rapidly worsening.
1313.74 1314.58 SPEAKER_06  Yeah, yeah, yeah.
1314.58 1317.60 SPEAKER_06  All we gotta do is release these cane toads and we'll be fine.
1317.88 1324.00 SPEAKER_06  It will feature a floating marina that will be located in the sea next to a mountain range that'll be the access point for visitors.
1324.30 1325.00 SPEAKER_06  That's the other thing.
1325.34 1331.36 SPEAKER_06  You enter the floating marina and they have a video where they've got some like Instagram influencers getting on a boat
1331.36 1336.40 SPEAKER_08  in front of a green screen. One of them's wearing a chainmail hijab which is a little bit comfy.
1336.80 1336.90 SPEAKER_08  Whoa.
1338.76 1339.20 SPEAKER_08  Seriously,
1339.40 1340.32 SPEAKER_07  because it's the future. Because it's the future.
1340.32 1340.94 SPEAKER_07  The world's first Muslim crusader.
1340.94 1344.70 SPEAKER_07  The game got too expensive.
1345.22 1346.12 SPEAKER_06  Yeah, that's right.
1346.60 1354.50 SPEAKER_06  And so, don't forget also, this is a building drilled into the ground beside the water.
1354.86 1356.48 SPEAKER_08  Wait, so are they going down or up?
1356.50 1369.62 SPEAKER_08  Because if they're going down, I have to rehash a thing that I had with a Twitter account last year where a guy posted one of those like ICBM silos that the Americans have in Montana that, you know, they decommissioned and was like, why don't we just build like this?
1369.70 1373.40 SPEAKER_08  Why don't we just solve density or overcrowding or whatever by building straight down?
1373.80 1376.30 SPEAKER_08  And I had to be like, do you know how a toilet works?
1376.66 1390.28 SPEAKER_08  Because, like, Dubai, which is just built like a relatively normal city, already has to pipe water in from desalination plants and pipe shit and piss out in like fleets of trucks.
1390.76 1403.66 SPEAKER_08  So, if you're like under a mountain going down, if you're living in Saudi dwarf fortress, if fucking Yurus bin Sultan has struck the earth and you live down there, how do you, are they going to like force it back up?
1403.78 1404.14 SPEAKER_08  What the fuck?
1404.14 1408.24 SPEAKER_03  In Dubai, there's an even harder form of the bin man for you to respect, the piss and shit man.
1409.50 1411.08 SPEAKER_07  Remember when the piss and shit man was out?
1411.08 1412.88 SPEAKER_03  You're a wheelie bin full of piss and shit.
1413.96 1416.92 SPEAKER_06  So, Alice, it will not surprise you know that has not been considered.
1417.32 1421.40 SPEAKER_06  To enter a quellum itself, visitors will go on a quote, specially designed vessel, unquote.
1421.40 1432.08 SPEAKER_08  In fairness to them, like these are various of like architect, sort of very PR kind of websites and so, in the FAQs, a queue not F-aid is like,
1432.08 1433.58 SPEAKER_03  what do you do with all the piss and shit?
1433.58 1442.20 SPEAKER_03  If you're building like hundreds of stories into the ground, like right next to the sea, are you going to encounter some like water table issues?
1443.08 1443.26 SPEAKER_08  Nope.
1443.56 1447.30 SPEAKER_08  But if you like drill straight down, then eventually you get into like China.
1447.66 1447.98 SPEAKER_08  You know.
1448.84 1452.06 SPEAKER_08  I was going to say like caves filled with like dragons and giants and stuff.
1452.12 1452.60 SPEAKER_06  Oh yeah, yeah.
1452.60 1453.18 SPEAKER_06  Well that's an option.
1453.20 1457.92 SPEAKER_06  To enter a quellum itself, visitors will go on a specially designed vessel that will travel on a hidden underground canal.
1457.92 1460.78 SPEAKER_06  This will open up into an underwater town square.
1461.80 1462.74 SPEAKER_08  An underwater town square.
1462.74 1463.94 SPEAKER_08  Mystery flesh pit national park.
1464.20 1466.90 SPEAKER_06  A quellum is an ultra luxury upside down.
1467.44 1473.22 SPEAKER_06  A quellum is an ultra luxury upside down skyscraper where the facade faces inwards instead of outwards.
1473.82 1474.20 SPEAKER_08  Question.
1474.74 1476.84 SPEAKER_08  What if the specially designed vessel breaks?
1477.06 1482.44 SPEAKER_08  Is everyone then in a sort of like Thai cave child world rescue situation inside a mountain?
1482.44 1483.20 SPEAKER_08  Thank you for your question.
1483.38 1483.66 SPEAKER_06  Yes.
1484.72 1486.54 SPEAKER_06  Oh, so you're just entombed then?
1486.58 1486.68 SPEAKER_06  Yeah.
1486.88 1490.72 SPEAKER_06  This is a place that the wealthy and powerful go to be entombed.
1490.82 1491.14 SPEAKER_06  Essentially.
1491.26 1491.62 SPEAKER_08  I don't.
1491.72 1497.48 SPEAKER_08  The thing is one of all the things that I could be while I'm alive, entombed is one that I really don't want to.
1497.92 1500.78 SPEAKER_03  Well, you're going to serve Mohammed bin Salman in the afterlife.
1500.98 1502.22 SPEAKER_03  That's why you have to be entombed there.
1502.30 1503.56 SPEAKER_08  Another thing I don't want to do.
1503.70 1509.98 SPEAKER_06  The building will be centered around a 100 meter tall central void that rises from the underwater square and is surrounded by walkable paths.
1510.42 1512.48 SPEAKER_06  Visuals show a large open concrete building.
1512.62 1515.96 SPEAKER_06  I want to serve cunt in this life, not serve a cunt in the afterlife.
1516.66 1517.20 SPEAKER_08  That's right.
1517.50 1520.28 SPEAKER_08  Walkable paths is a very funny, like stick an extra word in there.
1520.28 1520.44 SPEAKER_06  Yeah.
1521.18 1526.94 SPEAKER_06  Geometrically shaped balconies protruding from the walls as well as deep cutouts that will house terraces and patios, ponds, and indoor waterfalls.
1527.38 1532.72 SPEAKER_06  Natalie Rosenquake said, it becomes the sort of magic cube around which everything plays out.
1533.00 1533.92 SPEAKER_06  The only exterior part...
1533.92 1536.04 SPEAKER_08  What is it with the Saudis and magic cube?
1536.10 1537.28 SPEAKER_08  They've already had one.
1537.30 1537.68 SPEAKER_06  They have three.
1537.68 1538.30 SPEAKER_06  It was already there.
1538.30 1540.32 SPEAKER_08  They have the kubaraba as well, the second one.
1540.96 1541.86 SPEAKER_08  No, that's what I mean.
1541.98 1543.02 SPEAKER_08  They had one.
1543.08 1543.42 SPEAKER_08  And the kaba.
1543.42 1544.40 SPEAKER_08  It was perfectly good.
1544.76 1545.90 SPEAKER_08  But yeah, that's the one I mean.
1546.00 1549.92 SPEAKER_08  It was sticking around for like hundreds of years and they were like, this magic cube isn't enough.
1550.06 1551.10 SPEAKER_08  We got to have more cubes.
1551.14 1551.78 SPEAKER_08  Yeah, that's right.
1552.18 1553.46 SPEAKER_08  More hubristic cubes.
1553.60 1553.70 SPEAKER_03  Yeah.
1553.82 1554.94 SPEAKER_03  The more cubes you have,
1555.00 1557.92 SPEAKER_06  the more Muslim it is. Nate, can you cut all of me...
1557.92 1558.48 SPEAKER_06  It's fine.
1558.98 1563.42 SPEAKER_06  The only exterior part of the building, the roof, will contain a space described as a cloud garden.
1563.94 1567.72 SPEAKER_06  Renders show planted pathways arranged above the void with water visible below the gaps.
1568.06 1574.50 SPEAKER_06  The different levels of the skyscraper will be connected by The Boulevard, capital B, a path that winds its way through the courtyard.
1575.02 1578.84 SPEAKER_06  And it will feature a space called The Generator, which will be dedicated to ideas.
1579.62 1581.38 SPEAKER_08  They've got to stop naming things.
1581.48 1582.56 SPEAKER_08  They can't be trusted with it.
1582.56 1582.98 SPEAKER_03  The Generator.
1583.12 1585.96 SPEAKER_03  That sounds like a house robot on Robot Wars.
1587.24 1588.06 SPEAKER_03  Rosenquake said.
1588.70 1594.36 SPEAKER_03  Sorry, this is so crazy that we've completely left out the fact that her name is Rosenquake.
1594.76 1596.58 SPEAKER_03  Well, she's Dutch, so it's got a J in there.
1596.68 1597.58 SPEAKER_03  I don't know how it's pronounced.
1599.10 1600.48 SPEAKER_03  The Generator is an experience...
1600.48 1603.68 SPEAKER_03  It's very exciting to be designing the underwater town square for neon.
1604.68 1606.40 SPEAKER_08  Yeah, Rosenquake and Guildenstern are dead.
1606.82 1610.02 SPEAKER_06  The Generator is an experiential space that will change you forever.
1610.90 1612.98 SPEAKER_08  Every space is an experiential space.
1613.12 1615.04 SPEAKER_08  At most parts are walkable paths.
1615.44 1619.64 SPEAKER_08  Every, like a geometrically shaped balcony is a shape...
1619.64 1621.24 SPEAKER_08  Geometric is...
1621.24 1622.50 SPEAKER_08  The geometric shape is just a...
1622.50 1623.30 SPEAKER_06  We're not having...
1623.30 1624.80 SPEAKER_06  Crenching the fuck out of this space.
1625.74 1629.84 SPEAKER_06  The Generator is like a metaverse you can physically experience.
1631.52 1633.08 SPEAKER_03  You mean the verse?
1633.30 1634.70 SPEAKER_03  The original verse?
1634.80 1636.10 SPEAKER_03  The regular verse?
1636.46 1637.50 SPEAKER_08  The normal...
1637.50 1638.88 SPEAKER_08  It's like the normal world.
1639.50 1640.06 SPEAKER_08  R.I.P.
1640.14 1643.08 SPEAKER_08  Georges Barre, you would have loved the experiential space.
1643.08 1648.18 SPEAKER_07  That sounds like very threatening though because it's like the only way to differentiate is like it's a world where you can experience it without legs.
1649.24 1650.44 SPEAKER_07  Which I don't know if that's like...
1650.44 1650.64 SPEAKER_08  I'm just kind of misery.
1651.20 1653.62 SPEAKER_08  The special vessel just breaks all of your legs
1653.62 1655.72 SPEAKER_06  on the way out. You'll have residences.
1655.96 1656.34 SPEAKER_06  And guess what?
1656.38 1657.30 SPEAKER_06  This is again...
1657.30 1661.58 SPEAKER_06  Every area of Neon is just a different configuration of the following.
1662.70 1667.24 SPEAKER_06  Residences, hotels, cinemas, museums, high-end shopping, dining.
1667.96 1671.66 SPEAKER_08  Why do I even want to go to the dining district now?
1672.04 1672.18 SPEAKER_08  You know?
1672.26 1677.34 SPEAKER_06  Yeah, well, it's like a dinner that you can experience in a physical metaverse on a geometric patio.
1678.12 1682.86 SPEAKER_08  Some days, it's almost not worth getting in the special vessel to go to the experiential space.
1683.00 1683.16 SPEAKER_08  You know?
1683.20 1684.62 SPEAKER_08  I can just get dinner in the dinner district.
1684.74 1690.70 SPEAKER_06  And the generator, which is the research lab that will attract creators to come and interact and new ideas to emerge.
1690.88 1692.48 SPEAKER_06  We've never had a new idea.
1692.64 1702.46 SPEAKER_06  I'm so glad that we had the line and now we have the big stick as well into the earth that's accessed through this special tunnel that's a real physical metaverse.
1702.78 1702.94 SPEAKER_03  Yeah.
1703.26 1704.42 SPEAKER_03  Saudi dwarf fortress.
1704.52 1709.38 SPEAKER_03  They've employed a Dutch woman to design their canal-based city of the future and I, for one, know.
1709.42 1711.58 SPEAKER_07  What if you wanted to have a gold leaf burger underwater?
1712.26 1714.72 SPEAKER_07  That sort of seems to be like the only appeal of that.
1714.84 1720.50 SPEAKER_03  Yeah, what if you were Poseidon, king of the sea, and you wanted to enjoy royal treats such as the gold leaf burger?
1721.16 1734.80 SPEAKER_08  Just like 10 years from now, in whatever situation you're in, you're going to be dimly aware like on BBC News or whatever, there's going to be a story that's like Salt Bay, others killed in like a unique vessel accident.
1735.58 1737.50 SPEAKER_08  Entombing trillions, you know?
1737.72 1742.32 SPEAKER_07  Salt Bay, Hezbollah, like, I don't know, fucking...
1742.32 1742.42 SPEAKER_07  Yeah,
1742.52 1750.52 SPEAKER_08  Conor McGregor tried to record a TikTok in the special vessel in a way that disabled it and entombed Mohammed bin Salman.
1750.56 1754.48 SPEAKER_03  We warned Conor McGregor not to anger Poseidon, the god of the she, but he said he could take it.
1754.88 1757.42 SPEAKER_03  He said, I'm the notorious MMA, who's Poseidon?
1757.48 1759.94 SPEAKER_03  I said, well, he's the god of the she, that's his whole thing, he's got a trident.
1760.06 1761.26 SPEAKER_03  And he said, well, I've never heard of him.
1761.32 1763.84 SPEAKER_03  I said, well, that's because you're a very stupid man, but...
1763.84 1770.86 SPEAKER_08  subsisting on, like, gold leaf burgers until those run out in the vault from Dead Money.
1771.12 1771.30 SPEAKER_08  Yeah.
1771.40 1772.88 SPEAKER_08  I, Jesus Christ.
1772.98 1773.40 SPEAKER_08  Alright, alright, alright.
1773.62 1779.90 SPEAKER_06  I think that's, that's about all we have time for for our first half, but my god, they are back.
1779.96 1782.74 SPEAKER_06  Like, with the Willy Wonka elevator is my favourite part.
1782.78 1789.26 SPEAKER_06  It's not in this press release, but in another press release, they were like, oh yeah, and we're gonna have an elevator that moves in, like, every axis.
1789.56 1791.04 SPEAKER_03  They're like, they're a lot like Trump.
1791.16 1793.44 SPEAKER_03  They're, like, constantly needlessly escalating.
1793.44 1800.28 SPEAKER_03  Like, every Neon press release is just that, that time when Trump said, I know a big guy, one of the biggest in the world, actually.
1800.98 1804.02 SPEAKER_05  Like, that is every sentence of every Neon press release.
1804.02 1804.20 SPEAKER_03  Yeah, it's great.
1804.54 1809.96 SPEAKER_05  We're gonna have an elevator, it's gonna move in any direction, including backwards in time, actually, yes,
1809.96 1817.52 SPEAKER_06  it's a beautiful elevator. Alright, so that's, that's a quellum, we're excited to, look, I'm, I, I'm sad that it's the last Neon region.
1817.82 1824.04 SPEAKER_06  Um, I hope it is, because Neon is like, an, is a horribly exploitative project that should be shut down.
1824.38 1827.28 SPEAKER_03  Yeah, they killed people to do all of this shit.
1827.66 1828.62 SPEAKER_03  Like, yeah, Conor McGregor.
1828.70 1830.36 SPEAKER_03  Yeah, but, for pure,
1830.40 1837.04 SPEAKER_06  for pure fascinating interest to see what they come up with next, I am excited to see what they come up with next, if they come up with anything else.
1837.56 1840.22 SPEAKER_06  One day, we're gonna have to report on whether or not it's actually being built.
1840.76 1842.04 SPEAKER_06  Uh, that is not this day.
1842.14 1843.26 SPEAKER_06  More renderings.
1843.34 1845.78 SPEAKER_06  Yeah, we're gonna do a field trip to the Neon site.
1845.90 1847.24 SPEAKER_06  I don't wanna do a field trip to the Neon site.
1847.24 1847.50 SPEAKER_06  I don't know.
1847.50 1848.20 SPEAKER_06  We're gonna get better.
1848.54 1848.76 SPEAKER_06  I,
1849.06 1850.50 SPEAKER_03  yeah. I like my legs.
1851.16 1856.14 SPEAKER_06  Uh, so, anyway, I think I'm gonna hand over which one of us is the least killable
1856.14 1860.18 SPEAKER_03  in Saudi Arabia. Somehow it's me.
1860.66 1861.50 SPEAKER_03  Unexpectedly.
1861.50 1865.68 SPEAKER_03  You would instinctively say Hussein, but it is, it is a counterintuitive land.
1865.88 1866.18 SPEAKER_07  Mm.
1866.46 1874.56 SPEAKER_07  Well, I would, I would probably say that, like, uh, yeah, they, they probably don't take very kindly to Shias, which is why I would say, Alice is probably the safest person.
1874.90 1875.36 SPEAKER_02  No, actually,
1875.36 1884.76 SPEAKER_07  I disagree. I feel like, I feel like the thing that you can get away with in lots of the world is to just be like a very eager and well-meaning white guy.
1885.72 1890.94 SPEAKER_07  Which is to say, but I feel like Riley actually might be the one who survives and converts by the end of that.
1891.06 1891.34 SPEAKER_08  Yeah.
1891.52 1898.02 SPEAKER_08  I, I think Riley, when you get in situations, you're just kind of like, you style it out by being affable white guys.
1898.02 1898.26 SPEAKER_07  Yeah.
1898.26 1898.54 SPEAKER_07  Oh no.
1898.66 1900.46 SPEAKER_07  And you love treats and they love treats.
1900.60 1902.04 SPEAKER_07  And I feel like you could bond with those things.
1902.04 1902.14 SPEAKER_03  Yeah.
1902.14 1905.16 SPEAKER_03  Riley drinking a flight of very expensive grape juices.
1905.36 1905.86 SPEAKER_03  Someone,
1906.04 1910.98 SPEAKER_07  someone would say to you, like, do you want to go into this like underwater, uh, underwater bar?
1911.48 1915.62 SPEAKER_07  Uh, you could, there's like a very unique microclimate for all the secret wine that we've got.
1915.80 1918.84 SPEAKER_07  And I'd be like cask of a Monty auto me immediately.
1919.50 1921.22 SPEAKER_02  I'm a real convert to dates.
1921.30 1922.50 SPEAKER_06  I've become a date guy.
1922.72 1926.46 SPEAKER_06  I do like dates, but this is actually, this is true.
1926.50 1933.38 SPEAKER_06  Cause you were saying, we were talking before the show Milo and you were talking about like some people who'd been kind of like snide and shitty to you.
1933.38 1938.46 SPEAKER_06  And I, my response was no one has ever been snide or shitty to me in my entire life.
1938.88 1940.52 SPEAKER_06  And then I was like, counterpoint,
1940.64 1942.70 SPEAKER_03  you just haven't noticed, which is why I'm safe.
1942.70 1943.78 SPEAKER_03  Which is his superpower.
1943.78 1944.22 SPEAKER_03  Yeah.
1944.22 1944.58 SPEAKER_08  Yeah.
1944.94 1945.34 SPEAKER_08  Yeah.
1945.44 1945.80 SPEAKER_08  Yeah.
1945.80 1946.00 SPEAKER_08  Yeah.
1946.06 1948.06 SPEAKER_08  You're, you're the sort of like aquascutum oaf.
1948.22 1949.86 SPEAKER_08  I already don't remember the name of the place.
1950.52 1950.88 SPEAKER_08  All right.
1951.06 1952.34 SPEAKER_03  Well, yeah.
1952.56 1953.00 SPEAKER_02  I look,
1953.40 1955.00 SPEAKER_08  aquascutum is a fine. Yeah.
1955.18 1955.42 SPEAKER_08  Yeah.
1955.42 1957.84 SPEAKER_08  The aquascutum oaf is wearing a really nice coat.
1958.30 1958.70 SPEAKER_03  Aquascutum.
1959.00 1959.40 SPEAKER_03  All right.
1959.40 1959.76 SPEAKER_03  All right.
1959.76 1960.08 SPEAKER_03  All right.
1960.08 1960.86 SPEAKER_06  This is getting silly.
1961.02 1964.34 SPEAKER_06  I'm going to hand over to the second half for our conversation with Dan McQuillan.
1964.90 1966.34 SPEAKER_06  See you in a few moments, everyone.
1966.34 1975.28 SPEAKER_06  Hi, everyone from the first half.
1975.36 1977.54 SPEAKER_06  It is me introducing you to the second half.
1977.56 1978.44 SPEAKER_06  It's the second half.
1978.44 1980.58 SPEAKER_06  What a great first half it was, may I say.
1981.68 1984.14 SPEAKER_06  And we have certainly already recorded it.
1984.20 1986.08 SPEAKER_06  Who could forget such fantastic jokes?
1986.10 1986.22 SPEAKER_06  Yeah.
1986.32 1988.44 SPEAKER_07  I'm nostalgic for the first half personally.
1989.16 1990.78 SPEAKER_07  I wish I could relive it again.
1991.02 1992.10 SPEAKER_06  Return with a V.
1993.54 1995.92 SPEAKER_06  Return with a V to 20 minutes ago.
1995.92 1996.62 SPEAKER_06  That's right.
1997.00 1999.44 SPEAKER_06  I want to introduce our guest for the second half.
1999.64 2001.44 SPEAKER_06  It is, he's a returning champion.
2001.44 2012.64 SPEAKER_06  In fact, it is Dan McQuillan, author of resisting AI and anti-fascist approach to artificial intelligence, and also the lecturer in creative and social computing at Goldsmiths.
2012.68 2013.52 SPEAKER_06  Dan, welcome back.
2013.82 2014.78 SPEAKER_00  Oh, I'm very glad to be back.
2014.96 2017.90 SPEAKER_00  And to know that my book has a tongue twister title is even better.
2019.24 2019.64 SPEAKER_06  Excellent.
2019.72 2020.20 SPEAKER_06  May I say, Riley,
2020.24 2020.98 SPEAKER_03  you did that very smoothly.
2021.28 2022.12 SPEAKER_06  Yeah. You know what?
2022.12 2025.54 SPEAKER_06  That's the smoothest bar intro to a second half I have ever done.
2025.54 2027.46 SPEAKER_06  And I still tripped over one of the words.
2027.66 2029.48 SPEAKER_06  Can we get smooth operator dropped in?
2029.72 2030.96 SPEAKER_06  Yes, that's, that's right.
2031.04 2032.64 SPEAKER_06  I'm also Carlos Sainz.
2033.60 2055.20 SPEAKER_06  So, what we wanted to talk with, with Dan about was, well, it was a few things, but this was sort of spurred by an article that you are writing and probably maybe out by the time that this is out, that essentially states that, look, the Fujitsu post office crisis, we are going to have 10,000 of those every 20 minutes.
2055.20 2062.32 SPEAKER_06  the more the public sector and sort of semi-public sector is run on generative AI.
2062.74 2064.00 SPEAKER_00  Yeah, that's it in a nutshell.
2064.22 2073.40 SPEAKER_00  And it is out, and it's out in Computer Weekly, which I'm chuffed to say, because obviously Computer Weekly, we're the mag that, you know, really plowed the line in terms of that particular scandal.
2074.44 2074.66 SPEAKER_06  Hmm.
2075.62 2090.20 SPEAKER_06  And one of the things I wanted to hang this conversation off of, I think, was not just that article, but I've been doing some reading around different publications, such as from the IPPR, the Australian government in one sense.
2090.56 2091.78 SPEAKER_06  I think it was the Queensland government.
2092.26 2094.88 SPEAKER_06  Oh, they've just found out what a computer is up there.
2094.92 2095.58 SPEAKER_06  Yeah, that's right.
2095.96 2104.54 SPEAKER_06  As well as I've been reading some recent publications in the IMF, and I have watched every single Davos video and transcribed the interesting bar.
2104.80 2107.00 SPEAKER_08  Well, you're already going to do that, to be fair.
2107.26 2108.28 SPEAKER_06  Yes, that's right.
2108.56 2108.86 SPEAKER_06  That's right.
2108.90 2110.56 SPEAKER_06  Look, everyone goons in their own way.
2111.02 2111.30 SPEAKER_00  That's right.
2111.36 2113.78 SPEAKER_00  Transcribing the interesting parts presumably didn't take very long, I mean.
2115.18 2117.32 SPEAKER_06  Well, it's what we might call an executive summary.
2118.60 2125.38 SPEAKER_06  And all of that, I think, has given us a kind of snapshot of the elite consensus on AI.
2125.88 2136.30 SPEAKER_06  And I think as one of the few people in the academy, thinking about the actual consequences of that elite consensus on AI, I figured there was no one better to talk about that with than you.
2136.48 2137.40 SPEAKER_00  Well, I'm flattered.
2137.56 2138.04 SPEAKER_00  Thanks very much.
2138.40 2138.90 SPEAKER_00  Happy to.
2139.90 2140.10 SPEAKER_06  Yeah.
2140.20 2144.24 SPEAKER_06  So before I start, though, do you want to just give a quick pricey of the logic?
2144.42 2148.66 SPEAKER_06  I'm sure most of our listeners will be able to intuit it, but let's just go into it anyway.
2149.02 2157.70 SPEAKER_06  The logic behind your article that says, an AI enabled public sector means lets a thousand Fujitsu's bloom, essentially.
2157.70 2158.58 SPEAKER_00  That's funny.
2158.66 2160.86 SPEAKER_00  That wasn't my working title, more or less.
2161.50 2164.08 SPEAKER_00  And that came from the Queensland government's report.
2165.40 2171.24 SPEAKER_00  No, the Australian Royal Commission uses terms like venal and incompetent and, yeah, other words like that.
2171.28 2173.58 SPEAKER_00  So I really dug back on the word book there.
2174.10 2174.24 SPEAKER_00  Yes.
2174.34 2177.90 SPEAKER_00  I mean, the article's basically, it's pivoted on a few simple points.
2178.02 2179.96 SPEAKER_00  One is that AI is very fallible.
2180.32 2181.24 SPEAKER_00  In fact, it's more than fallible.
2181.40 2188.18 SPEAKER_00  You know, complex computer systems are fallible, but it's, it's pitched on the starting point being the AI is foundationally fallible.
2188.46 2191.52 SPEAKER_00  You know, it's, it doesn't do anything other than correlations, even in deep learning.
2191.86 2194.66 SPEAKER_00  And we all know when it gets to large language models, it's making stuff up.
2194.74 2199.90 SPEAKER_00  So it is foundationally flawed or foundationally untruthful.
2200.64 2216.10 SPEAKER_00  Plus you get this kind of quirk that because of the millions or even billions of weights inside these models, it's basically impossible to sort of work backwards and figure out exactly which piece of input or which weighting it was that might have led to this, sort of crucially unfortunate false prediction.
2216.64 2219.68 SPEAKER_00  So it basically kiboshes any idea of due process.
2220.10 2222.04 SPEAKER_00  So I wanted to kind of rehash those ideas.
2222.20 2225.94 SPEAKER_00  You know, this is a very bad system to build any conclusions around.
2226.50 2237.52 SPEAKER_00  But what we're interested to be more about the whole scandal was, I mean, being soaked in it as we all are, that there was this kind of ping pong between people who said, yeah, this is a disastrous IT exercise.
2237.52 2240.86 SPEAKER_00  And people who said, well, this is appalling, cruel management.
2240.86 2247.48 SPEAKER_00  And to me, it just came across as exactly those two things, you know, indivisibly and non-dually.
2247.68 2249.82 SPEAKER_00  You know, that's because that's how I understand AI.
2249.96 2251.38 SPEAKER_00  And it's not simply a technical system.
2251.46 2254.32 SPEAKER_00  It's not simply a form of social organizational construction.
2254.48 2257.34 SPEAKER_00  It is exactly these two things, fused and indivisible.
2257.92 2264.38 SPEAKER_00  And what does it do when it becomes this joint enterprise between, you know, tech and bureaucracy?
2264.38 2265.82 SPEAKER_00  It becomes a machine for cruelty.
2266.56 2268.98 SPEAKER_08  I'm so excited to see what else we can build this into.
2268.98 2274.88 SPEAKER_08  There are so few areas of British public life left, which aren't like filled with needless cruelty.
2275.44 2280.54 SPEAKER_08  And, you know, I, I'm really excited to find out what they are and then make them much worse.
2281.10 2283.30 SPEAKER_03  There are two ways you can come up with the statement.
2283.38 2284.82 SPEAKER_03  AI is a machine for cruelty.
2285.16 2291.42 SPEAKER_03  You can either do lots of academic research on the matter as Dan has, or you can use the every parcel chat.
2292.62 2293.94 SPEAKER_03  Radio four book me.
2293.94 2307.20 SPEAKER_06  One of the things I was, um, I was interested in, right, is the think tanks that are being listened to by the sort of presumptive, um, by the sort of, by, by Starmer and sort of assuming that he'll, he'll take it.
2307.28 2307.74 SPEAKER_06  Right.
2308.22 2314.76 SPEAKER_06  What they're saying about AI is probably what he's going to be listening to and what we can therefore expect him to do.
2314.88 2315.80 SPEAKER_06  The ideas on the table.
2315.90 2316.02 SPEAKER_06  Yeah.
2316.46 2317.08 SPEAKER_06  Yeah, exactly.
2317.20 2326.36 SPEAKER_06  When he tries to rebuild the British public sector and the IPPR report I have in front of me is probably the most progressive quote unquote of those that will be on the table.
2326.84 2337.74 SPEAKER_06  Um, and they have a report that says like it will take two terms, um, to repair the British public sector to have it even be taking over and not actively deteriorating of active funding.
2338.06 2341.90 SPEAKER_06  And the IPPR further says much of that will have to happen.
2341.98 2345.72 SPEAKER_06  And there's a whole box on it in the report by quote, freeing up the front line through automation.
2345.72 2346.86 SPEAKER_06  So I'm going to read you what they say.
2347.36 2350.20 SPEAKER_06  Automation will change the profile and nature of work in public services.
2350.20 2353.16 SPEAKER_06  In many cases, the nature of jobs will change rather than disappear.
2353.58 2359.90 SPEAKER_06  And indeed there is potential for routine administrative tasks to be supported by technology in a way that frees up staff for more relational work.
2360.02 2361.34 SPEAKER_06  Now let's just stop there.
2361.42 2382.74 SPEAKER_06  That is something that a claim that is made constantly that by allowing this unimportant busy work that somehow mandated, um, for more or less every public sector employee to allow that to be done by a large language model, they'll be able to do the things that a large language model can't do, which is relate to people, even though we're also being told that large language models are amazing at relating to people.
2382.74 2394.98 SPEAKER_06  But I think we all know if you've seen like any Ken Loach movie recently, we all know that it is actually the unimportant bureaucratic mundane stuff that routinely destroys people's lives.
2395.28 2395.32 SPEAKER_08  Hmm.
2395.72 2396.22 SPEAKER_08  Yeah, absolutely.
2396.72 2404.34 SPEAKER_03  And also anything simple enough to be done reliably by AI was already simple enough to be done by a computer.
2404.34 2410.80 SPEAKER_03  Like it's very easy to like automate accounts and stuff with just like normal software that existed 10 years ago.
2411.02 2413.86 SPEAKER_03  Like it's like, yeah, but that's not the future and that's not exciting.
2414.02 2417.46 SPEAKER_03  What they want to do is automate stuff that they can't actually automate.
2417.60 2419.88 SPEAKER_03  But like, what if stuff did just didn't work?
2419.90 2420.64 SPEAKER_03  That would be cheaper.
2421.20 2422.30 SPEAKER_00  It's very sad actually.
2422.46 2432.46 SPEAKER_00  And because, you know, this is clearly a scam or a, I think maybe more like a shock doctrine, you know, it's a way of restructuring things under, under the guise of a sense of urgency, but it is really sort of sad to talk to people.
2432.54 2440.22 SPEAKER_00  I don't get out much, but I talk to people who talk to people who talk to doctors, who talk to nurses, who talk to teachers and sort of ask them, you know, what do you think about this AI stuff?
2440.28 2443.46 SPEAKER_00  And that's for me would be the sort of prototypical frontline for resistance.
2443.46 2446.10 SPEAKER_00  And actually a lot of those people are just like, yeah, I don't know.
2446.16 2446.82 SPEAKER_00  It might be a good idea.
2446.88 2451.86 SPEAKER_00  It might help for exactly the same reasons that you said, it might take some of the burden off, but it's because that situation has been constructed.
2452.54 2454.18 SPEAKER_00  You know, they're so burnt out.
2454.28 2459.90 SPEAKER_00  They're so close to collapse all the time that some idiot comes along with something that sounds like it might take a bit of the pressure off.
2460.36 2463.02 SPEAKER_00  And, you know, they, they're certain, they're kind of basically for it.
2463.10 2468.96 SPEAKER_00  I mean, they're certainly not in a position of digging into resistance and it's a, it's obviously a complete con.
2469.40 2471.78 SPEAKER_00  You know, these things never free up anybody's time.
2471.88 2476.08 SPEAKER_00  If anything, they always create more busy work to try and fix the things that they don't do properly.
2476.30 2479.30 SPEAKER_00  And they don't do them properly because they don't actually do any of that relating stuff.
2479.38 2490.24 SPEAKER_00  And relating is what really makes the world go round in any of these, particularly in these key public service professions that have some aspect of, caring about what you do and caring for people involved in them.
2490.82 2502.32 SPEAKER_00  And, you know, the thing I find is that, you know, in higher education is that we've been sort of pre-massage to be, you know, susceptible to this stuff because already the whole system is based on metrics.
2502.50 2505.30 SPEAKER_00  It's based on optimized throughputs and so on and so forth.
2505.38 2507.26 SPEAKER_00  Basically we're already an algorithm of some kind.
2507.38 2513.64 SPEAKER_00  We've already been the process of reductive, of reduction of what we do has more or less already happened.
2513.64 2523.58 SPEAKER_00  Now you come along and add the capstone of AI, which simply sort of, well, it's literally accelerationist, but it just accelerates it, you know, in that direction, but into deep space.
2524.16 2539.60 SPEAKER_00  I mean, the thing that makes me really, really sad is reading about, as I was this afternoon, just on the news about kids who have to sit in their classrooms with their coats on, you know, because their port-a-cabin can't be fixed because, and I'm really struggling to see how AI is going to make any difference to that.
2539.60 2540.04 SPEAKER_00  Uh,
2540.82 2543.00 SPEAKER_06  well, uh, I could, I could help you with that one.
2543.14 2543.28 SPEAKER_06  Cool.
2543.48 2543.52 SPEAKER_06  Yeah.
2543.58 2544.44 SPEAKER_06  I'll sort of skip ahead.
2544.46 2553.00 SPEAKER_08  When the sort of like rack concrete roof collapses and crushes a child, the AI can write a very convincing, well, can write an approximately convincing letter home to the parents.
2553.30 2558.16 SPEAKER_00  There was, there was, that was one of the first things chat GPT was called up for was an American university that had a mass shooting.
2558.44 2562.50 SPEAKER_00  They, they sent out an email condolence and reassurance to parents.
2562.50 2564.86 SPEAKER_00  And it was actually had chat GPT's prompt line at the bottom.
2565.28 2565.54 SPEAKER_00  Amazing.
2565.66 2568.50 SPEAKER_06  As a large language model, I think you're cool and shouldn't come into school tomorrow.
2568.50 2572.24 SPEAKER_06  Um, so no, the, uh, this is actually from later in my notes.
2572.28 2575.96 SPEAKER_06  It was when I transcribed the interview with the UAE minister for AI.
2576.28 2578.48 SPEAKER_06  Of course the UAE has a minister for AI.
2578.52 2578.74 SPEAKER_08  Yeah.
2578.76 2580.32 SPEAKER_08  Although I'm not optimistic on this one.
2580.38 2585.62 SPEAKER_08  I don't think that the UAE is going to be able to exploit a form of labor whose passport it can't take, you know?
2585.62 2586.82 SPEAKER_06  Yeah.
2587.22 2593.46 SPEAKER_06  And he says, he says that, uh, governments can learn from how the UAE is implementing AI.
2593.78 2611.56 SPEAKER_06  And they say we have 200 nationalities living in a densely populated area, which means our data set is unique and we have cutting edge infrastructure and our loose regulatory regime allows us to move much more fat, much faster than a country with more bureaucracy, suggesting that we want to deploy AI in oil and gas to increase quality of life and reduce the dangers of climate change.
2611.66 2611.78 SPEAKER_06  What?
2613.28 2613.68 SPEAKER_06  Sorry.
2614.40 2614.80 SPEAKER_08  Okay.
2615.46 2620.34 SPEAKER_08  What, what they've done there is they've failed to hook up to fundamentally obscuring mechanisms.
2620.34 2626.10 SPEAKER_08  It seems to me like we already have a thing that we're going to pin all of our hopes for climate change on that doesn't work.
2626.14 2631.72 SPEAKER_08  And that's carbon capture, but they're not, he's not even saying like, Oh, we're going to use AI to like invent carbon capture and storage.
2632.00 2632.34 SPEAKER_08  Instead.
2632.44 2640.68 SPEAKER_08  It's like, we're going to use it to make oil and gas extraction, uh, good for the environment somehow, which I, I'm curious how that's supposed to work.
2641.46 2644.76 SPEAKER_06  So this is kind of a double point that, uh, that he's making.
2644.76 2649.16 SPEAKER_06  He's saying, look, regulating the dangers of AI, because he's talking about Skynet.
2649.28 2649.56 SPEAKER_06  Yeah.
2650.16 2655.58 SPEAKER_06  Um, is going to require cross country cooperation, like regulating the dangers of climate change.
2655.86 2662.82 SPEAKER_06  Uh, and then he says, and the UAE can lead the lead on both because we're using one to fight the other.
2662.98 2663.44 SPEAKER_06  Great.
2664.04 2664.26 SPEAKER_03  Yeah.
2664.26 2666.14 SPEAKER_03  AI is a form of dumb bullshit.
2666.14 2671.14 SPEAKER_03  And here in the UAE, we are the world's foremost experts on doing all kinds of dumb bullshit.
2671.62 2673.64 SPEAKER_03  We built a museum of the future.
2674.42 2678.42 SPEAKER_03  Every rich Russian goes on holiday here to buy shoes bigger than their head.
2678.72 2679.84 SPEAKER_03  We can do this.
2680.92 2683.58 SPEAKER_06  So, sorry, back to, uh, back to the IPPR report.
2684.34 2690.60 SPEAKER_06  Um, they say that jobs can be in the public sector can be understood in three broad categories with different relationships to automation.
2691.12 2693.80 SPEAKER_06  So administrative or operative roles, which are repetitive and predictable.
2693.80 2705.20 SPEAKER_06  And again, where a lot of the misery comes from, by the way, in finance, HR and procurement, some 60 to 80% of the tasks are considered automobile, uh, with net long-term savings estimated at more than 30%.
2705.20 2710.22 SPEAKER_06  Interactive or frontline roles, which require a high degree of personal interaction could be supported by the technology.
2710.22 2719.26 SPEAKER_06  And the operational costs of public facing services could be cut by one third by automation, while achieving better service delivery, counter fraud, and increased efficiency at the same time.
2719.26 2726.80 SPEAKER_06  And finally, cognitive roles that require strategic thinking and complex reasoning could be supported by technology such as decision augmentation.
2726.96 2728.62 SPEAKER_06  These are finance directors and chief executives.
2729.08 2734.50 SPEAKER_06  However, the report does not say that those could, that those roles could be cut at all, just that they could be supported.
2735.08 2740.72 SPEAKER_06  So again, like, this goes to, in fact, one of the things that the IMF was saying, I've read a lot of PDFs for this.
2740.72 2758.42 SPEAKER_06  Um, the IMF in their sort of, in their writing on AI was essentially saying that they see that, like so many newly deployed technologies, that this is going to, um, be a boon for people already on high pay and a real struggle for people on low pay.
2758.54 2771.34 SPEAKER_06  But because it's the IMF, they of course have to say, unless the right kind of regulatory and training regime can be put in, and then a, you know, subsistence farmer is going to be able to start the next Apple by harnessing enough, like, um, uh, you know, chat GPT based, um, uh, agents.
2771.44 2778.16 SPEAKER_08  So, so, so your sort of like consultancy job becomes even less real as you're just kind of manipulating an AI.
2778.76 2782.54 SPEAKER_08  Um, yeah, uh, but it still exists and it's still very highly paid.
2782.72 2793.96 SPEAKER_06  And between these, these sort of, I think visions, right, generated by sort of think tanks, international organizations, you can kind of see, and also this is supported by the way, by what people were saying at Davos.
2794.14 2796.80 SPEAKER_06  I mean, the theme of Davos was called rebuilding trust.
2796.80 2801.50 SPEAKER_06  But if you look at what, um, the actual CEOs are saying, it's basically a threat.
2802.32 2803.06 SPEAKER_08  It's, it's, it's interesting.
2803.14 2805.42 SPEAKER_08  Imagining this sort of like high income stuff as a cope, right?
2805.44 2808.72 SPEAKER_08  To be like, well, you know, this wire shrinking is never going to exclude me.
2809.20 2812.64 SPEAKER_08  Um, it's never going to come from my bullshit job.
2812.90 2813.82 SPEAKER_06  What's the nature of that threat?
2813.92 2814.34 SPEAKER_06  What'd you say?
2814.44 2822.40 SPEAKER_06  The threat basically, and this is, um, the CEO of IBM says, we assume that the industry will generate 4 trillion in annual revenue by 2029.
2822.78 2823.94 SPEAKER_06  Anyone can make up a number.
2823.94 2827.06 SPEAKER_06  But this was in an interview with Zannie Minton Bedos from the Economist.
2827.72 2828.90 SPEAKER_06  Sorry, excuse me.
2829.66 2830.46 SPEAKER_06  Say again.
2831.32 2833.62 SPEAKER_06  Yeah, this is an interview with Zannie Minton Bedos.
2833.76 2834.20 SPEAKER_06  Oh, excuse me.
2834.24 2834.80 SPEAKER_06  I misread that.
2835.04 2838.30 SPEAKER_06  This is an interview with Percocet Minton Bedos from the Economist.
2839.74 2840.96 SPEAKER_06  Lil Zannie Minton Bedos.
2841.66 2843.00 SPEAKER_06  Lil Zan is really grown up.
2843.06 2845.56 SPEAKER_06  Just like absolutely drawling through an interview.
2846.50 2848.74 SPEAKER_06  This is an interview with Kamala Harris Minton Bedos.
2848.88 2849.34 SPEAKER_06  That's right.
2849.34 2856.84 SPEAKER_06  Um, so, so, uh, the CEO of IBM said that the interview was, that the industry is expected to generate 4 trillion in revenue by 2029.
2857.34 2858.58 SPEAKER_06  And what tasks will be touched?
2858.68 2859.68 SPEAKER_06  He was, he was asked.
2859.98 2865.08 SPEAKER_06  He says, we'll see 20X productivity for a programmer who embraces AI, customer services of all kinds.
2865.20 2869.46 SPEAKER_03  Why is this written like the Quran for a programmer who embraces AI?
2870.74 2873.64 SPEAKER_03  He will receive, he'll be received in the gardens of Janna.
2873.66 2875.50 SPEAKER_08  And that's a clear signs for people who believe.
2875.50 2875.68 SPEAKER_03  Yeah.
2876.10 2876.84 SPEAKER_03  Well, I mean,
2876.92 2879.38 SPEAKER_08  because it is fundamentally an appeal to belief, right?
2879.40 2881.38 SPEAKER_08  And a promise that you will be rewarded for your belief.
2882.02 2882.80 SPEAKER_08  An appeal to submission.
2883.12 2883.52 SPEAKER_06  Yes.
2884.38 2887.32 SPEAKER_06  He says, um, there will be a wide area called digital labor.
2887.46 2888.94 SPEAKER_06  It's not necessarily job displacement.
2889.14 2892.02 SPEAKER_06  If you embrace AI, you make yourself more productive.
2892.36 2894.30 SPEAKER_06  If not, you will find you do not have a job.
2894.38 2897.48 SPEAKER_08  This, this is just Rocco's basilisk with extra steps, man.
2897.56 2907.26 SPEAKER_08  I, I, I like it when it's just an unalloyed dumb guy like Elon Musk being like, uh, you know, Skynet's going to enslave me if I don't, uh, you know, tell Grimes that I'm nice.
2907.84 2908.72 SPEAKER_03  No, sorry.
2908.82 2910.26 SPEAKER_03  I have to take the opposing view.
2910.36 2911.54 SPEAKER_03  I am now reassured.
2911.74 2916.30 SPEAKER_03  If IBM says it's good, then it must be because IBM would never use computers for evil.
2916.70 2918.38 SPEAKER_03  I have not Googled them.
2920.38 2923.62 SPEAKER_06  So, but again, what this, this paints us the picture, right?
2923.62 2934.28 SPEAKER_06  which is that the public, which is the plan is to make the public sector more treacherous and unreliable for people to work in it and rely on it.
2934.60 2942.06 SPEAKER_06  And that more people are probably going to need to rely on it because unless, because we know reskilling does not work.
2942.06 2952.22 SPEAKER_06  We know that no, like you did not, we did not manage to retrain, um, like people who lost their jobs in the nineties to become creative directors and programmers and stuff.
2952.34 2953.18 SPEAKER_06  It doesn't,
2953.18 2957.42 SPEAKER_08  it doesn't work because we didn't replace them and we didn't do it basically. Yeah.
2957.50 2965.78 SPEAKER_08  Uh, we just kind of said that we might do, uh, and, and just kind of assumed that like everyone who had been a coal miner was going to be a, you know, JavaScript developer.
2966.08 2968.10 SPEAKER_08  Well, we suggested to them that they do it.
2968.10 2968.28 SPEAKER_08  Yeah.
2968.42 2969.40 SPEAKER_06  And then they didn't,
2969.46 2971.38 SPEAKER_08  which is a huge failure of initiative on their part.
2971.58 2971.82 SPEAKER_06  You know? Sorry.
2972.02 2980.24 SPEAKER_06  So I should say retraining might work if anyone would ever try it, but we know we're not going to do it because any retraining initiative is just going to be run by AI.
2980.40 2999.22 SPEAKER_08  Well, that's, that's, I mean, um, Dan, this is exactly your point about it being a managerial system as much as anything is that like, uh, the second you even try to sort of like learn to use it now that you've been forced to, uh, the sort of, the logic underpinning it is, uh, more managerialism, worse, more unpredictable.
2999.84 2999.90 SPEAKER_00  Yeah.
2999.90 3008.12 SPEAKER_00  I mean, I mean, I mean, several worrying things about what you said, one, that latter point being that it really seems to fit with a sort of new, new labor model of how to run the country.
3008.26 3015.58 SPEAKER_00  I mean, I find that really disturbing, but just going back to your description of the, you know, what the sort of threat is or how they imagine even the changes of jobs.
3015.58 3021.98 SPEAKER_00  I think something that didn't come out to be before listening to those kinds of descriptions so clearly was how eugenicist the whole thing is.
3022.08 3029.34 SPEAKER_00  I mean, they're still very much fixated on a grading of things based on the sort of cognitive function that they consider to be involved in it.
3029.34 3039.88 SPEAKER_00  And the sort of low level boring and demeaning things are the most disposable, the most automatable, and only the important decision-making, CEO levels, stuff, whatever is going to be retained in some way.
3039.98 3057.88 SPEAKER_00  And that's, is that, that of course is a, you know, a sort of structurally hypercapitalist way of looking at things, but it's also very concerning, you know, going back to the sort of IBM link there, you know, without the sort of joke involved, that the element of these systems is in an increasingly crisis written time, they're going to be used for deciding who's disposable one way or another.
3057.88 3058.60 SPEAKER_06  Hmm.
3059.10 3065.28 SPEAKER_06  And, and this is something that, that sort of fits in with both the way the UAE does things and the way we do things.
3065.38 3065.62 SPEAKER_08  Hmm.
3065.84 3066.98 SPEAKER_08  Not so different after all.
3067.40 3067.66 SPEAKER_06  Yeah.
3067.74 3074.90 SPEAKER_06  Like if we're like the UAE is talking a great, a great game about being about constructing a responsible AI nation that they call brain.
3075.94 3076.62 SPEAKER_06  Excuse me?
3077.54 3083.24 SPEAKER_06  Look, it's obvious they're creating brain, which is a responsible nation that lives in AI in the UAE.
3083.42 3085.58 SPEAKER_06  As a Sultan tier brain in Abu Dhabi.
3085.58 3089.08 SPEAKER_08  As an actual, like it, like an offshore, like sort of outer heaven situation.
3089.68 3090.68 SPEAKER_08  I think it's a,
3090.80 3092.72 SPEAKER_06  I think it's more of a metaverse. Um,
3092.98 3095.20 SPEAKER_00  but the brain in a jar is a brain in UAE.
3095.94 3099.96 SPEAKER_06  But I mean, you can, you can very much see that we're, we're doing the same things.
3100.14 3104.54 SPEAKER_06  We are just, we have put it behind a different institutional setup.
3104.80 3104.92 SPEAKER_06  Hmm.
3105.14 3106.66 SPEAKER_08  So is Australia, right?
3106.68 3107.50 SPEAKER_08  Or at least Queensland.
3108.36 3110.52 SPEAKER_06  So this is an, this is a different thing.
3110.52 3124.64 SPEAKER_06  And this is something I did really want to come back to, which is the IPPR is, I think, giving us a kind of nakedly eugenicist look at, here are the jobs that we, where we, where we think we can save labor.
3124.78 3126.04 SPEAKER_06  We can get rid of people and stuff.
3126.04 3128.94 SPEAKER_06  And again, we know that that's just going to create more post office scandals.
3129.36 3132.50 SPEAKER_06  The Australian government, and this was sent to me by a listener on discord.
3132.98 3133.90 SPEAKER_06  I'm so happy.
3134.00 3137.86 SPEAKER_06  I checked it says this was from a series of focus groups.
3137.86 3143.46 SPEAKER_06  And now people would like to see AI united with public service.
3143.90 3150.38 SPEAKER_06  It says that specifically from the, the, this document called, and again, interesting things are contained in documents of weird and boring titles.
3150.88 3154.08 SPEAKER_06  Summary of insights from stakeholder engagements and future scenario workshops.
3154.40 3157.90 SPEAKER_06  How might artificial intelligence affect the trustworthiness of public service delivery?
3158.54 3159.68 SPEAKER_06  Now within this,
3159.82 3164.80 SPEAKER_08  every public servant is now a completely unaccountable liar, as opposed to like some of them.
3165.52 3165.72 SPEAKER_06  Yeah.
3165.72 3169.60 SPEAKER_06  So in this, right, this isn't what they plan to do.
3169.68 3178.14 SPEAKER_06  This is, they're proposing different scenarios to their people that they have in their focus group, but it's interesting to see what they think of as the scenarios that they're giving people in their focus group.
3178.22 3182.50 SPEAKER_06  If you know what I mean, they say, okay, here's one of the examples of extreme personalization.
3182.96 3189.54 SPEAKER_06  In 2026, after consultation with community and industry, the government embarked on a project to co-design public services 2.0.
3189.94 3195.92 SPEAKER_06  The aim was to integrate artificial intelligence with public services, so that delivery is automatically calibrated to suit each person's, needs.
3196.20 3205.36 SPEAKER_06  Now again, we go back, this is something that occurs in basically every document about augmenting public services with AI, mostly in the Tony Blair Institute, the other think tank Starmer listeners.
3205.62 3211.66 SPEAKER_08  Again, it's quite new labor to be like, the government won't do anything, but it will be like extremely tailored to your preferences, right?
3212.32 3216.44 SPEAKER_03  Yeah, we're going to collect exactly the bins you want in a way that's decided by a computer.
3216.82 3229.26 SPEAKER_06  The goal was to provide an outcome situated in the middle way between other models that had emerged in other countries, either letting technology lead the way in the knowledge that there may be some pain before the best model is identified, or the ultra cautious model with the minimal use of AI.
3229.86 3230.22 SPEAKER_06  Ahem.
3230.22 3235.54 SPEAKER_06  The new Serve Me system of public service delivery provides a single point of access for all government services.
3235.92 3240.96 SPEAKER_06  Users only ever need to open a single room on their personal holographic device to access government services and information.
3240.96 3247.24 SPEAKER_06  In this one room, they can do everything from enrolling children in school to getting a passport, paying their taxes, accessing the health system.
3247.62 3261.40 SPEAKER_06  The government still operates by the way of departments and agencies, but they all tap into a single suite of AI technologies, which use standardized and centralized processes and protocols to access a single constantly updating data set, seamlessly providing fully integrated public service.
3261.52 3268.78 SPEAKER_01  Oh, I've logged onto my AI room, but I can't seem to find a button for, I'm currently being torn to pieces by crocodiles in Northern Queensland.
3268.78 3269.08 SPEAKER_01  I mean,
3269.14 3272.76 SPEAKER_08  this is just PlayStation home with extra steps. Like,
3272.84 3284.04 SPEAKER_06  but what I think is really fun with a V is that they basically, they propose that the fantasy scenario is that they create a digital second Australia.
3284.82 3286.08 SPEAKER_06  Uh, I've, I've,
3286.08 3292.46 SPEAKER_08  I've provided you with this, this map that fits completely perfectly to the territory of Australia.
3292.46 3296.30 SPEAKER_08  And we can just govern that instead of the real one, a parallel Hooniverse.
3297.32 3297.80 SPEAKER_06  Amazing.
3297.80 3301.90 SPEAKER_06  I'm going to make it, I'm going to say that's, that's the episode title parallel Hooniverse.
3302.34 3305.26 SPEAKER_03  Australian Valhalla, where you can hoon all you want.
3305.48 3305.66 SPEAKER_04  So.
3305.90 3311.40 SPEAKER_04  If you die hooning, you go to Australian Valhalla, where every car's a Commodore V8U.
3311.40 3311.72 SPEAKER_04  That,
3311.82 3317.46 SPEAKER_06  that is just Mad Max Fury Road. That's just Mad Max Fury Road.
3317.58 3318.00 SPEAKER_06  You've just described.
3318.00 3320.24 SPEAKER_04  I don't know, the fucking Sheilas are in charge.
3320.68 3320.86 SPEAKER_06  Yeah.
3321.16 3321.36 SPEAKER_06  Yeah.
3321.68 3322.58 SPEAKER_06  Here's what I'm getting to, right?
3322.58 3334.40 SPEAKER_06  They say, hold on.
3334.40 3337.76 SPEAKER_08  First of all, this is the plot of the prestige.
3338.02 3338.62 SPEAKER_08  I'm pretty sure.
3339.02 3346.06 SPEAKER_08  Second of all, the sovereign citizen movement did not go completely insane and just start shooting cops for no reason.
3346.46 3353.98 SPEAKER_08  Off of a deranged sort of legal conspiracy that the government was going to invent a fictional twin U and then do all of its governing to that.
3353.98 3361.66 SPEAKER_08  Only to then have it be made real in Queensland in order to sell AI.
3363.28 3368.98 SPEAKER_00  But I've only been picking up on this myself recently and it's really quite chilling how widespread this idea of digital twins is.
3369.46 3370.50 SPEAKER_00  It's really well over the place.
3370.70 3374.56 SPEAKER_00  There are, there are UK digital twin projects that are really quite substantial.
3375.16 3380.78 SPEAKER_07  Nobody, nobody watched, because, because, and I'm sorry to bring the very, like a very Hussain reference into this.
3380.84 3382.80 SPEAKER_07  This is the plot of Serial Experiments Lane.
3383.98 3384.62 SPEAKER_07  This is it.
3384.72 3385.36 SPEAKER_07  This is it.
3385.60 3386.92 SPEAKER_07  The wall warning was there.
3387.00 3387.52 SPEAKER_07  It breaches.
3387.72 3390.14 SPEAKER_07  You can't, no, it will breach the wall.
3390.28 3391.52 SPEAKER_07  Things will become too crazy.
3392.04 3392.74 SPEAKER_07  Things will shoot out.
3392.82 3396.46 SPEAKER_07  You will be haunted by a child who will just be on your computer screen all the time.
3396.58 3397.72 SPEAKER_08  I'm joining the sovereign citizens.
3397.84 3399.62 SPEAKER_08  I'm taking the number plate off my card.
3399.62 3401.74 SPEAKER_08  Do, do not digitally twin me.
3401.82 3402.86 SPEAKER_08  I don't want it.
3403.46 3403.78 SPEAKER_08  You,
3403.94 3406.68 SPEAKER_07  you cloned the wrong fucking hoon, sunshine.
3407.02 3408.06 SPEAKER_07  I don't want to be perceived.
3408.38 3411.06 SPEAKER_07  I don't want to be perceived by a digital version of me that's Australian.
3411.30 3412.96 SPEAKER_07  That's too scary for me.
3412.96 3413.98 SPEAKER_07  We've made,
3414.08 3415.66 SPEAKER_04  I don't, I don't want that.
3415.92 3420.00 SPEAKER_04  You thought Mount Glorious would be safe from my tires in the metaverse?
3421.22 3423.00 SPEAKER_04  Got fucking news for you, come.
3424.08 3425.96 SPEAKER_04  I've been tearing it up out there.
3427.16 3435.68 SPEAKER_06  Yeah, we've made a digital Australia, but we didn't account for the fact that the hoons would escape containment and begin digitally hooning on Australia's streets.
3435.78 3436.42 SPEAKER_07  This is the problem.
3436.52 3440.04 SPEAKER_07  This starts off with a digital Australia, but then everything becomes digital Australia.
3440.04 3440.12 SPEAKER_07  Absolutely.
3440.78 3445.48 SPEAKER_00  Digital Australia also, I think it does kind of give us a hint of where some of the actual pushback might come.
3446.04 3449.38 SPEAKER_00  And that's, you know, in the actual Australians that were always there.
3449.50 3451.74 SPEAKER_00  And the same with other indigenous communities around the world.
3451.80 3459.88 SPEAKER_00  It's really interesting sort of frontline at the moment, because the, because of the material infrastructure of all these bullshit generating machines is this global network of data centers.
3460.24 3463.96 SPEAKER_00  Data centers do seem to be doing that kind of settler colonialism 2.0 thing.
3463.96 3466.36 SPEAKER_00  You know, they're not just doing digital colonialism.
3466.36 3470.10 SPEAKER_00  They're doing actual land grabbing, water resource grabbing.
3470.22 3480.98 SPEAKER_00  I'm sure you guys know about that as well, that these data centers are really taking the fight, you know, again, to the people who've been subjected to empire 500 years and sort of doubling it up, but they haven't gone away.
3480.98 3488.30 SPEAKER_00  And what they're also able to mobilize is outside of all that stuff where, you know, we've been channeled to think like these things.
3488.40 3499.98 SPEAKER_00  I mean, we're really against AI, but our whole worldview has been set up to be, you know, susceptible to those think along the way those things are, because they're really just channeling the enlightenment, the challenging positive scientism, the channeling all these things already.
3500.22 3502.92 SPEAKER_00  They're just the kind of biggest extrusion of them in the current moment.
3503.34 3506.98 SPEAKER_00  We really need alternative ways to think about these things, really alternative ways to being.
3507.38 3508.58 SPEAKER_00  Those things still exist.
3509.08 3510.78 SPEAKER_00  You know, they still exist on the borders of empire.
3510.98 3511.18 SPEAKER_08  Yeah.
3511.26 3519.02 SPEAKER_08  I mean, people who are sort of like in some way illegible or like sort of complicated to, uh, to power that way.
3519.34 3524.92 SPEAKER_08  The thing that strikes me as well is that just as you say, that we're, we're absolutely conditioned for this.
3525.26 3532.56 SPEAKER_08  I think one of the big things, why is this, this understanding of like, you know, uh, Wiggism or like technological progress, right?
3532.60 3535.40 SPEAKER_08  Like we're going to invent the next thing and it's going to be a sea change.
3535.44 3539.52 SPEAKER_08  And people ask questions like, is AI going to be the next steam engine or is it going to be the next steam loom?
3539.52 3542.62 SPEAKER_08  Is it going to be analogous to this technology or that technology?
3543.02 3545.34 SPEAKER_08  Um, and then you sort of look at what it actually is.
3545.40 3549.10 SPEAKER_08  And it turns out to be sort of like, you know, predictive text in a trench coat.
3549.62 3550.84 SPEAKER_08  And the next Furby.
3551.18 3551.58 SPEAKER_08  Yeah.
3551.58 3555.62 SPEAKER_08  It's just, it's such a scam, but we're, we're sort of like wired for it.
3555.62 3563.64 SPEAKER_06  I see it a little bit, a little bit differently, which is that it's more, well, it's more complex than predictive text in a trench coat.
3563.88 3565.82 SPEAKER_06  I'm being slightly sardonic.
3566.04 3573.72 SPEAKER_06  Oh, I know, I know, but it is certainly enough of a sea change just to make computers behave in a complex way that it will.
3573.90 3587.36 SPEAKER_06  I see, I still think it is, it's enormously impactful, but I, I just, I, I keep bristling at the idea that anything so important as government and public services is going to be handled by a computer that behaves in a complex way.
3587.36 3591.72 SPEAKER_06  When computers that behave in merely complicated ways cause the post office Fujitsu scandal.
3591.72 3603.56 SPEAKER_08  It, it occurs to me, it must be really bleak to have been a sort of an optimist and a believer in artificial intelligence or like generative intelligence who has not bought into this.
3603.66 3611.58 SPEAKER_08  Because if you view it as we tend to, I think that it's this kind of like dead end, this like opaque box that produces sort of plausible lies.
3611.72 3621.52 SPEAKER_08  If you were all in on the idea that like someday it will be possible for us to create a sort of like, you know, a computer that's better at organizing, better thinking than we are.
3621.72 3623.86 SPEAKER_08  And we can sort of like organize our society that way.
3623.94 3634.72 SPEAKER_08  What we've done instead is created something that mimics that just about well enough to trick us some of the time thrown everything at that and then completely forestalled the possibility.
3635.76 3655.84 SPEAKER_00  Well, if you want to see someone whose psychic state, you know, represents exactly what you just said, people can check out Gary Marcus because he's, you know, is completely dumping on the fallacies of generative AI as it is, but he does still believe that something like AGI will happen, but only if we combine it because this is his view, you know, if you combine it with go fi, good old fashioned AI.
3656.28 3661.62 SPEAKER_00  So you have this, the hybridity he's looking for is that mixture of sort of generative sort of neural network connectionist stuff.
3661.62 3664.48 SPEAKER_00  And, you know, the old sort of older rules based stuff.
3664.56 3672.14 SPEAKER_00  And he thinks, so he's, he's in this constant state of anxiety because he's, he's absolutely trashing the supposed solutions that are being proposed.
3672.34 3674.18 SPEAKER_00  But on the other hand, he wants to save the game.
3674.26 3676.30 SPEAKER_00  And it's obviously a very uncomfortable place to be.
3676.54 3684.90 SPEAKER_00  We have somebody like Emily Bender, who, you know, is just, is into linguistics, is into natural language processing and looks at all the other ideas that this stuff can actually think as completely ridiculous.
3684.90 3687.08 SPEAKER_00  And isn't afraid to just call bullshit on the whole show.
3687.18 3688.72 SPEAKER_00  So there's all sorts of characters out there.
3689.26 3693.10 SPEAKER_04  A lot of people are saying my, my AI stuck in a Chinese room.
3693.18 3695.34 SPEAKER_04  I said, Hey, this AI is fucking Australian.
3695.96 3698.08 SPEAKER_06  He won't be speaking a word of Chinese.
3699.04 3707.02 SPEAKER_06  So, um, I think this also is worth going, um, going back to some of the predictions about AI that came out of WEF.
3707.02 3714.96 SPEAKER_06  If we sort of have our kind of, you know, thousand, thousand foot view of the public sector work and, but people will be relying on.
3715.54 3725.72 SPEAKER_06  Um, the chief executive officer at manpower group said, the age of the static job is over and employers will, employees will have to continually upskill in the future.
3726.08 3729.76 SPEAKER_06  Which again, this has been proclaimed for ages.
3730.14 3731.26 SPEAKER_06  Every single time.
3732.08 3733.10 SPEAKER_08  Like you say, it's a threat.
3733.18 3737.70 SPEAKER_08  There's a guy, it's a guy being like, Ooh, precarity at you as if there isn't enough precarity to go, around already.
3738.44 3740.04 SPEAKER_06  He's saying you'll have to increase your manpower.
3740.32 3740.44 SPEAKER_06  Yeah.
3740.78 3752.38 SPEAKER_06  Uh, and, uh, where Sam Altman said, uh, tried to, let's say, reduce expectations saying he didn't think that would be a human level AI anytime soon.
3752.68 3756.24 SPEAKER_06  However, he said, um, uh, what happened to that guy anyway?
3756.66 3764.26 SPEAKER_06  Uh, well, he said, AI will give people space to come up with ideas and curate decisions saying, I think everyone's job will look a little bit like that.
3764.50 3766.72 SPEAKER_06  We'll operate at a higher level of abstraction.
3767.02 3769.02 SPEAKER_06  But we'll have access to a lot more capability.
3769.02 3772.48 SPEAKER_06  And I think that line, we will operate at a higher level of abstraction.
3772.48 3786.42 SPEAKER_06  Again, goes back to the plan to basically restore the kind of early modern Catholic church as the structure for how we understand our relationship to society and the God we call the economy.
3786.42 3786.86 SPEAKER_08  Yeah.
3787.04 3797.14 SPEAKER_08  Although it's an interesting thing where you, you, it envisions this kind of like unaccountable fickle AI God, uh, a little sort of like priesthood around it.
3797.20 3808.34 SPEAKER_08  And then everybody else is either starving or a kind of like late Austrian monarch who just kind of sits back and goes, uh, just handle that, you know, uh, do, do whatever.
3808.34 3810.80 SPEAKER_08  And the, you know, the AI sort of intervenes.
3810.92 3819.30 SPEAKER_03  I love to uncritically report the, one of the inventors of the beta max in saying that the beta max is going to revolutionize the way we live our daily lives.
3819.30 3821.26 SPEAKER_03  And everyone will use the beta max for everything.
3821.26 3821.86 SPEAKER_03  Well,
3822.06 3834.32 SPEAKER_06  again, I think it's, it's one of these things where imagine if the beta max, well, if every, every powerful person had a real, um, incentive to try to input the beta max into as much as possible.
3834.84 3834.98 SPEAKER_06  Yeah.
3835.08 3836.28 SPEAKER_06  The beta max would probably win.
3836.52 3836.60 SPEAKER_06  Yeah.
3836.82 3838.62 SPEAKER_06  Like if there was like really good porn on it.
3838.92 3839.12 SPEAKER_00  Yeah.
3839.34 3845.00 SPEAKER_00  But all of these accounts do, do seem to sort of elide the idea that people are going to push back at any point.
3845.38 3851.16 SPEAKER_00  And the only reason why, I mean, obviously, you know, the TV drama was a turning point for the struggle.
3851.26 3858.46 SPEAKER_00  Against the horizon IT system, but actually, and of course there's a lot of allies involved in those kinds of processes as there was fighting robot.
3858.46 3865.50 SPEAKER_00  But at the end of the day, it was the people who were, you know, who were done over by these things, who organized themselves to push back.
3866.00 3875.00 SPEAKER_00  And, you know, the same thing with, I've just been doing some work around self-driving cars and the whole fiasco and Farrago with sort of cruise and Waymo in San Francisco.
3875.86 3883.34 SPEAKER_00  You know, they, they, they, some awful things happened and, and the cruise at least has their license revoked now because, these things, but actually it was also popular resistance.
3883.54 3889.80 SPEAKER_00  I mean, people very entertaining discovered that putting a traffic cone on the, on the front of one of these cars would bring them to a complete halt, which is really great.
3890.32 3890.40 SPEAKER_00  So.
3891.40 3893.06 SPEAKER_03  They cannot come to Glasgow.
3893.06 3894.06 SPEAKER_03  Yeah.
3894.06 3894.50 SPEAKER_00  Yeah.
3894.64 3905.26 SPEAKER_00  You know, it's like a student uprising of, of, of a real kind, but in these accounts of how these changes are going to happen, it's, I don't know the language that you're citing from these people.
3905.26 3906.96 SPEAKER_00  It is itself so recycled.
3906.96 3918.36 SPEAKER_00  It's very light generative AI because, because the research points to the fact that one of the things that will make the whole generative AI bubble implode is the fact that it will increasingly feed on its own bullshit, basically.
3918.90 3922.84 SPEAKER_00  And this whole, what AI is going to change society on, it sounds like the same thing.
3922.92 3926.52 SPEAKER_00  We've heard this recycled shit since Tony Blair's time.
3926.84 3932.74 SPEAKER_00  All these words were arranged in the same order in the same patterns at that time as well, which is, I suppose, partly what makes it so chilling.
3932.88 3936.42 SPEAKER_00  I mean, this is a fulfillment of their dream as well, but it's really very, very tired.
3936.98 3938.16 SPEAKER_00  You know, I do think they see this.
3938.52 3955.24 SPEAKER_00  I can only, I mean, I can only really explain the absolute religious commitment of the EU, of the UK government or of all of these state and corporate level entities to AI in the face of what is clearly the case with AI in the sense that they believe it's going to save neoliberalism somehow.
3955.94 3956.04 SPEAKER_06  Yeah.
3956.50 3968.44 SPEAKER_06  Well, that really is what it comes down to is we have our, this is our last ditch attempt to make this tick over in a way that sort of works for everyone and keeps them bought in.
3968.84 3996.72 SPEAKER_06  But I think what's come back down to what you were saying, like to sort of round this all out is that the most striking thing is that whether it's business leaders, political leaders, uh, think tankers, or, you know, some of the same language used in the IMF report, it's all been the same ever since, you know, the, there have been different, like different computer systems being invented into sort of neoliberal age, which is that this is fundamentally just the same political process with a new technological gloss on it.
3996.72 4003.82 SPEAKER_06  It is not part of a technological process or rather it's not part of a technological process that is distinguishable from the political process.
4003.82 4004.00 SPEAKER_08  Yeah.
4004.00 4018.86 SPEAKER_08  I mean, it's interesting because the sort of the front is of politics outside this neoliberalism, whether that's sort of the populist right or some kind of like emergent left in both cases, both of those movements want to do things, you know, they want to do bad things.
4018.94 4028.58 SPEAKER_08  We want to do good things, but they want to like change things in government where neoliberalism wants to keep the same things going as absurd, like obscurely as possible.
4028.58 4033.80 SPEAKER_08  And I'm wondering what the sort of potential for AI is there, you know?
4034.26 4047.62 SPEAKER_00  Personally, I think one of the useful things that's come up and it's partly because of Genetive AI being, you know, the sort of jabber mouth that it is, is the fact that people have turned to it, not this, not the fact that people have turned to it for therapy, but the fact that they have has evoked people's memories of Eliza.
4047.76 4059.04 SPEAKER_00  So people have been returning to Joseph Eisenbaum and then they've been rediscovering that Joseph Eisenbaum, who was after all an AI insider, you know, at the time, at that time, you know, his objection wasn't really that chatbots were emulating human beings.
4059.04 4071.24 SPEAKER_00  It was simply that actually there's a vast class of things in the world and humans being together that computers, however good they are, however real AI is, simply should not do.
4072.02 4076.74 SPEAKER_00  And that includes the vast class of decisions that affect people's lives in any substantial way.
4077.14 4088.02 SPEAKER_00  So, you know, where that takes us, I think the bit that he didn't maybe follow through on is that opens up the idea that those things should be organized, those important decisions should be organized absolutely differently.
4088.30 4091.54 SPEAKER_00  But at least we could agree on one thing that AI definitely shouldn't be making any of those decisions.
4092.54 4095.58 SPEAKER_06  So I think that's as good as any place to leave it.
4096.20 4099.32 SPEAKER_06  Dan, I just want to thank you very much for coming and talking to us today.
4099.36 4101.06 SPEAKER_06  It's always lovely to have you on.
4101.72 4102.28 SPEAKER_06  You're very welcome.
4102.38 4102.92 SPEAKER_00  I really enjoyed it.
4103.20 4103.40 SPEAKER_06  Yeah.
4103.50 4111.04 SPEAKER_06  And don't forget, you can get Resisting AI, an anti-fascist approach to artificial intelligence, which I said correctly this time, I think,
4111.56 4114.82 SPEAKER_03  anywhere that fine books are sold. Yeah.
4114.92 4119.76 SPEAKER_03  And if you want to find out more about the IMF's approach to AI, you can watch Mission Impossible Ghost Protocol.
4120.90 4122.66 SPEAKER_03  How long you've been sitting on that one?
4122.78 4123.08 SPEAKER_03  Don't know.
4123.42 4124.26 SPEAKER_03  That's for you to guess.
4125.54 4127.34 SPEAKER_03  And Milo, you've got tour shows.
4127.54 4128.56 SPEAKER_03  I do have tour shows.
4128.70 4128.88 SPEAKER_03  Yeah.
4130.64 4132.14 SPEAKER_03  Brighton on the 3rd of March.
4132.26 4136.68 SPEAKER_03  I've got Leicester Comedy Festival, two shows in one day, a work in progress on a tour show on the 18th of February.
4137.12 4140.02 SPEAKER_03  Got all of Australia, name a fucking city in Australia.
4140.14 4141.00 SPEAKER_03  Virtual Australia.
4141.20 4141.92 SPEAKER_03  You're going to the metaverse.
4141.92 4143.52 SPEAKER_03  You're performing people's digital twins.
4143.64 4145.66 SPEAKER_03  I am honing around Australia.
4146.46 4146.82 SPEAKER_03  Yeah.
4146.94 4150.28 SPEAKER_03  Any major city in Australia, March, April, I will be there.
4150.42 4151.62 SPEAKER_03  Tickets for that are on my website.
4151.66 4153.04 SPEAKER_03  Tickets for everything are on my website.
4153.20 4153.34 SPEAKER_03  Please.
4153.42 4156.18 SPEAKER_03  I've got whips in London as well in February and March.
4156.32 4157.06 SPEAKER_03  So please come to those.
4157.40 4158.14 SPEAKER_03  I got whips.
4158.34 4158.88 SPEAKER_03  That's right.
4159.00 4159.16 SPEAKER_06  Yeah.
4159.26 4159.52 SPEAKER_06  All right.
4159.54 4159.80 SPEAKER_06  All right.
4159.84 4164.34 SPEAKER_06  And also, of course, you and I and Olga and Pierre have a new show on YouTube.
4164.34 4164.70 SPEAKER_03  We do.
4164.84 4165.48 SPEAKER_06  Called Blue Factory.
4166.00 4167.52 SPEAKER_06  It's Balthazar Speedboat, but filmed.
4167.68 4167.80 SPEAKER_06  Yeah.
4167.84 4168.28 SPEAKER_06  Check that out.
4168.28 4169.96 SPEAKER_06  So, you know, do check that out on YouTube.
4170.08 4170.60 SPEAKER_03  Log on.
4170.86 4171.70 SPEAKER_03  Comes out every what?
4171.76 4171.98 SPEAKER_06  Tuesday?
4172.20 4172.46 SPEAKER_06  Wednesday.
4172.66 4172.98 SPEAKER_06  Wednesday.
4173.12 4173.60 SPEAKER_06  Wednesday night.
4173.72 4174.16 SPEAKER_06  Wednesday night.
4174.58 4175.40 SPEAKER_06  I should probably know that.
4175.54 4175.76 SPEAKER_06  All right.
4175.80 4176.04 SPEAKER_06  All right.
4176.08 4176.30 SPEAKER_06  All right.
4176.78 4178.60 SPEAKER_06  Once again, thank you very much to Dan.
4178.76 4179.76 SPEAKER_06  Check out Resisting AI.
4180.04 4181.06 SPEAKER_06  Check out all that other stuff.
4181.42 4183.62 SPEAKER_06  And we'll see you on the What Day Is It Today?
4183.70 4185.26 SPEAKER_06  Monday free episode in a few days.
4185.52 4185.90 SPEAKER_06  Bye, everyone.
4186.00 4186.12 SPEAKER_06  Bye.
4186.12 4186.18 SPEAKER_06  Bye.
4186.18 4186.40 SPEAKER_06  Bye.
4186.40 4186.46 SPEAKER_06  Bye.
4186.46 4186.52 SPEAKER_06  Bye.
4186.52 4187.04 SPEAKER_06  Bye.
4187.04 4187.10 None  Bye.
4187.10 4187.18 None  Bye.
4187.18 4187.40 None  Bye.
4187.40 4188.40 None  Bye.
4188.40 4188.60 None  Bye.
4188.60 4188.62 None  Bye.
4188.62 4189.02 None  Bye.
4189.02 4190.46 None  Bye.
4190.46 4190.54 None  Bye.
4190.54 4192.46 None  Bye.
4192.46 4192.54 None  Bye.
4192.54 4193.54 None  Bye.
4193.54 4194.46 None  Bye.
4194.46 4194.54 None  Bye.
4194.54 4194.90 None  Bye.
