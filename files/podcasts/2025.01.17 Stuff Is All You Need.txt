0.00 30.60 SPEAKER_02  So I want to open today's episode by recognizing one of the best in what I would say is our, if you take a very, very broad look at what we sometimes do some of the time, one of the best to ever do it.
30.66 33.98 SPEAKER_02  That's Nate Anderson of Hindenburg Research is retiring.
34.34 39.16 SPEAKER_01  One of the haters of all time, you know, and we salute that, of course.
39.36 66.84 SPEAKER_02  Oh, a guy who took hating, who took like wanting to embarrass someone who was a fraudster and turned it into a multi-million, like many millions of dollars industry that involved, and I will never forget this as long as I live, hiring a firm of Turkish, like private investigators to comb through old tat shops just to prove that somebody he was trying to discredit used to work as a magician.
67.08 67.72 SPEAKER_02  And you know what?
67.84 70.08 SPEAKER_02  They fucking found it and it fucking worked.
70.96 73.08 SPEAKER_03  Can you believe the power?
73.24 73.38 SPEAKER_03  Yeah.
73.48 76.42 SPEAKER_03  Nothing more embarrassing than people proving you used to be a magician.
76.80 77.04 SPEAKER_03  Yeah.
77.20 80.82 SPEAKER_03  And not even a good magician, presumably, since you stopped, you know?
80.82 83.04 SPEAKER_03  Like, yeah, your rabbit died or something.
83.38 84.20 SPEAKER_03  Yeah, yeah.
84.40 87.44 SPEAKER_03  I said I'd never do magic again, not after I killed that rabbit.
88.00 90.14 SPEAKER_03  A real master of our art.
90.36 90.54 SPEAKER_02  Yeah.
90.66 93.66 SPEAKER_02  Just one of the greatest haters of all time.
93.72 96.52 SPEAKER_02  A man who should be immortalized in the player haters ball.
96.70 96.80 SPEAKER_02  Yeah.
97.12 101.84 SPEAKER_02  Nate Anderson, the TF podcast, issues you the official tipple the cap.
101.94 102.12 SPEAKER_02  Yeah.
102.22 105.00 SPEAKER_02  Playing the last post on the podcast bugle.
107.40 108.00 SPEAKER_02  That's right.
108.10 109.88 SPEAKER_02  Welcome to Bonus TF, everybody.
109.88 112.64 SPEAKER_02  It is Riley Milo, November and Hussein.
113.26 115.06 SPEAKER_02  The old gang back together.
115.22 115.72 SPEAKER_02  That's right.
115.86 127.10 SPEAKER_02  And before we get into some of our news and then our main segment for today, yes, we are talking about the plan that has come together from the Labour Party to transform the country with AI.
127.30 128.00 SPEAKER_02  They've published it.
128.10 130.40 SPEAKER_02  It's got 50 points and boy, is it substantive.
130.66 132.32 SPEAKER_02  Each more substantive than the last.
132.50 132.76 SPEAKER_02  Excellent.
133.16 133.28 SPEAKER_02  Yeah.
133.32 134.14 SPEAKER_03  Well, 50 points.
134.20 136.42 SPEAKER_03  I mean, that must cover pretty much every problem that we've got.
136.54 136.72 SPEAKER_03  Yep.
137.12 137.32 SPEAKER_03  Yeah.
137.40 137.68 SPEAKER_03  Great.
137.68 138.08 SPEAKER_03  Excellent.
138.18 139.42 SPEAKER_03  I look forward to hearing all 50.
139.42 140.96 SPEAKER_02  This can be the last episode of the show.
141.04 141.48 SPEAKER_02  They fixed it.
141.56 142.96 SPEAKER_03  Oh, no more work for us.
143.02 145.30 SPEAKER_03  I guess we'll have to get jobs in the excellent new economy.
145.68 145.86 SPEAKER_02  Yeah.
146.04 148.02 SPEAKER_03  Well, there's one job that's just opened up.
148.06 148.40 SPEAKER_03  Oh, really?
148.72 149.44 SPEAKER_03  Hindenburg Research.
149.60 150.06 SPEAKER_03  Oh, yeah.
150.18 150.54 SPEAKER_01  Right, right.
150.58 150.74 SPEAKER_03  Yeah.
151.24 154.58 SPEAKER_01  Do we really think we have what it takes to be that level of hate?
154.68 156.70 SPEAKER_01  So, is our hate that pure?
156.70 158.32 SPEAKER_01  I don't know.
158.32 166.14 SPEAKER_02  I mean, sometimes I think I remember years ago when I read the Credit Suisse supply chain finance bonds.
166.14 177.16 SPEAKER_02  I felt the rush of, I have learned some information that this person would find embarrassing in regards to his fraud that he's currently perpetrating.
179.06 179.50 SPEAKER_03  Yeah.
179.54 182.40 SPEAKER_03  Why did it say in those Bond prospectuses that he used to be a magician?
182.90 184.14 SPEAKER_03  He's buried in there.
184.14 184.46 SPEAKER_02  Yeah.
184.54 187.14 SPEAKER_02  Like Lex Greensill being a magician, but bad.
187.26 191.66 SPEAKER_02  Like there's a grainy 90s videotape somewhere in like Australia's Gold Coast.
191.78 194.30 SPEAKER_02  That's just like him going, pick a card.
194.80 195.62 SPEAKER_02  No, no, no, no.
195.68 196.14 SPEAKER_02  Not that one.
196.18 196.72 SPEAKER_02  Pick this one.
197.30 197.94 SPEAKER_02  You know?
198.64 202.80 SPEAKER_02  And pulling a coin out from behind someone's ear, but just yanking their head to one side.
202.92 203.34 SPEAKER_02  Like, hey.
204.22 207.02 SPEAKER_02  That insurance agent guy being like, oh, close enough.
207.42 209.32 SPEAKER_03  Oh, that coin was sort of in my ear.
209.38 211.02 SPEAKER_03  Yeah, that coin was pretty in my ear.
211.10 212.66 SPEAKER_03  I guess I'll insure whatever you do.
212.70 214.34 SPEAKER_03  Yeah, I'll sign you off as a magician.
214.62 215.94 SPEAKER_02  A bit's a bit, all right?
216.12 216.32 SPEAKER_05  Yeah.
217.50 222.04 SPEAKER_02  I said, if you could make me believe the coin was in my ear, I'd sign anything.
222.42 224.62 SPEAKER_03  No one's going to let me become a money farmer.
224.76 226.44 SPEAKER_03  I'm just an unsuccessful magician.
226.92 228.46 SPEAKER_03  I've got my tricks don't work.
228.52 229.50 SPEAKER_03  My rabbit's died.
229.50 232.40 SPEAKER_03  My glamorous assistant is playing at best.
233.34 236.54 SPEAKER_01  This is basically the plus of the greatest showman, by the way.
236.70 237.82 SPEAKER_02  Just wearing a sack.
238.90 244.10 SPEAKER_02  My plane assistant has now been mauled by yet another plane assistant mauled by chainsaw.
244.20 247.98 SPEAKER_01  Oh, the tiger's got out of the tiger enclosure and into the plane assistant enclosure.
248.28 249.16 SPEAKER_03  This is terrible.
249.50 249.64 SPEAKER_01  Yeah.
250.04 252.94 SPEAKER_03  I'm in court for actually sawing her in half.
254.00 258.04 SPEAKER_02  I thought I benefited from something called magician's privilege.
258.04 263.52 SPEAKER_02  I realized I dreamed that.
264.16 268.16 SPEAKER_03  I realized the magician's privilege is more of a structural condition.
268.60 272.70 SPEAKER_03  Alibaba made me promises about the sawing in half box that weren't kiffed.
274.40 281.30 SPEAKER_01  Magician's privilege refers to the collective of magicians rather than individual magicians to whom bad things can still happen.
281.30 285.80 SPEAKER_04  I like the idea of like cheating on your wife and then using magician's privilege as a way of justifying it.
286.82 287.06 SPEAKER_03  Yeah.
287.54 290.06 SPEAKER_03  Or just distracting your wife by pulling a coin out of her.
290.30 290.48 SPEAKER_01  Yeah.
291.00 294.46 SPEAKER_01  That conversation happened under magician audience privilege.
296.86 298.76 SPEAKER_01  The cops can't listen in.
298.98 302.04 SPEAKER_01  They have to turn off all the like surveillance equipment in the van.
302.16 303.36 SPEAKER_01  Like he's talking to his fucking magician.
303.36 309.04 SPEAKER_04  Well look like there's like a crisis with like, you know, there's like duty solicitors you get when you're arrested, right?
309.12 312.76 SPEAKER_04  So one solution other than the AI solicitor is to sort of like-
312.76 313.88 SPEAKER_03  Duty magician. Yeah.
314.02 314.20 SPEAKER_03  Yeah.
314.32 314.48 SPEAKER_03  Yeah.
314.48 316.82 SPEAKER_03  You can request a solicitor or a magician.
317.58 319.14 SPEAKER_03  Is this your charge?
319.50 322.86 SPEAKER_03  He can't give you legal advice, but he can just amuse you a little bit.
323.14 324.40 SPEAKER_03  And you can go, ooh.
324.50 327.82 SPEAKER_03  He can't give you legal advice, but he can really pass the time in the holding cell.
328.10 328.82 SPEAKER_03  He's great.
328.92 329.06 SPEAKER_03  Yeah.
329.14 329.22 SPEAKER_03  Yeah.
329.22 331.22 SPEAKER_03  And anything you tell him, he keeps it under his hat.
331.64 333.18 SPEAKER_03  That's magician client privilege.
333.18 335.44 SPEAKER_02  And here's the best part about magician privilege.
335.62 339.08 SPEAKER_02  You think he's going to like tell the like prosecutor, right?
339.16 340.82 SPEAKER_02  You're so sure that he's going to.
341.12 344.90 SPEAKER_02  And he just hands the prosecutor a single white dove with no evidence attached.
345.26 345.48 SPEAKER_02  Yeah.
345.66 347.54 SPEAKER_02  It's really, it's really good.
347.70 348.52 SPEAKER_03  Like it's really cool.
348.60 355.58 SPEAKER_03  Once he left behind in your cell, but a hundred handkerchiefs knotted together that you can use to commit suicide before you ever have to stand trial.
356.52 357.62 SPEAKER_03  Thank you, magician.
358.20 361.20 SPEAKER_01  Magician stalking towards Jeffrey Epstein's cell.
361.20 365.44 SPEAKER_01  I guess that answers how the CCTV went out, you know?
365.56 366.16 SPEAKER_01  Yeah, of course.
366.20 369.28 SPEAKER_04  What we figured out here is actually the plot to Now You See Me Free, right?
369.42 371.56 SPEAKER_04  Which is in production.
371.82 373.16 SPEAKER_04  I just want to say it is in production.
373.42 374.54 SPEAKER_04  The movies are back, baby.
374.92 375.48 SPEAKER_02  Yeah, that's right.
375.52 376.28 SPEAKER_02  We're back in business.
376.38 377.14 SPEAKER_02  We're back in the movies.
377.36 384.58 SPEAKER_02  We are all, in fact, this podcast, because we do a ceremonial card trick before we start, is under magician's privilege.
384.76 385.28 SPEAKER_02  That's true.
385.42 385.58 SPEAKER_02  Yeah.
385.58 387.34 SPEAKER_02  So we can actually defame whoever.
387.48 388.16 SPEAKER_02  Yeah, that's right.
388.24 396.86 SPEAKER_02  But I want to now go to my second trick, which is going to be, again, I found this and will there be a jarring shift in tone coming after it?
397.16 397.46 SPEAKER_02  Yes.
397.64 402.68 SPEAKER_02  However, I wanted to talk about an update on the law that is sending people to jail for posts.
402.78 404.52 SPEAKER_02  I think that Elon should get on this.
404.62 406.44 SPEAKER_02  I think the free speech union should get on this.
406.44 411.44 SPEAKER_02  In George Orwell's 1984, big brother, we didn't know he was Australian.
413.70 416.50 SPEAKER_02  In the Aus-k-k-k-kralia.
417.32 418.38 SPEAKER_02  Yeah, that's right.
418.42 418.78 SPEAKER_02  Thank you.
418.98 419.08 SPEAKER_02  Yeah.
419.72 419.94 SPEAKER_02  Uh-huh.
420.00 420.34 SPEAKER_02  Thank you.
420.40 420.58 SPEAKER_02  Yes.
420.62 430.06 SPEAKER_02  In the fascist dictatorship of Australia, they are now, they're not even, you know, if there are guys, you know, going around, you're committing actual crimes.
430.16 437.58 SPEAKER_02  If the Apex gang comes and, you know, does the knockout game on you, the police don't come, but you can go to jail for posting because they care about hurt feelings.
437.74 444.78 SPEAKER_02  And specifically, the kind of jail you can go to for posting is if you post about breaking your car on purpose by driving it really fast.
445.20 449.24 SPEAKER_03  In the future dystopian Australia, it's illegal to be a sick cunt.
450.62 452.90 SPEAKER_03  Culver sacks are now battlefields.
452.94 453.06 SPEAKER_02  Yeah.
453.20 457.48 SPEAKER_02  So this is, there are, there have been a rash of new hooning and posting laws.
457.58 458.58 SPEAKER_02  Oh, beautiful.
458.78 459.96 SPEAKER_02  Don't hoon and post.
460.08 461.30 SPEAKER_02  You can do one or the other.
461.30 461.38 SPEAKER_02  Yeah.
461.84 462.00 SPEAKER_02  Yeah.
462.06 471.60 SPEAKER_02  So Roger Cook revealed that Western Australia labor would introduce new laws criminalizing the circulation of videos showing hooning, violence, property damage, and other criminal behavior.
471.76 472.20 SPEAKER_01  Makes sense.
472.30 475.56 SPEAKER_01  You wouldn't, you know, want to glorify hooning, you know?
475.66 475.88 SPEAKER_02  Yeah.
475.98 482.64 SPEAKER_02  Well, for me, this is like, you know that there's that old meme of, um, they outlaw our medicine, so we buy their cures.
482.98 483.40 SPEAKER_02  Yeah, yeah, yeah.
483.40 487.04 SPEAKER_02  It's like, it just, it's, if we buy their cures, it's just like a speed limit sign.
487.04 487.44 SPEAKER_02  Yeah.
489.54 502.32 SPEAKER_03  They should do like a Jason Statham movie where it's like a guy who had to give up hooning because of the new rules and regulations and he's got like a wife and a kid and he's driving a minivan, but then something, something happens and he has, and he has to hoon to save his family.
502.56 504.56 SPEAKER_02  You're talking about the Australian transporter.
504.76 505.78 SPEAKER_02  That's just the transporter.
506.24 506.48 SPEAKER_02  The transporter.
506.68 507.22 SPEAKER_02  The transporter.
508.10 509.24 None  Oh, that's right.
509.40 510.02 SPEAKER_05  There we go.
510.10 511.14 SPEAKER_03  The transperther.
512.18 514.10 SPEAKER_03  Jaiso Stathos, the transporter.
514.10 514.28 SPEAKER_03  Wow.
516.90 517.90 SPEAKER_03  Yeah, I would love that.
517.90 519.56 SPEAKER_03  Turns out there's a Shiloh in the trunk.
520.40 523.74 SPEAKER_03  Running his hands across an old Holden Monaro in his garage.
524.22 525.32 SPEAKER_03  It's been a long time.
526.52 527.82 SPEAKER_02  Gone in 60 seconds.
528.02 530.36 SPEAKER_02  It's just like, fucked off in 60 seconds.
530.84 534.40 SPEAKER_03  But it's still there in 60 seconds, being a lot of tire smoke.
535.40 538.48 SPEAKER_01  In a slightly different orientation in 60 seconds.
538.66 539.18 SPEAKER_01  Yeah, yeah, yeah.
539.28 543.68 SPEAKER_02  It's there in 60 seconds with a lot of tire smoke and the engine non-functional.
543.68 546.60 SPEAKER_03  Going in circles for about 60 seconds, the new movie.
546.90 551.52 SPEAKER_02  I've been trying to steal that 1997 Holden Commodore five years.
552.36 553.90 SPEAKER_03  It's impossible to steal.
554.04 555.42 SPEAKER_03  You can't get it to start.
556.38 558.86 SPEAKER_03  I've hooked a PlayStation controller up to this.
558.92 560.62 SPEAKER_03  The interior's all fucking melted.
560.78 561.84 SPEAKER_02  It's disgusting in there.
562.24 577.38 SPEAKER_02  So, South Australian police have charged a 29-year-old man, this is an example of this law, for dangerous drive in extreme speeding after the hoon posted footage of his antics on social media, with police alleging the man uploaded footage of himself driving a Ford Falcon at 180 kilometers per hour.
577.70 578.02 SPEAKER_02  Yeah.
578.32 581.22 SPEAKER_01  There's something really offensive about these kinds of laws to me, right?
581.28 588.60 SPEAKER_01  Because what they're doing is they're interfering with a beautiful tradition of knocking on yourself by posting video of your own crimes.
588.60 594.10 SPEAKER_01  Like, if the post itself is a crime, it's really like, it's spoiling the game, you know?
594.20 601.74 SPEAKER_03  Yeah, it's inconsistent that the Australian government condemns this and yet supports the IDF, who are the kings of posting evidence of their own crime.
602.26 608.28 SPEAKER_01  If you're hooning, but you're wearing, like, stolen women's clothing, then you kind of, like, averages out, you know?
608.34 611.52 SPEAKER_02  I like a lot of the guys that are hooning do so with Mexican flags.
611.52 619.52 SPEAKER_02  A lot of the hooning gangs are called, like, South Brisbane Mexican outlaws, and all of them are white Australian.
620.50 620.86 None  Okay.
621.88 623.46 SPEAKER_02  With a Juarez cuntel.
625.56 625.92 SPEAKER_03  Yeah!
626.58 626.76 SPEAKER_03  Yeah.
627.02 631.46 SPEAKER_03  Your Honor, does the Australian constitution not protect the institution of being a sick cunt?
631.60 637.66 SPEAKER_03  And furthermore, if you are in the process of being a sick cunt, what would be the purpose of so doing if you're not allowed to film yourself?
637.66 645.52 SPEAKER_01  Going to the, getting Mexican, like, consular representation, like, as a white Australian having been arrested in Australia.
645.68 655.58 SPEAKER_02  So, just do me a favour, go to mexicanhooncartel.com, and then there is, like, the first- That feels like a Twitter screen name rather than a thing.
655.70 662.80 SPEAKER_02  The first thing that's there is, again, a white Australian guy in a balaclava and a bucket hat wearing the Mexican flag as a cape.
663.18 664.26 SPEAKER_02  This fucking rules?
664.46 667.06 SPEAKER_03  Yeah, well, this is also the Australian conception of race.
667.06 670.76 SPEAKER_03  We can be like, oh, mate, I'm Greek, which is like a type of Mexican.
671.72 672.82 SPEAKER_02  No, but that's the thing.
672.86 676.54 SPEAKER_02  I told you I was fucking Mexican today, but that's not even why.
676.68 681.52 SPEAKER_02  It's because they think of Mexico as, like, the Wild West and Outlaw Cowboy.
683.06 687.54 SPEAKER_03  Well, it's the original, the Hoon homeland, you know?
687.76 688.40 SPEAKER_02  That's right.
688.58 689.00 SPEAKER_03  Yeah.
689.20 695.90 SPEAKER_02  You can buy merch from the Mexican Hoon cartel, which is just a bunch of white Australian kids who live in the Gold Coast.
696.04 698.80 SPEAKER_01  All right, so next live show when we're all wearing this.
699.46 700.40 SPEAKER_02  Yeah, yeah, yeah, yeah.
700.56 703.90 SPEAKER_02  It's all in Mexican flags, bucket hats, and people are getting mad at us.
704.00 708.54 SPEAKER_02  I'm like, no, you should be mad at us if you're a white suburbanite who lives in, like, Tawunda.
708.72 711.70 SPEAKER_04  Can I expense a balaclava and a bucket hat?
711.86 712.68 SPEAKER_02  Almost certainly.
712.68 713.64 SPEAKER_02  Actually, you know what?
713.70 716.78 SPEAKER_02  If you ever get brought up on it, you can refer to this episode.
716.98 719.76 SPEAKER_02  And yeah, we now can all...
719.76 729.24 SPEAKER_01  Greetings to the HMRC inspector who is listening to this, trying to figure out why we have a Mexican flag line item in all of our tax records.
729.48 734.06 SPEAKER_02  Why we have Mexican flags for each of us.
734.22 746.20 SPEAKER_03  The Mexican Hoon cartel balaclava is now making me think of a very interesting concept, which is the Mexican Hoon IRA, like the voice changer phone call, which is like, you need to evacuate the following streets.
746.54 749.20 SPEAKER_03  There's going to be a hooning incident in 35 minutes.
749.50 751.20 SPEAKER_04  I think this is like a very important...
751.20 755.32 SPEAKER_04  I would go as far as to sort of say that like defending these guys is effectively...
755.32 758.06 SPEAKER_04  It is very much a test case of whether we want to defend the West or not.
758.06 778.68 SPEAKER_04  And it's very surprising that like none of the figureheads of the free speech movement have really sort of said anything about him because the integrity of freedom of speech in the West and by extension democracy is very much dependent on that question of would you defend to the death the right for white Australians pretending to be Mexican to like trash up cars for some reason and post it online, right?
778.82 780.32 SPEAKER_01  This is like a real litmus test.
780.44 783.10 SPEAKER_04  Do you look upon this man with contempt or respect?
783.26 790.04 SPEAKER_04  And if your answer is not with respect, if there's anything other than like without respect, then like, I don't know, you may as well join ISIS.
791.00 791.68 SPEAKER_02  That's right.
791.68 805.36 SPEAKER_02  Whenever I watch videos, and I do watch videos, of the Summer Nats Burnout Festival, I see guys with mullets wearing Mexican flag capes, crashing their cars into each other, hitting their heads together, and then say, oh, fucking sick, cunt.
805.56 807.16 SPEAKER_02  I stand up and I salute my phone.
807.22 808.28 SPEAKER_04  I hate guys being guys.
808.42 810.26 SPEAKER_04  I feel like that's really what it comes down to.
810.74 815.34 SPEAKER_02  Yeah, if we want to fix the crisis of masculinity, we need to like embrace the hoon.
815.54 817.60 SPEAKER_04  We have said that for a very long time.
818.86 819.98 SPEAKER_01  Embrace the hoon respectfully.
819.98 827.00 SPEAKER_04  Why haven't all these like fucking YouTube masculinity guys who all have like the same looking podcast, why aren't they speaking to any of the hoons?
827.08 834.38 SPEAKER_04  It's all just like, uh, fucking like testosterone, Andrew Huberman, um, I only like bathe in ice water type of fucking guys.
834.40 835.12 SPEAKER_04  What about Andrew Hooneman?
835.28 835.72 SPEAKER_01  Exactly.
835.92 837.12 SPEAKER_01  Why not Andrew Hooneman?
837.62 839.02 SPEAKER_01  Respect this hoon.
839.50 840.58 SPEAKER_01  Yeah, that's right.
840.58 854.42 SPEAKER_02  Okay, this is the official TF plan for fixing, for fixing the masculinity crisis is everybody who's currently trying to figure out what it means to be a man and is landing on the answer of whatever I imagined the fifties was like.
854.56 859.08 SPEAKER_02  We're fixing them by importing all mass 1990s Holden Commodores.
859.28 861.52 SPEAKER_03  Here's an idea for a shirt.
862.20 865.44 SPEAKER_03  And it's a picture of former UK defense secretary, Jeff Hoon.
865.44 868.56 SPEAKER_03  And he's in, he's in like a hold and doing a, doing a burnout.
868.78 874.84 SPEAKER_03  And it's like, Jeff Hoon says we did the Iraq war, but only because we needed the petroleum byproducts for sick shit.
875.44 877.58 SPEAKER_02  I think there's the germ of an idea in there.
877.62 883.22 SPEAKER_02  That's a shirt that in the world of 6 billion, no 6, 8 billion people, excuse me.
883.22 883.46 SPEAKER_02  Yeah.
883.62 885.52 SPEAKER_02  About 200 will get.
885.60 885.78 SPEAKER_02  Yeah.
885.82 889.40 SPEAKER_02  And 100% of those people are listening to this right now.
889.46 890.12 SPEAKER_02  Isn't that beautiful?
890.28 890.40 SPEAKER_02  Yeah.
890.46 890.58 SPEAKER_02  Yeah.
890.76 890.90 SPEAKER_02  Yeah.
890.98 897.06 SPEAKER_02  The crossover of people in the UK who appreciate Australian burnout culture was 100% created by us.
897.14 898.84 SPEAKER_02  I don't care if it's, if it's not right.
898.92 900.36 SPEAKER_02  I don't care if there's evidence to the contrary.
900.74 901.20 SPEAKER_03  Morally, it's true.
901.28 903.12 SPEAKER_04  And those people are the 1% males.
903.24 906.36 SPEAKER_04  They are the high value males that society has been searching for.
906.42 906.54 SPEAKER_02  Yeah.
906.56 910.32 SPEAKER_02  It's like they're the 1%, but it's like the 1% or outlaw biker.
910.32 912.24 SPEAKER_02  All right.
912.36 914.88 SPEAKER_02  The last thing is, um, the last Hoon story before we move on.
914.94 916.28 SPEAKER_02  How do we do 20 minutes on Hooning?
916.60 920.50 SPEAKER_02  A former private school student turned Hoon who has lived a privileged life free of consequence.
920.60 920.94 SPEAKER_02  Oh my God.
921.00 922.26 SPEAKER_02  Wrong side of the tracks.
922.66 925.80 SPEAKER_02  Well, it was wrong side, then right side, then wrong side, then right side.
925.84 926.54 SPEAKER_02  And he just kept spinning.
926.76 926.92 SPEAKER_02  Yeah.
927.02 927.16 SPEAKER_02  Yeah.
927.18 927.30 SPEAKER_02  Yeah.
927.30 929.02 SPEAKER_02  And then the fucking train came through.
929.14 929.44 SPEAKER_02  Uh, yes.
929.56 931.28 SPEAKER_02  Uh, lived a privileged life free of consequences.
931.28 937.22 SPEAKER_02  Could soon, uh, face jail time as he filmed himself speeding in luxury cars and leaving them to drive themselves on cruise control.
937.22 939.70 SPEAKER_02  The court heard that Sushant Mittal and his twin brother-
939.70 940.60 SPEAKER_03  They're game free, you know.
940.82 949.74 SPEAKER_02  Regularly filmed themselves Hooning around in like Mercedes AMGs and BMWs bought by their parents before sharing the footage to TikTok under the name Sushi on Fire.
951.82 953.86 SPEAKER_03  Sushi on Fire is a very funny screen name.
953.96 954.90 SPEAKER_03  Shouldn't, hang on though.
955.00 959.50 SPEAKER_03  Shouldn't you be really doing like Japanese tuna cars if your, if your screen name is Sushi on Fire?
959.72 961.14 SPEAKER_02  Do you want to call Sushant Mittal?
961.22 962.08 SPEAKER_02  Yeah, I think I should.
962.28 963.26 SPEAKER_02  You want to be his representation?
963.54 965.08 SPEAKER_01  You want to get magician's privilege with him?
965.08 967.52 SPEAKER_01  Showing up as the magician and being like, listen.
968.28 968.42 SPEAKER_03  Yeah.
968.52 973.90 SPEAKER_03  And at the start of every video, you say like, let's cook this sushi before setting fire to the tires of your Toyota Supra.
974.74 977.90 SPEAKER_02  Look, if he had these kinds of good ideas, maybe he wouldn't be in jail.
977.98 978.56 SPEAKER_02  That is true.
978.68 978.82 SPEAKER_02  Yeah.
978.92 979.48 SPEAKER_02  That is true.
979.88 980.04 SPEAKER_02  Yeah.
980.10 981.50 SPEAKER_02  The smart hoons don't get caught.
981.68 982.48 SPEAKER_02  Maybe he'd be mayor.
982.66 982.86 SPEAKER_02  Yeah.
983.04 987.92 SPEAKER_02  By criminalizing hooning, all we're doing is enabling smart hoons to do it with impunity.
988.20 988.40 SPEAKER_02  Yeah.
988.50 988.64 SPEAKER_02  Yeah.
988.64 988.82 SPEAKER_02  Yeah.
988.82 993.90 SPEAKER_02  Uh, anyway, Mittal's lawyer claimed, uh, in his defense that he was quote, kind of an idiot.
994.62 996.96 SPEAKER_03  I, I love those statements in defense.
997.14 998.30 SPEAKER_03  Those are the best ones.
998.42 1004.86 SPEAKER_03  It was, it's like when Wayne Hennessy did a Nazi salute and the manager of his club said, Wayne doesn't know what the Nazis are.
1006.44 1008.48 SPEAKER_02  He doesn't understand any of that stuff.
1008.60 1013.98 SPEAKER_02  Though, look, I want to do the jarring shift in tone now, um, which is, I don't think it has been around.
1013.98 1018.32 SPEAKER_02  So you could, so to speak long enough for us to be able to comment on it fully.
1018.32 1025.40 SPEAKER_02  But as, as of the day of recording Thursday evening, it looks as though there is going to be a ceasefire declared in Gaza.
1025.66 1029.58 SPEAKER_02  And there are a few things I think we can know.
1029.70 1030.68 SPEAKER_02  I mean, look, we don't know.
1030.84 1031.72 SPEAKER_02  It's been declared.
1031.82 1032.62 SPEAKER_02  It hasn't started yet.
1032.72 1034.28 SPEAKER_02  We don't know how long it's going to go for.
1034.32 1035.76 SPEAKER_02  We don't know if it's going to be respected.
1036.02 1042.30 SPEAKER_02  We also don't know, like, like we know going in, there was zero like day after plan, nothing right.
1042.34 1058.40 SPEAKER_02  The day after plan is this, uh, we don't know like what the Marshall plan for Gaza is going to look like, uh, but we can know a couple of things from what went on and from what people have said so far, which is that number one, the UK and Europe are relegated to utter strategic irrelevance again.
1058.52 1058.76 SPEAKER_02  Yeah.
1058.88 1060.20 SPEAKER_02  We did nothing.
1060.60 1061.34 SPEAKER_02  We did nothing.
1061.44 1062.32 SPEAKER_02  We accomplished nothing.
1062.56 1068.38 SPEAKER_02  We didn't try to accomplish anything, but our various overtures for, oh, you know, do it, but be careful.
1068.38 1076.10 SPEAKER_02  And we're, we're watching you if you're, you know, uh, some neglecting any human rights and so on and so on that did nothing that did less than nothing of trying to be the middle.
1076.34 1081.36 SPEAKER_02  Now the UK was sort of falling directly in behind the U S mostly on most things, not everything.
1081.48 1083.40 SPEAKER_02  Uh, continental Europe was a bit more varied.
1083.58 1093.44 SPEAKER_02  None of it made a difference because all you have to say is, uh, it's very clear that Trump coming in was, uh, if you, if sources are to be believed sources being quoted in Al Jazeera, for example, are to be believed.
1093.56 1094.48 SPEAKER_02  The difference was Trump.
1094.48 1097.44 SPEAKER_02  The difference was that, uh, the Israelis wanted to negotiate with Trump.
1097.44 1109.42 SPEAKER_02  And also that means that, uh, Israel is Israel time, the deal as a gift to Trump, then their entire strategic valence for being convinced to stop under undertaking a genocide was entirely geared towards America.
1109.66 1115.32 SPEAKER_02  Nobody has ever been as leverable as Israel has been in the last two years by the United States, if they wanted to do it.
1115.40 1129.50 SPEAKER_02  And to me, what this proves is that contrary to whatever fucking big brain sub stacker you might want to, you know, you might want to believe there always was an end this button in the white house that Joe Biden declined to press because he refused to be hard on Israel.
1129.86 1143.92 SPEAKER_02  Because I mean, apparently only Republicans can be tough on Israel, like Bush, Reagan, and so on, because Democrats feel as though, or have to whatever, uh, as though they will be disciplined for being too pro-Palestinian and have to prove their hardness at every turn.
1143.92 1154.50 SPEAKER_02  So, you know, I mean, this is what, this is what Mike Casey, a former U S state department official who resigned over Biden's support for the war said is that Israel time, the deal is a gift to Trump, a quote, there's domestic political consideration.
1154.52 1158.78 SPEAKER_02  And the deal itself is basically the same deal they could have agreed to in May.
1159.02 1166.14 SPEAKER_02  And that the Biden administration had no real negotiations with the Israelis because they knew the U S would ultimately just go along with whatever they wanted.
1166.32 1167.36 SPEAKER_02  And, uh, yeah.
1167.42 1173.24 SPEAKER_02  And media coverage, uh, went as far as suggesting that Trump's involvement had been the decisive factor in the breakthrough.
1173.58 1177.64 SPEAKER_03  Well, in fairness, Biden still thinks that, uh, Israel is the British Palestinian mandate.
1177.78 1179.16 SPEAKER_03  So he was deferring to us on that.
1179.46 1179.90 SPEAKER_03  Yeah.
1179.90 1182.28 SPEAKER_03  Talking to Starmer, like I did you guys a real favor here.
1182.28 1184.96 SPEAKER_00  Oh, you gotta get, get me Sykes and Pico on the line.
1185.82 1188.26 SPEAKER_01  I guess it's an uncomfortable realization.
1188.26 1200.34 SPEAKER_01  If it turns out to be true that all of the like, um, Arab voters in Michigan who like the few who like campaigned for Trump on the basis that he was more likely to get a ceasefire deal were right.
1200.50 1202.38 SPEAKER_01  And we're like completely vindicated.
1202.70 1203.14 SPEAKER_01  Yep.
1203.36 1203.58 SPEAKER_01  Yeah.
1203.66 1204.82 SPEAKER_03  He really is Mr.
1204.92 1205.32 SPEAKER_03  Deals.
1205.40 1205.94 SPEAKER_03  Isn't he?
1206.06 1211.32 SPEAKER_03  As much as, as much as he's bad for so many things, he's, he deals are his art form.
1211.32 1211.76 SPEAKER_01  Yeah.
1211.76 1224.68 SPEAKER_01  Like I think a lot about the time that he almost kind of got a, like a sort of like a new treaty with North Korea just out of boredom and then sort of got distracted by Robert De Niro being mean to him.
1227.06 1228.30 SPEAKER_01  We can have world peace.
1228.38 1231.14 SPEAKER_02  We just need to make every celebrity nice to Trump.
1231.42 1231.72 SPEAKER_02  Yeah.
1231.80 1232.16 SPEAKER_02  Basically.
1232.32 1232.56 SPEAKER_02  Yeah.
1232.72 1233.88 SPEAKER_02  Just long enough him to do it.
1233.88 1234.64 SPEAKER_02  He's like a savant.
1234.74 1235.96 SPEAKER_02  He doesn't even know he's doing it.
1235.98 1236.86 SPEAKER_02  But back to this, right?
1236.94 1249.56 SPEAKER_02  You know, this is, you know, Nova, we were talking about this a little bit earlier and you said, you know, like this is what has, again, what has happened here is, you know, Israel has proven itself to be utterly unhinged in front of the entire world that basically hasn't mattered.
1249.86 1252.44 SPEAKER_01  It's also something that Hamas has helped precipitate.
1252.56 1252.76 SPEAKER_01  Right.
1252.82 1272.66 SPEAKER_01  And if you're looking at the kind of settlement here, okay, Hamas might be, might've been kind of like largely destroyed in this process along with Hezbollah and, you know, most of Gaza, but they have kind of, it seems to me, fatally unhinged both like Israel on the world stage and like Israeli civil society just to itself.
1272.86 1288.14 SPEAKER_01  And to then end that with, well, I say end that, to end this current phase of it with negotiations and it just kind of freezes the genocide in amber at this moment is just going to be something that I think is going to just ratchet up that insanity.
1288.50 1306.74 SPEAKER_01  You know, as best I can tell, the kind of spectrum of Israeli public opinion on this ranges from, oh, okay, so we're going to have to do this again in four years time with a kind of rueful tone for the kind of left to, oh, okay, well, we're going to have to do this again in four years time with a kind of vengeful tone for the right.
1307.10 1314.94 SPEAKER_01  And so I don't know what this means other than giving a bunch of Genesides like blue balls for it effectively.
1315.32 1322.78 SPEAKER_02  What, so what the actual discussion of this has to like incorporate is what we know that Israel never had a day after plan.
1323.08 1333.22 SPEAKER_02  We know that a lot of the normalization activities that were taking place with like Gulf state neighbors that are fellow US allies and now depend on like, you know, a robust path to Palestinian statehood.
1333.46 1338.32 SPEAKER_02  We also know that the Marshall plan for this, if there's going to be one, is going to largely be coming from the Gulf.
1338.48 1340.18 SPEAKER_02  We don't know what Israel is going to do.
1340.38 1351.42 SPEAKER_02  We don't, I mean, it's unless, unless actual pressure continues to be put on them, then this is just going to happen again because Israeli civil society is, has been utterly polarized again.
1351.52 1353.44 SPEAKER_02  Not like, not like with itself.
1353.44 1355.12 SPEAKER_02  It's not like, oh, there's too much disagreement.
1355.12 1362.80 SPEAKER_02  More like they are now negatively polarized against like almost entirely negatively polarized against ever coexist.
1362.98 1365.04 SPEAKER_02  They were never like happy with coexisting, right?
1365.04 1367.66 SPEAKER_02  That's one of the reasons this, why this all went, went the way that it did.
1367.66 1373.28 SPEAKER_02  But the kind of management of the frozen conflict can't go back to how it was.
1373.28 1376.26 SPEAKER_02  Yeah, or it will just hot up again.
1376.40 1377.92 SPEAKER_02  And who's going to rebuild the schools?
1378.02 1379.18 SPEAKER_02  Who's going to rebuild the hospitals?
1379.24 1380.70 SPEAKER_02  Who's going to rebuild the water infrastructure?
1380.90 1383.20 SPEAKER_02  Are people just going to go back to living in an open air prison?
1383.30 1383.98 SPEAKER_02  I don't know.
1384.48 1391.58 SPEAKER_03  Yeah, it feels as though over time, just gradually, you get these kind of like flare ups conflicts in Israel and the surrounding area.
1391.58 1401.40 SPEAKER_03  And then eventually they kind of like stop and things go back to like scare quotes normal, but always with a like ratchet effect of like there's slightly less of Palestine or slightly less of Syria left or whatever it is.
1401.40 1406.38 SPEAKER_02  Well, I suppose then the this is why I almost don't want to say too much about it now.
1406.54 1408.56 SPEAKER_02  I also want to talk with someone who knows.
1408.70 1408.78 SPEAKER_02  Yeah.
1408.96 1409.26 SPEAKER_02  Right.
1409.52 1414.48 SPEAKER_02  In the in the coming weeks, especially as we see more things emerge right about it.
1414.54 1434.80 SPEAKER_02  But I think it's I guess because we talked about it a lot over the last couple of years, I suppose the best thing we can say is at least it appears that probably one of the most significant crimes against humanity, certainly in my living memory, appears to at least be materially stopping for now.
1435.18 1444.52 SPEAKER_02  And all of the nominally left wing progressive, whatever you want to call it, parties in the West that tried to both sides of the issue and tried to say, oh, this is all very unfortunate.
1444.52 1448.62 SPEAKER_02  They had the power to save tens of thousands of lives at a minimum.
1448.62 1450.02 SPEAKER_01  And they chose to not.
1450.22 1454.92 SPEAKER_01  Well, think about those like people at the Democratic National Convention, like kind of putting their fingers in their ears.
1455.02 1455.22 SPEAKER_01  Right.
1455.32 1465.86 SPEAKER_01  It's this is something that I think for like the center, the center left, the center right, whatever, has just kind of destroyed or should destroy any credibility that they have on.
1466.06 1470.66 SPEAKER_01  I mean, anything really, but like especially any kind of like moral aspect of foreign policy.
1470.66 1475.96 SPEAKER_01  And I think this this deserves to be like thrown back in their faces every day for the rest of their lives.
1475.96 1483.76 SPEAKER_04  My feeling is that if anything, like with sort of really ardent Democratic supporters who were very like just chose to be ignorant about everything that's happened.
1483.76 1494.02 SPEAKER_04  Like I feel like their reaction is just sort of going to be to be like more unhinged, like pro-Israel for like reasons that they don't quite understand other than like purely motivated by you didn't vote for Kamala.
1494.22 1496.46 SPEAKER_04  That's kind of I feel like that's kind of going to be it.
1496.50 1509.30 SPEAKER_04  Like the thing that really frustrated me about all of this and kind of continues to frustrate me about all of this is that like beyond like, well, a big part of like the sort of major the way that this sort of operate was entirely through like an orchestrated campaign of dehumanization.
1509.42 1517.60 SPEAKER_04  The fact that it was allowed to happen largely came out of like, and you know, when we talk about like what what's the plan for like post ceasefire, it's going to be more dehumanization, right?
1517.68 1531.00 SPEAKER_04  Like the dehumanization of the Palestinians is sort of how we kind of got to this point where you could spend over a year like going onto every social media platform and like, you know, arguably seeing like the worst thing like any like you've ever seen in your entire life.
1531.00 1539.82 SPEAKER_04  And it would just like massively increase like regardless, even as Israel like tried to block Palestinian internet access is like, well, it was still coming through, right?
1539.82 1549.96 SPEAKER_04  And the amount of people that like were denying that it was happening, that was sort of accusing the Palestinians of like making up casualties and deaths, like and saying that in a completely normal way.
1550.08 1552.38 SPEAKER_04  All of that was sort of like a display of ignorance.
1552.38 1560.78 SPEAKER_04  And then when the US election kind of came up, like there was a real desperate attempt to divorce like what was happening in Gaza with like everything else.
1560.78 1563.12 SPEAKER_04  Like they tried to frame this as like a domestic election.
1563.46 1567.16 SPEAKER_04  Kamala like barely mentioned Gaza, you know, and still won't acknowledge it.
1567.16 1570.98 SPEAKER_04  Like if anything is going to happen, I don't think there's going to be like any self-reflection of any kind.
1570.98 1577.90 SPEAKER_04  And I do imagine like a lot of the rejection of the Democrats really actually didn't have that much to do with like the Gaza policy in and of itself.
1577.90 1581.54 SPEAKER_04  It's really like a refusal to even acknowledge that it existed, right?
1581.88 1596.22 SPEAKER_01  One of the things that's really going to, I think, drive us all insane over the next few months is it's now going to be legal everywhere except Germany to notice some of the war crimes or to notice like Palestinian suffering, at least in more than an abstract level.
1596.22 1601.06 SPEAKER_01  And but not in a way that like ever indicts any of the decision makers.
1601.28 1618.48 SPEAKER_04  Well, yeah, now, well, now is like the opportunity for like the Israeli soldiers who sort of felt a little bit guilty for killing like the 50th child on their campaigns to suddenly be like, this is the perfect opportunity to like pitch myself to Netflix or to do a like Waltz of Bashir 2 type of deal.
1618.86 1621.04 SPEAKER_04  Like next season of Fowder is going to be fire.
1621.04 1621.16 SPEAKER_01  Yeah.
1623.10 1623.62 SPEAKER_01  Kill myself.
1623.62 1625.38 SPEAKER_04  There's going to be like a lot of there's going to be.
1625.50 1625.80 SPEAKER_04  Yeah.
1625.80 1630.02 SPEAKER_04  There's going to be like a Lego movie about like just like destroy Israeli soldiers.
1630.02 1630.94 SPEAKER_04  I don't fucking know.
1631.10 1632.40 SPEAKER_02  Waltz with Bashir 2.
1632.62 1633.70 SPEAKER_02  Dab with Smotrich.
1633.88 1634.20 SPEAKER_02  That's right.
1634.42 1634.56 SPEAKER_02  Yeah.
1634.66 1634.88 SPEAKER_02  Yeah.
1635.60 1635.96 SPEAKER_02  Fuck.
1636.08 1636.28 SPEAKER_01  I know.
1636.32 1636.44 SPEAKER_01  Yeah.
1636.52 1637.44 SPEAKER_01  Skibbadee with Bashir.
1637.70 1638.20 SPEAKER_04  I don't know.
1638.40 1639.30 SPEAKER_01  God damn it.
1639.82 1640.44 SPEAKER_01  Good news.
1640.52 1643.28 SPEAKER_01  It is now legal to see Palestinians as human again.
1643.40 1643.58 SPEAKER_01  Yeah.
1643.58 1646.48 SPEAKER_01  Within certain like tightly defined limits.
1646.90 1647.12 SPEAKER_01  So yeah.
1647.32 1647.54 SPEAKER_01  I mean,
1647.56 1653.00 SPEAKER_04  I mean, not also not really like, I don't know whether you saw like Keir Starmer's statement today at the time of recording.
1653.26 1653.46 SPEAKER_04  Yeah.
1653.56 1673.22 SPEAKER_04  But the very stark thing that lots of people sort of pointed out is that, well, they talked about like Israelis being massacred on October the 7th while sort of referring to Palestinians as like they lost their homes and lost their lives as if it was like, you know, there was like, there was, there were like, there was more of like an emotional, like for statements, like from British, like politician statements about like the fires in Los Angeles.
1673.58 1674.38 SPEAKER_04  Right.
1674.78 1675.30 SPEAKER_04  Um, yeah.
1675.50 1684.52 SPEAKER_04  You know, the idea of like losing your home to, I don't know, like, I don't know that I feel like there's a better way of describing like losing your home to an error to like an aerial bomb.
1684.62 1685.08 SPEAKER_04  I don't know.
1685.28 1692.80 SPEAKER_04  Personally speaking, I feel like there are other adjectives, but, um, we are, we are living in an increasing, like a society where people are like are struggling to read.
1692.80 1695.84 SPEAKER_04  So I, I'm, you know, maybe it's for lack of like synonyms available.
1696.18 1698.02 SPEAKER_02  Well, anyway, look, I think we're going to move on.
1698.02 1698.44 SPEAKER_02  Right.
1698.54 1714.26 SPEAKER_02  But you know, this, if you want a touchstone to keep yourself from, you know, going crazy, as you see reality acknowledged by, by people around you all of a sudden, then just remember that they're doing it on purpose and know your eyes are not deceiving you.
1714.46 1717.92 SPEAKER_02  I want to talk about, uh, how Keir Starmer is going to fix Britain.
1718.10 1719.54 SPEAKER_02  Oh, well, this will cheer us up.
1719.64 1719.90 SPEAKER_02  Yes.
1720.10 1721.34 SPEAKER_02  Oh, it's going to work a hundred percent.
1721.56 1728.88 SPEAKER_02  This is of course the AI strategic plan or as it's called the AI opportunities action plan.
1728.88 1732.54 SPEAKER_02  Now it has been signed off by everybody who can sign things off.
1732.54 1737.26 SPEAKER_02  It was written by a technology entrepreneur, uh, called Matt Clifford, who we'll get into.
1737.58 1739.40 SPEAKER_02  Oh, and it is, of course, the big red dog.
1739.62 1749.70 SPEAKER_02  It is, of course, being boosted, not just by Starmer, but by Peter Kyle, a man, uh, who's basically entire life is just people like big companies, seconding staff to him.
1749.78 1751.88 SPEAKER_02  Uh, we've spoken about him, of course, that Ethan shown.
1752.26 1762.92 SPEAKER_02  Now the AI strategic plan or the AI strategic opportunities plan, whatever it's called, it's here largely to fix all of the problems with Britain that are making Rachel Reeves depressed.
1762.92 1763.60 SPEAKER_02  Right.
1764.28 1786.06 SPEAKER_02  Because the, the thing to remember, right, is that the wicked problems that challenged all the underlying logic of the basic Thatcherite consensus, Thatcher Blair consensus we've been living under is that if you can't, that you need to have like growing GDP so that you can either pay down debt or you can borrow freely, or you can spend money on public services rather than servicing interest payments.
1786.06 1788.82 SPEAKER_02  That's like, and it, that works until it stops working.
1788.90 1794.60 SPEAKER_02  Then it creates a doom loop where like lowering growth means that there's less money to invest in less growth and so on and so on.
1794.68 1796.72 SPEAKER_02  We've talked about that particular doom loop forever.
1796.84 1807.88 SPEAKER_02  And the only thing that will change it is a whole bunch of free productivity, largely shooting into the UK or Mohammed bin Salman deciding to relocate Neom to Staffordshire.
1808.06 1809.96 SPEAKER_02  Those are the two things that could fix it.
1810.18 1810.74 SPEAKER_02  Toot line.
1811.08 1811.48 SPEAKER_03  Yes.
1811.60 1812.12 SPEAKER_02  There we go.
1812.34 1812.52 SPEAKER_02  Yeah.
1812.76 1813.90 SPEAKER_02  Newcastle under line.
1814.04 1814.66 SPEAKER_02  What about that?
1814.72 1815.38 SPEAKER_02  Ah, very good.
1815.38 1828.82 SPEAKER_02  Because if you boost GDP, then you're going to be able to fund all of the things that you need to fund in order to keep getting elected without having to break your own fiscal rules, which I always need to remind everybody listening and everybody with me.
1828.94 1831.04 SPEAKER_02  There's no one else that has fiscal rules like that.
1831.14 1835.00 SPEAKER_02  Other countries have fucked up rules about borrowing the U.S. debt ceiling, for example.
1835.16 1835.32 SPEAKER_02  Right.
1835.40 1841.18 SPEAKER_02  But we're, we have kind of the most fucked up that allows the most, like the least suspension on our car.
1841.26 1843.80 SPEAKER_02  So you feel every bump and pothole in the road.
1843.80 1843.96 SPEAKER_03  Yeah.
1844.04 1844.18 SPEAKER_03  Yeah.
1844.18 1847.62 SPEAKER_03  The British economy is like a Porsche 911 GT3.
1847.80 1848.70 SPEAKER_03  It's just like that.
1848.72 1851.96 SPEAKER_03  But we've taken the engine out and we've replaced it with like a hairdryer.
1852.30 1854.84 SPEAKER_03  So you just get the ride quality, but none of the horsepower.
1855.22 1856.16 SPEAKER_02  And it's awesome.
1856.40 1857.50 SPEAKER_02  And also our road is full of potholes.
1857.50 1869.86 SPEAKER_02  So that, but so this is the whole point of why we have the AI strategic plan is because if we can do the thing that boosts GDP hugely, then we will not have to make any difficult decisions on tax.
1869.98 1874.00 SPEAKER_02  We can maintain, we can basically keep being right wing, but be nice.
1874.12 1874.42 SPEAKER_02  Right.
1874.42 1878.72 SPEAKER_02  Because when the labor party has to choose between being right wing and being nice, they will choose being right wing.
1878.82 1879.30 SPEAKER_02  So there we go.
1879.44 1881.24 SPEAKER_02  That's the, that's the basic table setting.
1881.24 1886.66 SPEAKER_02  And so far, uh, they are, they are now the third most popular party in the country.
1886.66 1887.58 SPEAKER_02  Oh no.
1887.80 1895.38 SPEAKER_02  Uh, behind the Tories and reform tied on 25% each, which for like, that's also not good.
1895.66 1897.30 SPEAKER_02  Everybody hates all of them.
1897.58 1897.80 SPEAKER_02  Yeah.
1897.86 1898.48 SPEAKER_02  It's not great.
1898.54 1898.92 SPEAKER_02  Is it?
1899.00 1899.56 SPEAKER_02  No, indeed.
1899.92 1904.36 SPEAKER_02  So labor now on 24 and a recent, I believe, Savannah comrades Paul.
1904.60 1908.74 SPEAKER_02  Anyway, because AI's lines are all going up all around the world and they're all very buzzy and very exciting.
1908.88 1912.72 SPEAKER_02  Uh, we're hoping that we can do a line that's not going up is the one in Saudi Arabia.
1913.00 1913.40 SPEAKER_02  Indeed.
1913.40 1921.56 SPEAKER_02  Well, we're hoping we can do a little bit of that patented Tony Blair, a razzle dazzle where we hitch Britain's line to the industry lines.
1921.56 1924.94 SPEAKER_02  And then we take largely the crumbs that are left over to find the welfare state.
1925.08 1928.12 SPEAKER_02  So Starbird got Matt Clifford to produce a sales pitch.
1928.22 1933.12 SPEAKER_02  So Matt Clifford is a, uh, a big tech guy, but he's not himself an engineer.
1933.38 1935.50 SPEAKER_02  Um, he is more of a salesman.
1935.60 1935.84 SPEAKER_02  Oh,
1935.90 1936.72 SPEAKER_03  okay. Yeah.
1936.72 1940.04 SPEAKER_03  He's built AI economies for Ogdenville and North Haverbrook.
1940.08 1940.64 SPEAKER_03  A little bit.
1940.90 1949.04 SPEAKER_02  It's going to be a little, there's going to be a little bit of like what we've done is we've brought on a pitch man because all we know left to do is just advertise for investment.
1949.14 1949.92 SPEAKER_02  Please invest in us.
1950.10 1956.62 SPEAKER_02  Matt Clifford, he came up in like 2011 under David Cameron in like the Silicon roundabout years of like, um, of London.
1956.80 1966.60 SPEAKER_02  Uh, he was at McKinsey, went to Cambridge, MIT, and basically he founded like a company called entrepreneur first, which is like an accelerator that helps graduates launch startups.
1966.60 1968.72 SPEAKER_02  It's like a Y combinator for the UK.
1968.72 1968.80 SPEAKER_02  Okay.
1969.38 1971.74 SPEAKER_02  And so he's not himself a technologist.
1972.16 1973.64 SPEAKER_02  He is an investment promoter.
1973.82 1974.02 SPEAKER_02  Yeah.
1974.26 1974.58 SPEAKER_02  Yeah.
1974.74 1974.86 SPEAKER_02  Yeah.
1974.86 1975.02 SPEAKER_02  Yeah.
1975.02 1975.06 SPEAKER_02  Yeah.
1975.06 1976.74 SPEAKER_02  He's like the Don King of investment.
1977.20 1977.64 SPEAKER_02  Indeed.
1977.78 1978.76 SPEAKER_02  You should see this company.
1978.86 1979.96 SPEAKER_02  They're a wrecking machine.
1981.04 1985.84 SPEAKER_02  Clifford and his entrepreneur first co-founder will like, you know, talk about, Oh, I use AI in my everyday life.
1985.90 1989.40 SPEAKER_02  I use chat GPT to write storybooks that I then read to my kids.
1989.46 1990.52 SPEAKER_03  Jesus fucking Christ.
1990.58 1992.02 SPEAKER_03  That is the most fucked thing.
1992.02 1995.42 SPEAKER_03  I think anyone has ever said about AI in quite a crowded field.
1995.42 2001.96 SPEAKER_03  Nothing has ever actually viscerally annoyed me more than him using chat GPT to generate bedtime stories for his children.
2002.20 2002.92 SPEAKER_03  Make them up yourself.
2003.04 2003.14 SPEAKER_03  Yeah.
2003.34 2008.54 SPEAKER_03  Whether, whether it's true or he's lying because he thinks that sounds good either way.
2008.62 2008.70 SPEAKER_03  No,
2008.80 2011.82 SPEAKER_04  it's like, I don't imagine it's false.
2011.88 2020.22 SPEAKER_04  It's in the sense that like I've seen other tech guys, like, you know, you know, there's lots of, there's that sort of like format of like 12 AI businesses that you can set up from your home.
2020.30 2025.30 SPEAKER_04  Like one, the one that always comes up or one of them always comes up is like children's storybooks.
2025.42 2027.12 SPEAKER_04  But are entirely generated by AI.
2027.22 2033.14 SPEAKER_04  Like there's a real problem in like children's publishing right now because like as with all forms of publishing, like it pays nothing.
2033.14 2039.10 SPEAKER_04  And the amount of labor that goes into making children's books tends to be a lot higher because you've got like lots of other things to deal with.
2039.20 2054.92 SPEAKER_04  Like one of them sort of being illustrations, for example, but introduction of like GPT and other types of like image generation software like has disrupted like the children's book industry, like more than other forms of public, or at least like on this, like one of the sort of big disruptors of the publishing industry.
2054.92 2057.58 SPEAKER_04  And yeah, this is, this is like a very sort of like common problem.
2057.58 2061.22 SPEAKER_04  And one of those like things that the AI boost is doing, it really like fucks me off as well.
2061.64 2067.42 SPEAKER_04  Um, it's just like, yeah, you can get chat GPT to insert your child into like, you know, a fairy tale.
2067.52 2068.90 SPEAKER_04  So you no longer need to buy books.
2068.90 2072.26 SPEAKER_04  And it's just like, like, where, where, where, where do you, where do you begin with?
2072.64 2072.70 SPEAKER_04  Like,
2072.82 2075.34 SPEAKER_02  well, it's like we talked about in other times, right?
2075.34 2076.94 SPEAKER_02  That this is a substitute, so many things.
2076.96 2078.54 SPEAKER_02  This is a substitute for care.
2078.68 2079.00 SPEAKER_02  Yeah.
2079.10 2081.00 SPEAKER_02  Um, but this is one more thing on Clifford.
2081.14 2081.42 SPEAKER_02  Clifford.
2081.42 2083.62 SPEAKER_02  This is from politics home became the politicians.
2083.78 2085.40 SPEAKER_02  Techie in the techies wonk quote.
2085.52 2086.36 SPEAKER_02  He has cachet.
2086.52 2092.20 SPEAKER_02  He's very valued in the British tech community, which is also why he's valued by political people said Benedict Macon Cooney.
2092.44 2093.36 SPEAKER_02  Uh, wow.
2093.92 2094.48 SPEAKER_02  Wow.
2094.48 2100.62 SPEAKER_02  Um, a chief strategist for the Tony Blair Institute for global change.
2100.70 2101.66 SPEAKER_03  I hardly know.
2102.16 2103.36 SPEAKER_03  And now this is,
2103.54 2108.66 SPEAKER_02  this is the other thing about the AI policy plan. It's just the Tony Blair Institute plan.
2108.66 2111.52 SPEAKER_02  Oh, how is this going to give us ID cards?
2111.76 2115.04 SPEAKER_02  Well, that's the, that's the weird, the weird thing.
2115.26 2117.34 SPEAKER_02  Every pothole is going to have an ID card.
2117.46 2122.94 SPEAKER_02  It hasn't mentioned digital identity directly yet, but you can, you believe the next thing they announced.
2123.00 2123.26 SPEAKER_03  Yeah.
2123.40 2126.88 SPEAKER_03  Because vein popping, on Tony Blair's forehead, trying not to say ID cards.
2126.94 2127.78 SPEAKER_03  I'll tell you why, right?
2127.86 2131.98 SPEAKER_02  I'll tell you why is that there's, I've, I've, you know, I've read the 50 points there.
2132.22 2133.56 SPEAKER_02  What they are as a sales pitch.
2133.60 2139.28 SPEAKER_02  I mean, I'm going to read some of Keir Starmer speech a little later and we're going to see like how transparent of a sales pitch it is.
2139.28 2140.90 SPEAKER_02  It is saying, please invest in us.
2140.94 2144.14 SPEAKER_02  There's very little of a plan to like actually be entrepreneurial.
2144.50 2158.58 SPEAKER_02  Mostly it's a plan because when British government transformed itself into buying for something that's buying for managers a while ago that they are just, they, all they're doing is the only way they can think of, using AI is we are going to either build capacity that someone else is going to use.
2158.66 2166.50 SPEAKER_02  We don't know for how, or we are going to automate administrative and clerical activities that will like hopefully magic some material transformation into existence.
2166.84 2186.72 SPEAKER_02  Some of the plans they have for like the NHS, for example, are like, Oh, we're going to be able to do personalized medicine for people that you're going to have, or you're going to, Oh, you're going to have, your child's going to have a personalized school curriculum for all of this to work though, because all of this compute is going to be handled on central like government owned data center, like server farms, government owned.
2186.72 2188.36 SPEAKER_02  That doesn't sound very labor party.
2188.46 2195.96 SPEAKER_02  Well, this is the, they're at least going to fund, there's going to be some of what they call sovereign compute capacity, and then a huge amount of private compute capacity.
2196.10 2197.10 SPEAKER_02  So don't get me wrong.
2197.16 2198.00 SPEAKER_02  It's not that they're building much.
2198.12 2199.64 SPEAKER_02  Server stack with a big ER on it.
2199.70 2209.06 SPEAKER_02  Like, like we are, the, the sovereign compute capacity is supposed to be about the same as what Elon Musk alone has built only in Memphis.
2209.06 2209.68 SPEAKER_02  Uh huh.
2209.84 2210.96 SPEAKER_02  So big, but like,
2210.96 2216.72 SPEAKER_01  and it's been going well in Memphis in the sense of it's been giving everybody like, you know, it's been poisoning the water and so on.
2217.06 2223.34 SPEAKER_02  Oh, I mean, the rapid growth of data centers has been enormously fucking with power and water availability.
2223.34 2224.46 SPEAKER_02  And guess what?
2224.50 2228.18 SPEAKER_02  The, uh, ex-industrial parts of the States where they're all being built.
2228.28 2228.54 SPEAKER_02  Yeah.
2228.80 2233.90 SPEAKER_02  Where it's like, Oh, this data center, this, this factory used to, you know, have 4,000 jobs or whatever.
2233.90 2238.42 SPEAKER_02  This data center is going to need like five engineers, two security guards, and a guy mowing the lawn.
2238.62 2239.02 SPEAKER_02  Right.
2239.18 2242.30 SPEAKER_02  But also it like makes the power non-dependable.
2242.40 2243.76 SPEAKER_02  It uses a huge amount of water.
2243.92 2250.34 SPEAKER_02  In fact, all of the renewable capacity that we're like building now, like offshore wind and stuff, all of that will be just powering data centers.
2250.50 2250.76 SPEAKER_01  Good.
2250.96 2251.28 SPEAKER_01  Great.
2251.38 2259.24 SPEAKER_01  What if we just built all of this shit that like would otherwise pay for itself and we use it to, you know, power the wrong idea generator.
2259.64 2259.88 SPEAKER_03  Yeah.
2259.88 2260.22 SPEAKER_03  Yeah.
2260.22 2265.86 SPEAKER_03  We need to, we need to have all of this jet energy directed, uh, straight into bad children's books.
2266.22 2266.62 SPEAKER_03  Indeed.
2266.80 2267.28 SPEAKER_03  Sorry, sir.
2267.32 2268.50 SPEAKER_03  He needs a bedtime story.
2268.50 2269.84 SPEAKER_03  Fire up the generator again.
2270.10 2271.46 SPEAKER_03  She's going to blow, sir.
2271.74 2272.94 SPEAKER_03  She can't hold.
2273.66 2275.66 SPEAKER_03  We need to know what the Gruffalo did next.
2275.66 2276.28 SPEAKER_03  So what,
2276.40 2282.32 SPEAKER_02  but what I'm saying, right, is for that stuff to work is because it all AI, so much AI compute happens centrally.
2282.32 2284.34 SPEAKER_02  you need IDs for people.
2284.34 2285.84 SPEAKER_02  Ah, right.
2286.20 2288.54 SPEAKER_01  They haven't said they're going to do ID cards.
2288.54 2291.06 SPEAKER_01  The Tony Blair Institute rears its head once again.
2291.22 2291.52 SPEAKER_01  Beautiful.
2291.96 2296.40 SPEAKER_03  It's very like Jordan Belfort coded, you know, like sell, sell me this ID card.
2296.56 2299.34 SPEAKER_03  And it's like, well, prove to me who you are.
2299.44 2301.68 SPEAKER_03  Otherwise I can't sell you the ID card.
2301.82 2301.96 SPEAKER_01  Yeah.
2302.06 2302.32 SPEAKER_01  Indeed.
2302.32 2306.62 SPEAKER_01  You also think about this in the context that the online safety act is about to come in.
2306.72 2309.76 SPEAKER_01  You're going to need like two forms of ID to use Pornhub.
2309.98 2313.66 SPEAKER_01  So everything is coming together for you to need a gooning license.
2313.96 2314.12 SPEAKER_01  Yeah.
2314.24 2317.86 SPEAKER_02  Once they bring in the gooning license, the search for just normal.
2317.86 2321.02 SPEAKER_02  thanks on Pornhub goes up by 1 million percent.
2322.12 2323.14 SPEAKER_02  Regular sex.
2324.04 2326.10 SPEAKER_03  The number one Pornhub search.
2326.12 2327.32 SPEAKER_02  The number one Pornhub search.
2327.46 2329.70 SPEAKER_02  Actually just that girl that does the calculus lectures.
2330.04 2330.22 SPEAKER_03  Yeah.
2330.88 2332.26 SPEAKER_03  Appropriately aged woman.
2332.54 2334.94 SPEAKER_03  Searching for the articles on Pornhub.
2336.04 2341.50 SPEAKER_02  Fucking, fucking Alito being like, well, does Pornhub do, do they have like Norman Mailer articles on there?
2341.52 2342.76 SPEAKER_01  Yeah, he said it was Gore Vidal.
2342.94 2345.96 SPEAKER_01  I would love to be the Gore Vidal of Pornhub, you know?
2346.24 2346.52 SPEAKER_01  Yeah.
2347.86 2349.76 SPEAKER_01  Gore Vidal, is that anything?
2349.94 2350.68 SPEAKER_02  Pretty good.
2350.76 2351.52 SPEAKER_02  Norman Rayler.
2352.24 2357.08 SPEAKER_02  We're redoing the Gore Vidal, William F. Buckley debates, but they're nude.
2357.46 2357.68 SPEAKER_02  Yeah.
2358.04 2358.18 SPEAKER_02  Yeah.
2358.82 2359.90 SPEAKER_02  Bill B. Fuckley.
2360.12 2360.30 SPEAKER_02  Yeah.
2360.46 2361.18 SPEAKER_02  Thank you very much.
2361.22 2361.66 SPEAKER_02  You got there.
2361.74 2361.88 SPEAKER_02  Yeah.
2362.04 2362.26 SPEAKER_02  All right.
2362.26 2363.16 SPEAKER_02  So what's the plan?
2363.26 2368.88 SPEAKER_02  For the most part, the recommendations largely are around expanding skills and training, which the British government has.
2368.88 2368.98 SPEAKER_01  It's not a plan.
2369.06 2369.80 SPEAKER_02  That's a goal.
2370.06 2370.46 SPEAKER_02  Has tried.
2370.46 2371.46 SPEAKER_02  Well, that's the other thing, right?
2371.54 2374.22 SPEAKER_02  The plan, that's like one of the themes, right?
2374.26 2375.08 SPEAKER_02  There are 50 points.
2375.38 2378.94 SPEAKER_02  The high level themes are liberalizing data sharing, right?
2378.98 2382.36 SPEAKER_02  So being like, okay, the national biobank, that's got an API on it.
2382.40 2384.60 SPEAKER_02  If you want to use that to train an AI, fucking go ahead.
2384.80 2385.08 SPEAKER_02  Right.
2385.16 2385.46 SPEAKER_02  Okay.
2385.58 2385.82 SPEAKER_02  Yeah.
2385.88 2400.40 SPEAKER_02  And they're also saying specifically, they're taking an example from Jeff Bezos at Amazon, where they're saying everything that the government is going to do has to have an API, which means you should be able to API call basically whatever, which again is saying, please, we will give you any amount of information.
2400.74 2402.56 SPEAKER_02  If you are an AI company, you can have it all.
2402.56 2408.90 SPEAKER_02  So liberalizing data sharing, number one, and like finding data sets that they can like open up in this way, expanding skills and training.
2409.02 2420.54 SPEAKER_02  But again, we've seen why you say you want to expand skills and training while also making like the main way people gain skills and training universities while making them what like less funded and more expensive.
2420.98 2422.18 SPEAKER_02  That's not addressed here.
2422.40 2429.56 SPEAKER_02  Mostly they're like, oh, we'll do, you can do like a, like a, like a, like a course, you know, or we're going to fund like some high level scholarships for like elite talent.
2429.56 2434.88 SPEAKER_02  But like the idea of actually like expanding most people's skills in a meaningful way.
2434.98 2435.82 SPEAKER_02  No, it's not in here.
2436.44 2442.80 SPEAKER_02  Encouraging regulators and government departments to use AI, which will have hilarious effects and encouraging public private partnerships around AI.
2442.98 2453.82 SPEAKER_02  So it's like this transformative plan that is the labor party's last hope and their ace in the hole seems mostly about stuff that, that every government has tried to do for fucking ever.
2454.16 2454.30 SPEAKER_02  Great.
2454.52 2454.66 SPEAKER_02  Yeah.
2454.72 2454.96 SPEAKER_02  Yeah.
2455.10 2455.38 SPEAKER_02  Good.
2455.54 2456.48 SPEAKER_02  Well, more of the same.
2456.48 2462.06 SPEAKER_02  But for example, instead of establishing like free ports, they're establishing something called AI growth zones.
2462.34 2465.60 SPEAKER_01  Wasn't, wasn't one of the things using AI to detect potholes?
2465.98 2466.26 SPEAKER_01  Yes.
2466.28 2467.18 SPEAKER_01  I looked into that.
2467.38 2475.34 SPEAKER_01  And yeah, because like, I remember potholes being the like sort of flagship policy of John Major's comedy government.
2475.70 2480.40 SPEAKER_01  So John Major's comedy government roadshow, but it keeps hitting potholes.
2480.90 2481.42 SPEAKER_02  Yeah.
2481.52 2483.70 SPEAKER_02  So the potholes, that's an interesting example.
2483.70 2489.36 SPEAKER_02  There are in addition, like, cause it's the, cause it's the British government or it's specifically the labor party in the British government.
2489.52 2493.22 SPEAKER_02  They're doing a whole bunch of stuff, all of which is actually pretty small.
2493.22 2495.40 SPEAKER_02  And it's all been announced kind of piecemeal.
2495.50 2496.52 SPEAKER_02  So you don't know what it is.
2496.56 2499.92 SPEAKER_02  So everyone's heard of the potholes thing, for example, but no one actually knows what it is.
2499.96 2507.24 SPEAKER_02  Is what, there were 120 small pilot programs for like organizations to use AI to like, you know, just fix a problem.
2507.36 2507.74 SPEAKER_02  Right.
2507.82 2509.08 SPEAKER_02  So I'll go to the pothole thing.
2509.08 2512.60 SPEAKER_02  So it's from 120 pilot projects where organizations use AI for different things.
2512.78 2514.94 SPEAKER_02  And so they say, yeah, it can spot potholes more quickly.
2515.28 2522.22 SPEAKER_02  And then in fact, the example that they use is that, is that there is one like council, it's road testing AI tool that will predict potholes before they form.
2522.32 2526.40 SPEAKER_02  So roads can be repaired earlier and more cheaply before they cause damage to vehicles.
2526.40 2531.62 SPEAKER_02  And in that same list, we're saying, oh, we also have an AI model that anticipates where mold is likely to go in buildings.
2531.72 2534.04 SPEAKER_02  So they can be remediated before they become a health and safety issue.
2534.04 2542.50 SPEAKER_02  And in both of those cases, you're not addressing the fact that what's actually happening is, it doesn't matter when you tell the person who owns the commercial building, that mold is going to form.
2542.56 2543.56 SPEAKER_02  It doesn't matter if it's formed.
2543.64 2546.06 SPEAKER_02  It doesn't matter if it's like killed five people who work there.
2546.14 2547.42 SPEAKER_02  They're not going to fucking fix it.
2547.64 2551.36 SPEAKER_03  What I'm saying to the people of Britain is that I will fill any hole.
2551.74 2555.52 SPEAKER_03  If there's a hole that needs filling, I will go there for this labor government.
2555.70 2556.90 SPEAKER_03  Any hole is a goal.
2557.04 2558.48 SPEAKER_03  And I want that to be very clear.
2559.36 2559.76 SPEAKER_02  Right.
2559.76 2565.90 SPEAKER_02  So it's how like in a country that has so much mold in its building, because landlords won't fix them.
2566.24 2571.04 SPEAKER_02  What is the point of telling them three months beforehand where the mold is going to form?
2571.14 2571.22 SPEAKER_02  Yeah.
2571.28 2572.50 SPEAKER_02  The mold precog.
2572.80 2573.66 SPEAKER_02  What's the point?
2573.74 2574.66 SPEAKER_02  Why would you bother?
2574.66 2576.40 SPEAKER_03  Might make some of the lawsuits easier, I suppose.
2576.68 2576.98 SPEAKER_02  Yeah.
2577.38 2583.80 SPEAKER_03  Tom Cruise running around telling the most disinterested man in a string vest that there's actually going to be mold growing in one of his apartments.
2583.94 2585.10 SPEAKER_03  And he's like, yes, that's about right.
2585.86 2593.08 SPEAKER_02  So they say, oh, we're going to use AI to cut food waste at a bakery by accurately predicting sales and forecasting how much of each product needs to be made daily.
2593.08 2595.24 SPEAKER_03  What kind of fucking Balamori-ass scheme is this?
2595.34 2597.14 SPEAKER_03  Reducing food waste at the bakery.
2597.44 2597.86 SPEAKER_03  What next?
2597.98 2599.22 SPEAKER_03  Fire at the old mill.
2599.52 2601.52 SPEAKER_03  Fucking dog stuck down a well.
2601.82 2602.00 SPEAKER_03  Like,
2602.04 2603.84 SPEAKER_02  what else are we going to solve? Yeah.
2603.88 2606.88 SPEAKER_02  Well, and also like, yeah, that's, that's so small time.
2607.12 2610.20 SPEAKER_02  And also most places, there are ways to predict food waste.
2610.32 2612.90 SPEAKER_02  How many, what kind of a marginal problem are you solving?
2613.00 2615.90 SPEAKER_02  How much compute do you need versus how much food waste are you saving?
2616.08 2617.72 SPEAKER_02  Anyway, so that's the plan at the high level though.
2617.86 2628.30 SPEAKER_02  And the other thing I think is very amusing is that science, business and technology secretary, Peter Kyle, uh, has said he will quote, take personal responsibility for anything that goes wrong as the UK rapidly adopts AI.
2628.86 2629.14 SPEAKER_02  Great.
2629.52 2629.72 SPEAKER_02  Cool.
2629.82 2630.54 SPEAKER_02  Thanks, Peter.
2630.78 2632.56 SPEAKER_02  Yeah, definitely, definitely cool.
2632.82 2641.32 SPEAKER_02  Uh, yeah, he said, uh, during the development of the government's experimental chat bot last year, he insisted on staying close to the process, despite officials telling him to please not do that.
2641.70 2643.32 SPEAKER_01  I was bothering people.
2643.42 2644.78 SPEAKER_01  I was annoying people.
2644.78 2647.90 SPEAKER_01  I was doing all of the things that you would hope that I might not do.
2648.16 2651.86 SPEAKER_02  I said, it was very important to me to say to officials that I'm not going to stay away.
2652.08 2653.06 SPEAKER_02  I want to embrace it.
2653.12 2656.42 SPEAKER_02  And I want to be the person that explains to the public what we're doing and what could go wrong.
2656.56 2662.22 SPEAKER_02  I said, I will be the person that fronts up anything that comes out of this, that could be embarrassing or challenging or could go wrong with this kind of development.
2662.22 2668.38 SPEAKER_02  But by the next election, people will be much more aware of AI and how AI is interacting with the services they use.
2668.54 2670.94 SPEAKER_02  That's definitely going to be a winning message.
2671.38 2672.44 SPEAKER_00  Be aware of AI.
2672.58 2672.70 SPEAKER_00  Yeah.
2672.90 2673.08 SPEAKER_02  Yeah.
2673.08 2674.56 SPEAKER_02  This is the actual announcement.
2674.56 2681.32 SPEAKER_02  where Starmer says, artificial intelligence will be, this is an actual quote from the actual speech, mainlined into the veins of the nation.
2681.64 2681.84 SPEAKER_02  Boo.
2682.06 2682.52 SPEAKER_02  Amazing.
2682.94 2683.14 SPEAKER_02  Yeah.
2683.36 2687.74 SPEAKER_02  We've had to shoot artificial intelligence into the aisles of Skilly near the nation's toes.
2688.42 2689.70 SPEAKER_02  We've run out of veins.
2689.94 2691.36 SPEAKER_03  A lot of the veins have collapsed.
2691.48 2694.90 SPEAKER_03  We will, we are prepared to inject AI into the nation's penis.
2695.34 2701.86 SPEAKER_03  If we run out of AI, we are prepared to make a synthetic AI using bits of old spreadsheets and lighter fluid.
2702.30 2704.56 SPEAKER_03  This can have a necrotic effect on the flesh.
2704.56 2708.56 SPEAKER_03  If you miss the vein, we're going to be shooting it into East Anglia.
2708.62 2711.66 SPEAKER_03  We're going to put the nation into a big bath, shoot it full of AI.
2711.82 2713.14 SPEAKER_03  And it's going to go, oh, fuck yeah.
2713.14 2713.98 SPEAKER_02  That's the good stuff.
2713.98 2722.38 SPEAKER_02  He says, waiting times in the NHS, we will use AI to cut them by filling appointments patients can no longer make and quickly rescheduling.
2722.48 2723.68 SPEAKER_02  Or take your children's schooling.
2723.90 2728.56 SPEAKER_02  We will expand opportunities for teachers to use AI to personalize lessons specifically to your child's needs.
2728.68 2729.84 SPEAKER_02  The possibilities are endless.
2729.84 2735.72 SPEAKER_02  And also, it's like we've heard for years now, actual years, that like personalized lessons are just around the corner.
2735.92 2738.80 SPEAKER_02  But also like, how personalized could lessons be?
2738.96 2740.40 SPEAKER_02  Children are like developing.
2740.74 2745.26 SPEAKER_02  Part of what they're learning is how to interact with each other, how to share knowledge, how to be together.
2745.42 2752.42 SPEAKER_02  And it's like, oh yeah, no, you actually, you should put yourself into like a box where you're going to be learning completely privately with like a mirror, essentially.
2752.78 2753.50 SPEAKER_01  This will be cool.
2753.54 2755.30 SPEAKER_02  And then you can take a break from that and go on TikTok.
2755.72 2756.88 SPEAKER_02  So it's all good.
2757.08 2759.70 SPEAKER_02  AI can support small businesses with their record keeping.
2759.82 2761.14 SPEAKER_02  It can spot potholes more quickly.
2761.42 2763.00 SPEAKER_02  It can speed up planning applications.
2763.42 2764.56 SPEAKER_02  And to get written building again,
2764.68 2771.78 SPEAKER_01  can it speed up a planning application? By lying about how good a bunch of like, you know, shit dumped into a river is for the fish.
2772.24 2772.68 SPEAKER_01  Again,
2772.68 2783.76 SPEAKER_02  like there is this constant, I would say delusion on the part of the economic and political managers of Britain, that if you can just make it easier to build, then more people will build.
2784.12 2788.72 SPEAKER_02  And while that is in the one sense true, it's not because our planning process isn't simple enough.
2788.78 2791.14 SPEAKER_02  It's because it's actually, there aren't enough planners.
2791.14 2793.38 SPEAKER_02  Like there's no one actually doing the planning.
2793.54 2800.02 SPEAKER_02  And so what happens is it gets like left to people who object to the idea of building any, it gets left to that fucking brewery owner.
2800.02 2801.10 SPEAKER_02  Uh, Humphrey.
2801.10 2801.80 SPEAKER_02  Yeah, yeah, yeah.
2802.10 2803.88 SPEAKER_02  Fucking, uh, Humphrey, uh, Mr.
2803.88 2805.40 SPEAKER_03  Tom Smith or whatever.
2805.54 2806.12 SPEAKER_02  Yeah, yeah, yeah.
2806.24 2807.60 SPEAKER_03  Tom Smith makes the crackers.
2807.74 2808.26 SPEAKER_03  Sam Smith.
2808.46 2808.58 SPEAKER_02  Yeah.
2808.66 2809.72 SPEAKER_02  It's left to Humphrey Smith.
2809.94 2810.12 SPEAKER_02  Yeah.
2810.24 2813.14 SPEAKER_02  To just be like, well, there's no planning and authority in the country.
2813.14 2814.42 SPEAKER_02  So I guess I'll just say no to everything.
2814.52 2815.34 SPEAKER_02  I don't understand.
2815.34 2823.36 SPEAKER_02  It's never made clear in any of these speeches that Starmer and, or Kyle or even Matt Clifford is supposed to be like the tech person fronting this all up.
2823.38 2826.64 SPEAKER_02  Give, there's no indication how all of this is to happen.
2826.74 2828.16 SPEAKER_03  I've got Humphrey Smith on board.
2828.28 2831.58 SPEAKER_03  There aren't going to be any potholes where we cobblestone all of the streets.
2831.58 2836.36 SPEAKER_03  There won't be any light bulb problems when we change all of the streetlights to be gas lamps.
2836.62 2840.08 SPEAKER_03  We're going to 19th century max, the United Kingdom.
2840.30 2841.36 SPEAKER_03  That's when we were great.
2841.36 2844.50 SPEAKER_03  Public executions are coming back.
2844.66 2846.48 SPEAKER_02  They say the tie, the bloody code.
2846.64 2849.42 SPEAKER_02  Uh, we've got chat GPT to rewrite a version for 2025.
2849.70 2851.22 SPEAKER_02  We're going to send people to Australia.
2852.36 2855.50 SPEAKER_02  Everyone's committing minor crimes for some reason.
2855.60 2856.04 SPEAKER_02  All of a sudden.
2856.32 2856.50 SPEAKER_02  Yeah.
2856.74 2865.00 SPEAKER_02  So, but he says in the years ahead, barely any of our aspect of our society will remain untouched, but they have never said how they've never said specifically.
2865.26 2866.06 SPEAKER_02  Here's what we're going to do.
2866.16 2869.94 SPEAKER_01  It's just going to change stuff in a way that we don't really know about.
2870.02 2870.44 SPEAKER_01  And that's fine.
2870.44 2882.54 SPEAKER_02  Like how many reports from the Tony Blair Institute or the British government have we ever read that say we're going to be rolling out rapid prototyping of technological solutions that will transform the way the DWP cuts your benefits or whatever.
2882.68 2883.88 SPEAKER_02  How many of those have we read?
2883.90 2887.46 SPEAKER_01  It's like reading a development proposal for like Jurassic Park, right?
2887.54 2892.28 SPEAKER_01  It's like, well, it's going to be transformative, uh, on the basis of some untested technology.
2892.66 2894.30 SPEAKER_01  Uh, and we're rolling it out everywhere.
2894.48 2895.20 SPEAKER_01  So it should be fine.
2895.30 2895.48 SPEAKER_01  Yeah.
2895.48 2900.96 SPEAKER_03  Watching like a 60 foot high pothole filling Asimo walking over the horizon and going,
2901.18 2903.00 SPEAKER_00  they did it. The crazy bastards.
2903.20 2903.76 SPEAKER_00  They did it.
2904.68 2906.88 SPEAKER_02  You know, and so Starmer go back to his speech, right?
2906.94 2910.76 SPEAKER_02  Says, if you're sitting around the kitchen table tonight, worry about opportunity at your children's school.
2910.98 2914.40 SPEAKER_02  AI can help teachers plan lessons tailored to their specific needs.
2914.40 2916.26 SPEAKER_03  Oh, please fuck off gear.
2916.38 2916.76 SPEAKER_03  Please.
2916.84 2919.42 SPEAKER_03  For the love of God, his heart's not even in it.
2919.54 2919.66 SPEAKER_01  Yeah.
2919.70 2920.70 SPEAKER_03  He doesn't have the source.
2920.80 2921.84 SPEAKER_01  He knows it's bullshit.
2922.08 2925.74 SPEAKER_01  He's, he's seen the glory of the toboggan in the Ballyaric islands.
2925.84 2927.72 SPEAKER_01  And he's like, he's still there mentally.
2927.80 2928.44 SPEAKER_02  He wants to go back.
2928.50 2932.58 SPEAKER_02  It's like, what also like, Oh, lesson plans tailored to your children's specific needs.
2932.66 2938.58 SPEAKER_02  Again, this is something that was like, we're trying to magic additional virtual teachers into existence, right?
2938.62 2941.28 SPEAKER_02  By saying, well, a teacher with an AI is like 10 teachers.
2941.46 2947.98 SPEAKER_02  So actually the teacher is going to be more like a manager of a bunch of, AIs that are individually teaching students, which is a fucking fantasy.
2948.26 2951.12 SPEAKER_02  That's a fantasy, but it's a cheaper fantasy.
2951.30 2952.08 SPEAKER_02  Well, precisely.
2952.42 2955.34 SPEAKER_02  Or is it even it's cheaper in their fantasy.
2955.34 2958.92 SPEAKER_02  It is cheaper to build one exascale computer.
2958.92 2960.88 SPEAKER_02  Now that employs 200 people.
2960.94 2963.06 SPEAKER_02  Give a man an exascale computer.
2963.50 2968.92 SPEAKER_02  You know, it's cheaper to do that than to like have an education system forever.
2968.92 2969.28 SPEAKER_02  Right.
2969.68 2970.96 SPEAKER_01  Well, the thing about kids is right.
2971.04 2973.80 SPEAKER_01  They keep fucking showing up asking you to educate them.
2973.80 2977.86 SPEAKER_01  Whereas if you, if you just stick them in front of a computer, then it's not your problem anymore.
2978.08 2984.22 SPEAKER_02  Well, yeah, you, and you don't have to, you ultimately write the higher setup costs with the exascale computer.
2984.22 2989.52 SPEAKER_02  And then like the app that's built by, you know, lunch or whatever, a lunch education.
2989.76 2993.56 SPEAKER_02  That's like, Oh, we're going to tailor the exact math lesson to, you know, little Timmy.
2993.78 2998.60 SPEAKER_02  It's easier to imagine that than being like, we need to pay teachers more and hire more of them.
2998.66 3003.88 SPEAKER_02  We need to hire more teaching assistants because that doesn't actually cost as much as the exascale computer, but it's not cool.
3004.00 3005.20 SPEAKER_02  And it's not futurey.
3005.42 3006.78 SPEAKER_02  And it's kind of lame.
3006.78 3009.24 SPEAKER_02  So we're hoping we can go a to D.
3009.34 3009.88 SPEAKER_02  It's also like,
3009.88 3017.10 SPEAKER_04  I mean, obviously this is just like trying to fast track, getting the lineup to like, uh, make sure that all the better help, like, you know, stuff that Rachel Reeves is doing can be paid for.
3017.30 3019.00 SPEAKER_04  But it's also just like, I find it number one.
3019.04 3021.94 SPEAKER_04  I find it very funny that this is like a very, especially with schools and stuff.
3021.96 3025.80 SPEAKER_04  It's like, well, how can you show your disdain towards children in a way that also makes the line go up?
3025.82 3026.26 SPEAKER_04  And that is okay.
3026.26 3032.48 SPEAKER_04  You just get a computer to like fast track their sort of bizarre racism that will inevitably emerge out of like the AIs that they produce.
3032.82 3038.92 SPEAKER_04  Um, but the second part of it is also just like, as again, it's like very much like you're not really thinking about what you, what you're actually trying to do here.
3038.92 3049.12 SPEAKER_04  And the only conclusion I can sort of reach is like, well, what you're actually trying to do is a signal to AI investors that like you want Britain, you want, you want the UK to sort of be the place where everyone parks their AI money.
3049.28 3050.86 SPEAKER_04  It doesn't matter what type of project they do.
3050.98 3053.64 SPEAKER_04  It doesn't matter like whether it's sort of conducive to any public good.
3053.64 3068.18 SPEAKER_04  It also doesn't really matter how much energy it uses up or, you know, and that's like a big thing too, because like, how does this sort of fit with like any of like what Ed Miliband wants to do in terms of like expanding capacity, but also like the sort of at least the, um, the gestures towards moving to green energy.
3068.18 3073.18 SPEAKER_04  Like I don't, I feel like that's going to be the next climb down because it's going to be like, well, we can't have any of this cool AI stuff.
3073.26 3079.32 SPEAKER_04  We can't have like the warehouse of AI girlfriends if like we want to sort of not, you, you know, without like the fossil fuels.
3079.38 3081.96 SPEAKER_04  And so we're going to like step down on those ambitions as well.
3081.96 3082.26 SPEAKER_04  Right.
3082.40 3082.64 SPEAKER_04  Um,
3082.64 3083.32 SPEAKER_00  it just, it does,
3083.32 3097.88 SPEAKER_04  it does just sort of feel like this is very much a, how do you get like, especially in this particular climate, um, and where the interest rates won't go down at all, despite how much we would like them to, how do you get this like quick injection into the economy to sort of like make it feel like things are good.
3097.92 3110.18 SPEAKER_04  The most obvious answer and the most plausible answer to all of this is like, you want to sort of kind of prove that you are a growth government, which is like your sort of main goal that you've stated, but you don't actually want to do anything or you don't actually want to do the work to do anything.
3110.18 3112.34 SPEAKER_04  You don't want to do any like coalition building to do anything.
3112.34 3115.64 SPEAKER_04  You don't want to like, you know, build any infrastructure to like kind of cement.
3115.72 3129.46 SPEAKER_04  Cause like, you know, for all the sort of problems of the nine of the, of the, like the Blair labor governments, like the thing that it did very well was to sort of like really focus in on like the institutions and sort of build those institutions around the new labor model in a way that like has been still like fairly difficult to dismantle.
3129.46 3129.72 SPEAKER_04  Right.
3129.78 3131.82 SPEAKER_04  Like they were sort of at least good on the politics side.
3132.04 3133.94 SPEAKER_04  These guys aren't good at the politics side.
3134.04 3135.48 SPEAKER_04  They just want the number to go up.
3135.50 3145.92 SPEAKER_04  And it is like truly, truly insane to see them like take such a bet that like, you know, from the outset based on all the stuff that we've seen, like with crypto and NFTs and all that stuff, like this is not going to work.
3145.92 3150.06 SPEAKER_04  And like, you are just biding your time until like everyone kind of has to admit that.
3150.10 3151.62 SPEAKER_04  And like, will they ever admit they're wrong?
3151.72 3152.20 SPEAKER_04  No, I am.
3152.30 3158.42 SPEAKER_04  I, I'm very much looking forward to like them sort of blaming the British public for not allowing the AI revolution to happen.
3158.42 3161.74 SPEAKER_04  I keep going back to like what happened to fucking Silicon Roundabout.
3161.86 3165.34 SPEAKER_04  Remember like George Osborne and lighting wanting to build Silicon Valley on old street.
3165.34 3169.64 SPEAKER_04  And like the legacy of that has just been like a perpetual roadworks and nothing else.
3169.90 3170.00 SPEAKER_03  Yeah.
3170.00 3173.32 SPEAKER_03  Well, they built like a, like a bit of grass on top of the entrance to the street.
3173.62 3174.62 SPEAKER_03  It makes it, it makes it,
3174.62 3181.98 SPEAKER_04  it makes it incredibly difficult to use a train station or the tube station because in order to go on like one side, you have to like cross the road.
3182.08 3186.60 SPEAKER_04  I got to cross the roundabout, like depending on what side you want to go on, you can't actually do it within the station.
3186.60 3188.06 SPEAKER_04  And they got it out of the station as well.
3188.06 3189.96 SPEAKER_04  Like anyway, I could go on for old street for HSP.
3189.96 3194.54 SPEAKER_03  Sadiq Khan wants you to circle the tube station like it's the car bug because it's part of the Islamification.
3194.82 3195.82 SPEAKER_02  The other thing is right.
3195.92 3198.90 SPEAKER_02  What we didn't get Silicon Valley like the U S did.
3199.10 3206.38 SPEAKER_02  We did get something, which is a huge number of like large, like a lot of biotechnology and actually quite a few AI startups that are connected to like Cambridge.
3206.56 3206.92 SPEAKER_02  Right.
3206.96 3207.54 SPEAKER_02  That happened.
3207.62 3208.58 SPEAKER_02  It wasn't what they planned.
3208.64 3209.38 SPEAKER_02  It wasn't what they wanted.
3209.44 3210.90 SPEAKER_02  It's not what Matt Clifford promoted.
3211.04 3214.20 SPEAKER_02  It's what happened because that's where a huge fucking amount of public money was.
3214.30 3214.50 SPEAKER_02  Yeah.
3214.50 3215.52 SPEAKER_02  Nevermind like that.
3215.52 3219.98 SPEAKER_02  But it's, as you say, like with labor, what they want is they want this to be a magic bullet.
3220.10 3221.36 SPEAKER_02  They want this to be a wizard.
3221.50 3223.80 SPEAKER_02  They want wizards privilege, sorry, magicians privilege.
3223.90 3224.30 SPEAKER_02  Excuse me.
3224.34 3224.46 SPEAKER_02  Yeah.
3224.62 3225.52 SPEAKER_02  To solve the problem.
3225.64 3230.12 SPEAKER_02  You know, even when we say like, Oh, it's going to alert, you know, someone to come fill a pothole before it forms.
3230.22 3231.76 SPEAKER_02  The councils are still bankrupt.
3232.02 3233.46 SPEAKER_02  Who's going to fill the pothole?
3233.64 3237.28 SPEAKER_02  Why does it matter when you tell them if no one fills it at all ever?
3237.42 3238.70 SPEAKER_02  Batman, he's real.
3238.90 3240.60 SPEAKER_03  And he's going to fill the potholes.
3240.62 3241.28 SPEAKER_03  And he's British.
3241.28 3242.50 SPEAKER_03  I have spoken to.
3242.74 3243.70 SPEAKER_03  I'm British Batman.
3244.12 3245.14 SPEAKER_03  Where are the potholes?
3245.24 3246.00 SPEAKER_03  Where are they?
3246.10 3246.24 SPEAKER_02  Yeah.
3246.30 3247.22 SPEAKER_02  Where are the potholes?
3247.40 3252.68 SPEAKER_02  And so it doesn't matter if you tell a bankrupt council where the potholes are going to be.
3252.80 3261.06 SPEAKER_02  They still won't get filled because the actual investment in the doing of things, rather than the management of the doing of things, has just never been available.
3261.34 3263.06 SPEAKER_02  You're saying to me that I don't have a plan,
3263.28 3268.32 SPEAKER_03  but look what I've got up my sleeve. It looks like one handkerchief, but oh no, there's another one tied to the end of it.
3268.36 3270.74 SPEAKER_03  And look, as I pull it out further, more and more handkerchiefs.
3270.80 3271.60 SPEAKER_03  What's that in my hat?
3271.68 3272.32 SPEAKER_03  It's a rabbit.
3272.54 3273.54 SPEAKER_03  You're like, what is that?
3273.64 3274.86 SPEAKER_03  Poof, smoke, I'm gone.
3275.58 3276.94 SPEAKER_03  I'm already on a toboggan.
3277.02 3278.22 SPEAKER_03  There's no point getting mad at me.
3278.36 3285.00 SPEAKER_02  He also says it will reduce job center form filling, halve the time social workers spend on paperwork, help in the fight against tax avoidance.
3285.00 3290.48 SPEAKER_02  Why is the problem with the job center the form filling and not the fact that you can't get any money at the end of the form?
3290.78 3292.10 SPEAKER_03  Well, I don't know about it.
3292.10 3294.82 SPEAKER_02  The forms are like a bit arduous, but that's not really the point.
3295.00 3296.28 SPEAKER_02  Can I check if it addresses that?
3296.32 3296.66 SPEAKER_02  Oh, okay.
3296.72 3296.86 SPEAKER_02  Yeah.
3297.16 3297.52 SPEAKER_02  Okay.
3297.92 3298.80 SPEAKER_02  Job center.
3298.92 3299.40 SPEAKER_02  Is there more?
3299.48 3300.38 SPEAKER_02  No, there won't be more money.
3300.54 3300.96 SPEAKER_02  Oh, okay.
3301.16 3302.14 SPEAKER_02  No, no, no, no.
3302.30 3307.70 SPEAKER_02  The, again, the idea is like what by, by making everything more efficient, we can just squeeze more out of less.
3307.70 3309.38 SPEAKER_02  That's on and on and on.
3309.42 3310.04 SPEAKER_02  It goes with this.
3310.16 3311.84 SPEAKER_02  And that's the irony of the AI.
3312.06 3316.96 SPEAKER_02  It will make public services more human and reconnect staff with the reasons they came to public service in the first place.
3317.08 3317.82 SPEAKER_02  And I mentioned this.
3317.86 3319.06 SPEAKER_02  I want to talk about cuts, right?
3319.06 3326.96 SPEAKER_02  Reeves was poised to, and likely still will make enormous cuts to disability benefits to just trying to get 3 billion pounds worth of people fit for work at the same time this is happening.
3327.10 3336.70 SPEAKER_02  So this capacity has to be built, which is basically administer more management and administrative capacity, which includes like its compute capacity, the skills to run and all this stuff that will be better at directing in theory.
3336.70 3342.94 SPEAKER_02  If it works work and performing clerical activities to record work or to like inscribe things onto the administrative state.
3342.94 3349.80 SPEAKER_02  But we're still cutting the substantive material things or that support for people or just the ability of a council to fill a pothole.
3349.80 3357.38 SPEAKER_02  So it's where the information environment, again, if this all works is improving by an order of magnitude at the expense of the material environment.
3357.52 3359.20 SPEAKER_02  It's purely imaginary.
3359.20 3360.40 SPEAKER_02  Yeah,
3360.40 3361.18 SPEAKER_03  that's good, isn't it?
3361.52 3370.96 SPEAKER_03  It's also like when you're doing things like cutting disability benefits, it's sort of like when you say like you're cutting unemployment benefit or something, you can at least notionally say like, oh, well, we're going to, we're going to get more people into work or whatever.
3371.02 3374.20 SPEAKER_03  When you're cutting disability benefits, are you going to make less people disabled?
3374.42 3377.12 SPEAKER_03  Like what is, what is even the notional plan there?
3377.30 3380.30 SPEAKER_01  You're just going to like push them to, you know, work harder.
3380.48 3384.58 SPEAKER_01  It's the same thing as the Blair thing about people self-diagnosing with depression, right?
3384.64 3387.14 SPEAKER_01  I'm going to self-diagnose with depression after reading this.
3387.26 3387.48 SPEAKER_01  Yeah,
3387.60 3389.56 SPEAKER_02  I'm right there with you. Again and again, right?
3389.66 3397.02 SPEAKER_02  This is the only thing that they are willing to do is work with expanding administrative power at the expense of material power.
3397.12 3402.58 SPEAKER_02  This is why I always go back to like things like, you know, 14th century or 15th century Byzantium, right?
3402.58 3415.80 SPEAKER_02  This like elaborate administrative state with its like many units and functions and officials and high titles and schemes that is ultimately having a materially negligible effect on the territory that it controls or notionally controls,
3415.88 3419.66 SPEAKER_03  barely controls any territory. Kier Starr was going to have to start castrating his advisors.
3420.34 3421.86 SPEAKER_03  Bad news for Morgan McSweeney.
3422.94 3433.78 SPEAKER_02  But ultimately, right, you're trying to magically make enough growth happen that you can do the third way progressivism of the 90s, which means you fund some things without being confrontational with like global financial markets at all.
3433.96 3437.44 SPEAKER_02  And then, of course, after this, that, you know, when you, when you do, we use all that up, it doesn't matter.
3437.58 3439.32 SPEAKER_02  So he says, Britain should be excited by this.
3439.46 3441.32 SPEAKER_02  For one, it offers credible hope.
3441.42 3444.12 SPEAKER_02  I love to hear a political leader saying, no, this hope is credible.
3444.26 3445.24 SPEAKER_02  Unlike all that other hope.
3445.50 3447.70 SPEAKER_03  Well, it may not be hope, but it's certainly credible.
3448.06 3451.20 SPEAKER_02  It offers credible hope of a long desired boost in public sector productivity.
3451.46 3457.90 SPEAKER_02  AI can give them the precious gift of time so they can refocus on the care and connection aspects of their job that so often get buried beneath the bureaucracy.
3458.14 3461.92 SPEAKER_02  But again, they get buried beneath the bureaucracy, not because there's too much bureaucracy, because there's a lot of fucking people.
3462.08 3462.88 SPEAKER_03  Yeah, that's it.
3462.92 3467.28 SPEAKER_03  As my friend who works in the NHS always says, people think the NHS is, is overmanaged.
3467.36 3468.02 SPEAKER_03  It's undermanaged.
3468.10 3469.26 SPEAKER_03  There's no one to do any management.
3469.26 3469.46 SPEAKER_03  Yeah.
3469.98 3472.48 SPEAKER_02  Everyone's just running around with a fire extinguisher the whole time.
3472.64 3472.74 SPEAKER_02  Yeah.
3472.78 3475.16 SPEAKER_02  And he says, Britain shouldn't just be excited about AI.
3475.34 3476.12 SPEAKER_02  It should be confident.
3476.26 3479.20 SPEAKER_02  We don't need to walk down a US or EU path in regulation.
3479.38 3483.90 SPEAKER_02  We can go our own way, taking a distinctively British approach that will test AI before you regulate.
3484.04 3484.96 SPEAKER_02  Whoa, whoa, whoa, whoa, whoa.
3484.96 3487.18 SPEAKER_02  I don't like the sound of a distinctly British approach.
3487.44 3488.96 SPEAKER_02  I feel like that never ends well.
3489.14 3494.08 SPEAKER_02  But also, like, you remember, the internet was supposed to solve all the problems of public services back in 2002.
3494.22 3494.60 SPEAKER_02  Remember that?
3495.06 3495.16 SPEAKER_02  Yeah.
3495.16 3497.50 SPEAKER_02  Just the fact that it was going to have open government.
3497.68 3499.18 SPEAKER_02  It was going to be personalized learning.
3499.36 3502.02 SPEAKER_02  Yeah, but crucially, we needed ID cards to make it work,
3502.06 3504.10 SPEAKER_01  and we never got those, so it never really took off.
3504.36 3504.44 SPEAKER_01  Yeah.
3504.44 3515.50 SPEAKER_02  The actual plan itself, I don't know what it looks like other than just, we're going to try really hard to put AI wherever we can without sort of changing too much, hire as many people as we can, and hope something comes of it.
3515.56 3529.02 SPEAKER_02  It's more of an article of faith in the ability of AI to, quote unquote, transform public services, and a plea to investors to share that faith, which, like, if you look at, if Kier Starver's article in the FT contains a perfect sentence, which I think Milo's going to enjoy.
3529.24 3533.14 SPEAKER_02  Put simply, this is our message to anybody who's working at the AI frontier.
3533.14 3534.48 SPEAKER_02  Take a look at Britain.
3535.76 3536.58 SPEAKER_03  Fuck hell.
3537.26 3538.18 SPEAKER_02  Just check us out.
3538.76 3540.20 SPEAKER_03  Give us the code, like for your gut.
3540.26 3540.46 SPEAKER_03  Yeah.
3540.70 3540.92 SPEAKER_03  Yeah.
3541.16 3548.70 SPEAKER_03  The advice I always give, you know, to anyone running a country is, hope for the best, prepare for the best, do nothing.
3549.22 3552.86 SPEAKER_02  And then just hang your shingle on the door and just say, how about it?
3552.96 3553.10 SPEAKER_02  Yeah.
3553.18 3554.02 SPEAKER_02  Anybody for Britain?
3554.22 3555.12 SPEAKER_03  Seen Britain lately?
3555.22 3566.04 SPEAKER_03  Then yeah, Kier Starmer, look, to be fair to Kier Starmer, and this is what I will give him, he is delivering on his election promises, because if you remember the election campaign, he campaigned on, I will do absolutely fucking nothing.
3566.22 3567.56 SPEAKER_03  And that is what he's doing.
3567.88 3568.74 SPEAKER_03  Fair play to the man.
3568.80 3571.52 SPEAKER_03  He's locked himself in the David Blaine perspex box.
3571.62 3572.28 SPEAKER_03  He is inert.
3572.52 3577.52 SPEAKER_04  And maybe, and maybe that's why he's upset, because people are yelling at him for like, doing the thing that he said he would do, which is nothing.
3577.70 3578.84 SPEAKER_03  This is what you asked for.
3579.16 3580.68 SPEAKER_03  You don't want me to be the Batman.
3580.94 3584.10 SPEAKER_02  Our view is to be the best state partner for you anywhere in the world.
3584.16 3585.16 SPEAKER_02  And we can see this future.
3585.30 3591.10 SPEAKER_02  We are running towards it because we back our builders, because we know that AI has arrived as the ultimate force for change in national review.
3591.10 3591.98 SPEAKER_02  Now there's a vote winner.
3592.06 3592.44 SPEAKER_02  You're too ripe.
3592.60 3595.00 SPEAKER_02  So, you know, the talks then about unlocking public data.
3595.12 3599.32 SPEAKER_04  We're going to give like every AI guy who moves to the UK, like a white van with like a massive poppy.
3600.00 3600.36 SPEAKER_04  Yes.
3600.76 3601.12 SPEAKER_01  Yes.
3601.40 3603.34 SPEAKER_01  Sam Altman trading in the Koenigsegg.
3604.80 3611.00 SPEAKER_02  So he has outlined these plans to give like researchers and AI companies access to public data sets, including anonymized NHS patient data.
3611.08 3617.08 SPEAKER_02  By the way, if you add more than like five data points together, it doesn't matter if it's anonymized, you're fully identifiable from that.
3617.08 3617.48 SPEAKER_02  Yeah.
3617.54 3618.08 SPEAKER_02  No, good.
3618.36 3619.28 SPEAKER_02  Maybe five isn't.
3619.38 3624.40 SPEAKER_02  There is a number of data points about you that even if they're anonymized, you should just be known.
3624.52 3625.60 SPEAKER_02  Just be known who you are.
3625.68 3625.82 SPEAKER_02  Right.
3625.86 3636.34 SPEAKER_02  Like if we anonymize like all of our heights and we anonymized like, I don't know, our list of like even stuff like, see if that's partially identifiable, like addresses, but even stuff that's not identifiable at all.
3636.38 3636.70 SPEAKER_02  Right.
3636.78 3641.78 SPEAKER_02  Stuff like if you anonymized just are like heights, chronic medical conditions, like two other things.
3642.48 3642.62 SPEAKER_02  Yeah.
3642.68 3643.00 SPEAKER_02  Yeah.
3643.20 3643.56 SPEAKER_02  Yeah.
3643.80 3644.76 SPEAKER_02  Fully identifiable.
3644.76 3646.42 SPEAKER_02  So anyway, that's fun.
3646.48 3647.90 SPEAKER_02  But all of this is going to be secured.
3647.98 3651.28 SPEAKER_02  Of course, you're going to have really robust processes of governing who accesses this data.
3651.40 3652.62 SPEAKER_02  We're not going to give it to race scientists.
3652.62 3656.36 SPEAKER_01  We can't even secure the fucking biobank thing from like non AI guys.
3656.46 3656.66 SPEAKER_02  Yeah.
3656.72 3656.96 SPEAKER_02  Yeah.
3657.10 3659.04 SPEAKER_03  Race scientists use that shit all the time.
3659.18 3663.98 SPEAKER_03  Oh, you say you won't give the data to everyone, but suddenly the race scientists aren't allowed to have a look.
3664.50 3666.98 SPEAKER_03  Curious that that race scientist sounds like Hennig Vane.
3667.14 3667.28 SPEAKER_03  Yeah.
3668.14 3668.54 SPEAKER_03  Okay.
3668.68 3668.92 SPEAKER_03  Yeah.
3668.92 3671.46 SPEAKER_03  So I came over to the UK to do race science.
3672.24 3673.06 SPEAKER_03  But it's great.
3673.14 3674.72 SPEAKER_03  People want you to invest in Britain.
3675.16 3675.30 SPEAKER_02  Yeah.
3675.50 3677.64 SPEAKER_02  I kept saying, no, I want to do race science.
3677.70 3678.84 SPEAKER_02  They pushed me onto QI.
3679.08 3681.94 SPEAKER_01  I've often wondered who the first person to sue us would be.
3685.24 3685.60 SPEAKER_02  Yeah.
3685.66 3691.36 SPEAKER_02  So they're also saying like, look, we can have like a 1.5% GDP boost, which is like a very hedge language.
3691.48 3693.46 SPEAKER_02  They say, oh yeah, this isn't an IMF estimate.
3693.52 3695.50 SPEAKER_02  It's calculations based on an IMF estimate.
3695.50 3699.82 SPEAKER_02  All of the numbers are very like, you know, airy and random and assume all best case scenarios.
3700.04 3704.56 SPEAKER_02  He wants to build more miniature nuclear reactors that will exclusively power data centers.
3704.76 3705.12 SPEAKER_02  All right.
3705.82 3707.56 SPEAKER_03  How, how miniature are we talking?
3707.70 3709.18 SPEAKER_03  Like Ferrero Rocher size?
3709.50 3712.44 SPEAKER_03  Do not eat the Ferrero Rocher modular reactor.
3712.64 3713.98 SPEAKER_03  The forbidden Ferrero Rocher.
3713.98 3722.98 SPEAKER_02  So the other thing I want to go to, right, is if you make AI adoption a top priority across like the civil service, what happened when we did that with postmasters?
3723.14 3729.34 SPEAKER_02  With not even AI, we just used a computer system that we didn't fully understand and utterly trusted the output of.
3729.38 3731.46 SPEAKER_02  What happened when that happened in the post office?
3731.54 3732.38 SPEAKER_01  Well, it ended very well.
3732.38 3735.88 SPEAKER_01  We got, we got, ITV got a prestige drama out of it.
3735.96 3740.22 SPEAKER_01  So ultimately what we're doing is we're feeding state funding to prestige drama.
3740.36 3740.98 SPEAKER_03  Yeah, exactly.
3741.12 3744.58 SPEAKER_03  If we carry on doing this, there could be a job for Sarah Lancashire in 10 years.
3745.80 3748.20 SPEAKER_03  They know it's terrible what they've done with AI.
3749.62 3753.32 SPEAKER_02  And you know, the other thing that we haven't discussed is the AI growth zones, right?
3753.36 3755.92 SPEAKER_02  These are like, okay, they're places we're going to plop data centers down.
3756.04 3760.40 SPEAKER_02  And I'm just going to read from Dan McQuillan, who's been on the show before lately of this parish writing on AI growth zones.
3760.40 3766.34 SPEAKER_02  In between invocations of speed, pace and scale, there's some recognition in the plan that the UK is not a wholly happy place right now.
3766.42 3772.64 SPEAKER_02  We're recommending a high tech form of land enclosures via AI growth zones, which are about handing data center developers access to land and power.
3772.76 3776.96 SPEAKER_02  It gestures to the idea that these could drive local innovation in post-industrial towns.
3777.08 3786.72 SPEAKER_02  Well, the plans claims about AI's inevitable progress and the oncoming waves of agentic systems, which we're going to talk about in a future episode, that will reason, plan and action themselves already seem dated and discredited.
3786.72 3794.76 SPEAKER_02  What hasn't changed that the very regions targeted for growth via these zones, have already seen, for example, violent anti-immigrant pogroms accompanied by fascist rhetoric.
3794.92 3796.20 SPEAKER_02  And those sentiments have not gone away.
3796.34 3801.92 SPEAKER_02  So what we're saying is these places that have less of everything, they're also going to have less power and water.
3802.12 3802.24 SPEAKER_02  Good.
3802.40 3808.50 SPEAKER_02  They're also going to have like less land for how they're going to have less of everything so that we can create a minuscule number of jobs.
3808.50 3811.36 SPEAKER_02  Cause we know that data centers don't create that many jobs directly.
3811.36 3817.36 SPEAKER_02  So that then like we can see about a pilot program where a teacher manages 10 chat GPTs.
3817.36 3827.76 SPEAKER_03  So the way to deal with this is we need to, in order to kind of turn our enemies against each other, we need to convince Keir Starmer that all of these data centers should be built to look like a mosque.
3828.12 3831.48 SPEAKER_02  And then we're just going to build them in the most EDL town possible.
3832.62 3837.94 SPEAKER_02  So in this, just to end, right, Tony Blair, who's really, like, this is his plan to be clear.
3838.02 3842.20 SPEAKER_02  This is his plan via Matt Clifford, who's very connected to the Tony Blair Institute.
3842.20 3849.34 SPEAKER_02  He says, Sam Altman, the chief executive of open AI, has argued that by the end of 2025, we will see AI agents join the workforce.
3849.56 3854.22 SPEAKER_02  Meanwhile, Elon Musk has announced Tesla will start selling AI powered humanoid robots in 2026.
3854.54 3862.28 SPEAKER_02  And Jensen Huang, the chief executive of NVIDIA, said that advances in AI put the world on the cusp of a quote, multi-trillion dollar opportunity in autonomous vehicles.
3862.44 3865.08 SPEAKER_02  So he has quoted three hucksters, essentially.
3865.82 3866.00 SPEAKER_02  Yeah.
3866.00 3870.84 SPEAKER_03  It's so funny when they, like when they quote Elon Musk on anything, it's like, yeah, Elon Musk says he's going to be doing this next year.
3870.84 3872.82 SPEAKER_03  It's like Elon Musk says a lot of shit, brother.
3873.26 3876.22 SPEAKER_03  Elon Musk said that like Twitter was going to be amazing after he bought it.
3876.24 3878.70 SPEAKER_03  He said there was going to be a man on Mars two years ago.
3878.98 3880.94 SPEAKER_03  Maybe there is, you know, haven't checked back yet.
3881.04 3881.16 SPEAKER_02  Yeah.
3881.32 3882.16 SPEAKER_03  Have you been to Mars?
3882.26 3882.84 SPEAKER_03  Have you checked for men?
3882.92 3883.10 SPEAKER_03  Yeah.
3883.26 3884.56 SPEAKER_03  We sent a guy up there.
3884.80 3884.94 SPEAKER_03  Yeah.
3885.60 3888.16 SPEAKER_02  So, you know, he's, so Blair sort of talks about this, right?
3888.16 3896.80 SPEAKER_02  He says, but we all know too well from our time in government, how easy it is for well-designed strategy to get mangled to the machinery of Whitehall and for levers in Downing Street to be pulled, but for nothing to happen.
3897.02 3905.02 SPEAKER_02  Delivery in the AI action plan with the necessary urgency will require significant additional investment and projects to be funded rapidly without the usual obstacles of treasury business cases.
3905.14 3905.86 SPEAKER_02  So that's it, right?
3905.92 3910.46 SPEAKER_02  We're going to exempt one thing from treasury brain in the British economy.
3910.46 3913.14 SPEAKER_02  And it is the, um, it's the thing that's not real.
3913.32 3913.78 SPEAKER_02  It's the magic.
3913.94 3914.32 SPEAKER_02  We're expanding.
3914.58 3914.72 SPEAKER_01  Yeah.
3915.00 3918.64 SPEAKER_02  Magician's privilege is that you are exempt from treasury brain.
3918.76 3918.96 SPEAKER_01  All right.
3918.96 3919.96 SPEAKER_01  New plan, right?
3920.22 3922.62 SPEAKER_01  Within and against the institutions, right?
3922.64 3929.32 SPEAKER_01  What we do, anything we want to fund, say the NHS, we just say that it's AI and hope that they don't check.
3929.48 3929.66 SPEAKER_01  Right?
3929.66 3936.38 SPEAKER_01  So like, we're going to build a new AI center and due to the sort of vagaries of AI, it's going to look a lot like a hospital.
3936.64 3945.40 SPEAKER_01  It's going to have a lot of like doctors, nurses, you know, sort of hospital type activities, but there is a data center and that's probably going to use a lot of power and like water and stuff.
3945.50 3947.44 SPEAKER_01  So you're going to need to definitely fund that.
3948.30 3949.32 SPEAKER_01  Yeah, that's it.
3949.38 3955.00 SPEAKER_01  That's, that's, I mean, you know, I've developed this data center that looks almost exactly like a secondary school.
3955.14 3955.24 SPEAKER_02  Yeah.
3955.44 3958.82 SPEAKER_02  Children are going to go in and they're going to be the server.
3958.82 3960.68 SPEAKER_04  The data center is going to be Porter cabin.
3961.44 3962.60 SPEAKER_02  It's all still like,
3962.80 3970.02 SPEAKER_04  yeah, it's, they're all going to catch on fire because not because of like the energy that's being used or just like the bad kind of like engineering to sort of structure.
3970.12 3972.20 SPEAKER_04  And it's big, it's going to be like in Porter cabins.
3972.28 3973.88 SPEAKER_04  The whole country is just going to be filled.
3973.94 3978.10 SPEAKER_04  Cause like to build the Porter cabins, you're going to need to actually like build a warehouses for them.
3978.10 3978.34 SPEAKER_04  Right.
3978.34 3981.38 SPEAKER_04  That's not going to happen because like the NIMBYs still run everything.
3981.68 3986.12 SPEAKER_04  And you know, you might ruin the British skyline in like Swindon or something if you like build it.
3986.46 3988.34 SPEAKER_03  So I know someone has ruined a fucking skyline.
3989.82 3995.70 SPEAKER_04  So the solution is going to be to use temporary quote unquote temporary like casings, which will be poor cabins.
3995.92 4001.20 SPEAKER_04  And so I would say if you are investing, if you're investing in Britain, don't invest in the AI stuff, right?
4001.30 4002.70 SPEAKER_04  Like it's, it's a gold rush.
4002.80 4005.42 SPEAKER_04  Don't invest, like invest in the shovels, invest in the picks.
4005.42 4007.80 SPEAKER_04  And in this case, invest in the Porter cabin.
4008.06 4008.42 SPEAKER_03  Exactly.
4008.76 4010.54 SPEAKER_03  TF Porter cabin sales room.
4010.66 4011.18 SPEAKER_03  That's how it is.
4011.26 4012.28 SPEAKER_03  Sales Porter cabin.
4012.40 4014.62 SPEAKER_02  If you want to bring it back around to the start, right?
4014.76 4019.12 SPEAKER_02  You can't fix a Porter cabin country by going on the computer.
4019.30 4040.06 SPEAKER_02  There's no amount of going on the computer that is going to fix the very real and material problems that are causing this country to fall apart, literally and figuratively going on the computer, no matter how good of a computer you go on, no matter how big it is, no matter how powerful it is, no matter how smart your AI agent system is, there is no going on the computer to address what's happening.
4040.34 4041.08 SPEAKER_02  And that's just it.
4041.40 4041.76 SPEAKER_03  Yeah.
4041.90 4046.82 SPEAKER_03  It's like just every time you hear about any plan that like Keir Starmer or the rest of the labor government announced, it's like,
4046.94 4048.98 SPEAKER_00  it's like, Oh, just do stuff, man.
4049.26 4050.66 SPEAKER_00  Just do like actual stuff.
4050.72 4051.74 SPEAKER_00  Like just stop doing stuff.
4051.78 4052.74 SPEAKER_00  That's not stuff.
4052.98 4055.72 SPEAKER_00  This is so, it's so obvious that you just need to do stuff.
4055.84 4056.24 SPEAKER_02  I'm sorry.
4056.38 4058.84 SPEAKER_02  It's magicians privilege.
4059.06 4060.58 SPEAKER_05  All we need is stuff.
4060.68 4061.66 SPEAKER_05  Just actual stuff.
4061.66 4062.70 SPEAKER_02  I love that song.
4062.70 4065.52 SPEAKER_05  I love that song.
4065.76 4067.42 SPEAKER_02  All you need is stuff.
4067.92 4068.04 SPEAKER_02  Hey,
4068.38 4071.22 SPEAKER_05  all you need is stuff.
4071.72 4075.48 SPEAKER_02  All you need is stuff. Stuff.
4075.66 4077.46 SPEAKER_02  Stuff is all you need.
4077.76 4087.52 SPEAKER_04  When, when, when the, when the AI stuff fails, hopefully Ben Kirsten would be like, well, all right, well, you know, there's no other choice now other than to like train a generation of woodworkers and then we'll be back.
4087.64 4087.80 SPEAKER_04  Right.
4087.98 4088.86 SPEAKER_03  For the love of God,
4088.98 4092.30 SPEAKER_04  build a road or a train line or a school or something. Just please.
4092.48 4094.06 SPEAKER_04  Cause then you could build wooden ports of cabins.
4094.24 4095.62 SPEAKER_04  At least they'd be built slightly better.
4095.80 4095.94 SPEAKER_02  Yeah.
4096.22 4098.82 SPEAKER_02  Anyway, I think that's all we have time for, for today.
4098.94 4102.54 SPEAKER_02  It's been a long discussion of a terrible plan, which always leaves me quite personally drained.
4102.66 4102.80 SPEAKER_02  Yeah.
4102.80 4105.02 SPEAKER_02  But thank you for being a subscriber to the Patreon.
4105.20 4106.48 SPEAKER_02  Thank you for being involved.
4106.62 4109.84 SPEAKER_02  We will see you on the free episode in a few days.
4109.98 4110.24 SPEAKER_02  Yes.
4110.38 4111.84 SPEAKER_02  Milo, you're in Belgium or something.
4112.04 4112.26 SPEAKER_02  Yeah.
4112.40 4115.86 SPEAKER_03  Belgium sold out Belgium, Brussels still tickets.
4116.04 4117.16 SPEAKER_03  Please come and see me in Leicester.
4117.26 4118.36 SPEAKER_03  I haven't plugged that day enough.
4118.48 4119.80 SPEAKER_03  Sales are bad.
4120.02 4120.96 SPEAKER_02  Please come to that.
4121.02 4122.10 SPEAKER_03  He's going to be in Schaffhausen.
4122.18 4122.68 SPEAKER_03  That's right.
4122.82 4125.04 SPEAKER_03  I'm going to, I'm going to be in Groningen.
4125.04 4128.16 SPEAKER_03  I'm going to be in Strasbourg.
4128.34 4128.44 SPEAKER_03  Yeah.
4128.52 4129.50 SPEAKER_03  That'd be pretty fun.
4129.64 4129.86 SPEAKER_03  Yeah.
4130.16 4130.38 SPEAKER_03  Yeah.
4130.70 4135.92 SPEAKER_02  You're going to be in a town with a German, a German name on the Italian border and an Italian name on the French border.
4136.00 4136.52 SPEAKER_02  That's right.
4136.56 4138.36 SPEAKER_03  I'm going to be in the Tyrell suit.
4138.72 4139.08 SPEAKER_03  Yeah.
4139.60 4141.12 SPEAKER_02  He's going to be in Ticino.
4141.34 4141.54 SPEAKER_02  Yeah.
4142.36 4145.24 SPEAKER_02  I don't know why this always, this, I always have a good time with this.
4145.28 4146.80 SPEAKER_02  He's going to be in Gaziantep.
4147.10 4149.48 SPEAKER_02  I'm going to be in Cisalpine Ghoul.
4150.62 4151.10 SPEAKER_02  All right.
4151.14 4151.40 SPEAKER_02  All right.
4151.42 4151.64 SPEAKER_02  Yeah.
4151.82 4152.48 SPEAKER_02  Thanks everybody.
4152.48 4153.82 SPEAKER_02  We'll see you on the free episode.
4154.00 4154.12 SPEAKER_02  Bye.
4154.62 4154.76 SPEAKER_02  Bye.
4162.64 4163.28 None  Bye.
4169.96 4171.00 None  Bye.
4171.16 4171.32 None  Bye.
4171.38 4171.94 None  Bye.
4172.08 4172.98 None  Bye.
4172.98 4173.46 None  Bye.
4173.50 4173.80 None  Bye.
4174.30 4175.88 None  Bye.
4175.90 4176.52 None  Bye.
4176.52 4176.98 None  Bye.
4177.04 4178.06 None  Bye.
4178.06 4180.96 None  Bye.
4180.98 4181.04 None  Bye.
4190.62 4191.78 None  Bye.
4191.84 4192.54 None  Bye.
